{
    "docs": [
        {
            "location": "/", 
            "text": "dev\n\n\n\n\nTextile Cheat Sheet\n\n\nScaling images, animated GIFs in Gimp\n\n\nScreenshots, Screencasts, Animated Gifs\n\n\nffmpeg Notes\n\n\nUnix-y Notes\n\n\nLattice Reduction Notes\n\n\nPS/SVG to GCode Conversion\n\n\nChange Git default 'master' branch to 'release'\n\n\nMkDocs Quickstart\n\n\nGPG Notes\n\n\nGit Notes\n\n\nShannon Entropy\n\n\nEnabling Server HTTPS\n\n\nBGZF Example\n\n\nC Project Template\n\n\nProject Organization\n\n\nKelly Criterion\n\n\nFile Naming Conventions\n\n\nLoose Standards for Command Line Options\n\n\nPCB Notes\n\n\nElements of Coding Style\n\n\nEnergy Consumption Stats\n\n\nSimple Sums\n\n\nFisher Yates Shuffle\n\n\nHalting Problem\n\n\nAssorted Small Probability Problems\n\n\nProbability Notes\n\n\nAmdahl's Law\n\n\nIs It Really Open\n\n\nNumber Theory Notes\n\n\nArbitrary Binary Functions\n\n\nEmpirical Laws\n\n\nFood - CO2 emissions and water usage\n\n\nSSH Recipes\n\n\nFuture Predictions\n\n\nDiophantine Approximation\n\n\nCommon GCode Commands\n\n\nMisc. Math\n\n\nSocio-Economic Definitions\n\n\nBitcoin Moon Math\n\n\nSolar Energy Discussion", 
            "title": "Home"
        }, 
        {
            "location": "/#dev", 
            "text": "Textile Cheat Sheet  Scaling images, animated GIFs in Gimp  Screenshots, Screencasts, Animated Gifs  ffmpeg Notes  Unix-y Notes  Lattice Reduction Notes  PS/SVG to GCode Conversion  Change Git default 'master' branch to 'release'  MkDocs Quickstart  GPG Notes  Git Notes  Shannon Entropy  Enabling Server HTTPS  BGZF Example  C Project Template  Project Organization  Kelly Criterion  File Naming Conventions  Loose Standards for Command Line Options  PCB Notes  Elements of Coding Style  Energy Consumption Stats  Simple Sums  Fisher Yates Shuffle  Halting Problem  Assorted Small Probability Problems  Probability Notes  Amdahl's Law  Is It Really Open  Number Theory Notes  Arbitrary Binary Functions  Empirical Laws  Food - CO2 emissions and water usage  SSH Recipes  Future Predictions  Diophantine Approximation  Common GCode Commands  Misc. Math  Socio-Economic Definitions  Bitcoin Moon Math  Solar Energy Discussion", 
            "title": "dev"
        }, 
        {
            "location": "/Textile-Cheat-Sheet/", 
            "text": "Textile Cheat Sheet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeader (h1)\n\n\nh1.\n\n\n\n\n\n\nHeader (h2)\n\n\nh2.\n\n\n\n\n\n\nHeader (h3)\n\n\nh3.\n\n\n\n\n\n\nlink (aligned)\n\n\n@\"text\":http://url@, @!\npic.png!@\n\n\n\n\n\n\npicture link\n\n\n@!http://url!@\n\n\n\n\n\n\ncode block\n\n\npre\n \n/pre\n\n\n\n\n\n\nbold\n\n\nbold\n\n\n\n\n\n\nbold\n\n\nbold\n\n\n\n\n\n\nitalic\n\n\nitalic\n\n\n\n\n\n\nliteral\n\n\nliteral\n\n\n\n\n\n\nparagraph alignment\n\n\n@p\n.@, @p=.@, @p\n.@\n\n\n\n\n\n\nparagraph indent\n\n\n@p(.@, @p((.@, ..., @p().@, ..., @p)).@, @p).@\n\n\n\n\n\n\ndot list\n\n\n@*@, @**@, ...\n\n\n\n\n\n\nnumbered list\n\n\n@#@, @##@, ...\n\n\n\n\n\n\nblock quote\n\n\n@bq.@\n\n\n\n\n\n\n\n\nTables\n\n\n|_. attribute list |_. ...  |\n| val | ue |\n\n\n|\\2. spans two cols |\n| col 1 | col 2 |\n\n|/3. spans 3 rows | a |\n| b |\n| c |\n\n\n\n\n\nReferences\n\n\n\n\nTextile Quick Reference\n\n\nA Textile Reference\n\n\n\n\n2015-10-20", 
            "title": "Textile Cheat Sheet"
        }, 
        {
            "location": "/Textile-Cheat-Sheet/#textile-cheat-sheet", 
            "text": "Header (h1)  h1.    Header (h2)  h2.    Header (h3)  h3.    link (aligned)  @\"text\":http://url@, @! pic.png!@    picture link  @!http://url!@    code block  pre   /pre    bold  bold    bold  bold    italic  italic    literal  literal    paragraph alignment  @p .@, @p=.@, @p .@    paragraph indent  @p(.@, @p((.@, ..., @p().@, ..., @p)).@, @p).@    dot list  @*@, @**@, ...    numbered list  @#@, @##@, ...    block quote  @bq.@", 
            "title": "Textile Cheat Sheet"
        }, 
        {
            "location": "/Textile-Cheat-Sheet/#tables", 
            "text": "|_. attribute list |_. ...  |\n| val | ue |\n\n\n|\\2. spans two cols |\n| col 1 | col 2 |\n\n|/3. spans 3 rows | a |\n| b |\n| c |", 
            "title": "Tables"
        }, 
        {
            "location": "/Textile-Cheat-Sheet/#references", 
            "text": "Textile Quick Reference  A Textile Reference", 
            "title": "References"
        }, 
        {
            "location": "/Textile-Cheat-Sheet/#2015-10-20", 
            "text": "", 
            "title": "2015-10-20"
        }, 
        {
            "location": "/Image-Resize/", 
            "text": "Resize with Imagemagick\n\n\nUsing Imagemagick's \nconvert\n tool, you can resize an image but Imagemagick\ndoes interpolation so the resulting image can look pretty bad.\n\n\nFor example, using the input (animated) gif:\n\n\n\n\nAnd issuing the command to resize it by a factor of 4:\n\n\n$ convert tree_anim_inp.gif -resize 400% tree_anim_ugly.gif\n\n\n\n\nproduces the interpolated (and ugly) picture:\n\n\n\n\nInstead, use the \nscale\n command:\n\n\n$ convert tree_anim_inp.gif -scale 400% tree_anim_out.gif\n\n\n\n\n\n\nReference\n\n\n\n\nImageMagick resize without interpolation\n\n\n\n\n\n\nSaving animated GIFs in Gimp\n\n\nSave as a \n.gif\n file extension.  When exporting, there will be an option to save as an animation:\n\n\n\n\nCheck it and you should have an animated GIF.\n\n\n2015-10-27", 
            "title": "Image Resize"
        }, 
        {
            "location": "/Image-Resize/#resize-with-imagemagick", 
            "text": "Using Imagemagick's  convert  tool, you can resize an image but Imagemagick\ndoes interpolation so the resulting image can look pretty bad.  For example, using the input (animated) gif:   And issuing the command to resize it by a factor of 4:  $ convert tree_anim_inp.gif -resize 400% tree_anim_ugly.gif  produces the interpolated (and ugly) picture:   Instead, use the  scale  command:  $ convert tree_anim_inp.gif -scale 400% tree_anim_out.gif", 
            "title": "Resize with Imagemagick"
        }, 
        {
            "location": "/Image-Resize/#reference", 
            "text": "ImageMagick resize without interpolation", 
            "title": "Reference"
        }, 
        {
            "location": "/Image-Resize/#saving-animated-gifs-in-gimp", 
            "text": "Save as a  .gif  file extension.  When exporting, there will be an option to save as an animation:   Check it and you should have an animated GIF.", 
            "title": "Saving animated GIFs in Gimp"
        }, 
        {
            "location": "/Image-Resize/#2015-10-27", 
            "text": "", 
            "title": "2015-10-27"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/", 
            "text": "Screencasts\n\n\nI've found \nkazam\n to work very well.\n\n\n$ sudo apt-get install kazam\n$ kazam\n\n\n\n\nScreenshots\n\n\nGimp\n\n\nFile-\nCreate-\nScreenshot\n\n\nImageMagick\n\n\n$ import -window root screenshot.png\n\n\n\n\nAnimated Gifs\n\n\nImageMagick\n\n\n$ convert -delay 1 -layers optimize inp*.png anim.gif\n\n\n\n\nQuick and dirty way to create animated Gifs from a window\n\n\n$ winid=`xwininfo | grep -o 'Window id: [^ ]* ' | cut -f3 -d' '` ; echo $winid\n\n\n\n\nClick on the window in question and make sure the portion of the\nwindow you want to record is exposed.\n\n\n$ for x in {1..10}\ndo\n  import  -window $winid out$x.png\n  sleep 0.1\ndone\n\n\n\n\nOnce the \nout{1..10}.png\n files are created, coalesce them into an animated Gif:\n\n\n$ convert -delay 1 -layers optimize out*.png anim.gif\n\n\n\n\nUsing ImageMagick is sometimes slow.  Using \nkazam\n (and only capturing a window) will create an \nmp4\n file that can be exploded:\n\n\n$ ffmpeg -i inp.mp4 pic%03d.jpg\n$ for x in `ls pic*.jpg`\ndo\n  mogrify -crop 1000x700+0+70 $x\ndone\n$ convert -layers optimize pic*.jpg out.gif\n\n\n\n\nWhere \nmogrify\n alters the image file in place and \n-crop\n crops the top pixels (to get rid of the tabs and URL if it's a web browser, say).\n\n\nSometimes ImageMagick has a lot of issues when trying to create an animated Gif, especially if there are many frames.  Instead, you can use \nffmpeg\n directly (see \nSO\n):\n\n\n$ palette=\n/tmp/palette.png\n\n$ filters=\nfps=15,scale=320:-1:flags=lanczos\n\n$ ffmpeg -i input.mp4 -vf \n$filters,palettegen\n -y $palette\n$ ffmpeg -i input.mp4 -i $palette -lavfi \n$filters [x]; [x][1:v] paletteuse\n -y output.gif\n\n\n\n\nffmpeg\n can apparently also directly create (large) animated Gifs:\n\n\n$ ffmpeg -i input.mp4 large_output.gif\n\n\n\n\nTo reduce the \nlarge_output.gif\n, \ngifsicle\n can be used:\n\n\n$ gifsicle -O1 --loop large_output.gif \n slim_output.gif\n\n\n\n\nthough \ngifsicle\n looks to have some problems compressing well.\n\n\nTo take a sub range of pictures from \ngifsicle\n, you can do something like:\n\n\n$ gifsicle -U inp.gif '#50-73' \n out50-73.gif\n\n\n\n\nWhere the \n#\n specifies the frame range and the \n-U\n (unoptimize) option is needed to get rid of artifacts that appear to happen when selecting from a mid range of frames.\n\n\nrecommended workflow\n\n\n\n\ncapture with \nkazam\n\n\nuse the above script to convert from \n.mp4\n to animated Gif with \nffmpeg\n\n\n\n\n2015-11-01", 
            "title": "Screenshots Screencasts Animated Gifs"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#screencasts", 
            "text": "I've found  kazam  to work very well.  $ sudo apt-get install kazam\n$ kazam", 
            "title": "Screencasts"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#screenshots", 
            "text": "", 
            "title": "Screenshots"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#gimp", 
            "text": "File- Create- Screenshot", 
            "title": "Gimp"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#imagemagick", 
            "text": "$ import -window root screenshot.png", 
            "title": "ImageMagick"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#animated-gifs", 
            "text": "", 
            "title": "Animated Gifs"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#imagemagick_1", 
            "text": "$ convert -delay 1 -layers optimize inp*.png anim.gif", 
            "title": "ImageMagick"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#quick-and-dirty-way-to-create-animated-gifs-from-a-window", 
            "text": "$ winid=`xwininfo | grep -o 'Window id: [^ ]* ' | cut -f3 -d' '` ; echo $winid  Click on the window in question and make sure the portion of the\nwindow you want to record is exposed.  $ for x in {1..10}\ndo\n  import  -window $winid out$x.png\n  sleep 0.1\ndone  Once the  out{1..10}.png  files are created, coalesce them into an animated Gif:  $ convert -delay 1 -layers optimize out*.png anim.gif  Using ImageMagick is sometimes slow.  Using  kazam  (and only capturing a window) will create an  mp4  file that can be exploded:  $ ffmpeg -i inp.mp4 pic%03d.jpg\n$ for x in `ls pic*.jpg`\ndo\n  mogrify -crop 1000x700+0+70 $x\ndone\n$ convert -layers optimize pic*.jpg out.gif  Where  mogrify  alters the image file in place and  -crop  crops the top pixels (to get rid of the tabs and URL if it's a web browser, say).  Sometimes ImageMagick has a lot of issues when trying to create an animated Gif, especially if there are many frames.  Instead, you can use  ffmpeg  directly (see  SO ):  $ palette= /tmp/palette.png \n$ filters= fps=15,scale=320:-1:flags=lanczos \n$ ffmpeg -i input.mp4 -vf  $filters,palettegen  -y $palette\n$ ffmpeg -i input.mp4 -i $palette -lavfi  $filters [x]; [x][1:v] paletteuse  -y output.gif  ffmpeg  can apparently also directly create (large) animated Gifs:  $ ffmpeg -i input.mp4 large_output.gif  To reduce the  large_output.gif ,  gifsicle  can be used:  $ gifsicle -O1 --loop large_output.gif   slim_output.gif  though  gifsicle  looks to have some problems compressing well.  To take a sub range of pictures from  gifsicle , you can do something like:  $ gifsicle -U inp.gif '#50-73'   out50-73.gif  Where the  #  specifies the frame range and the  -U  (unoptimize) option is needed to get rid of artifacts that appear to happen when selecting from a mid range of frames.  recommended workflow   capture with  kazam  use the above script to convert from  .mp4  to animated Gif with  ffmpeg", 
            "title": "Quick and dirty way to create animated Gifs from a window"
        }, 
        {
            "location": "/Screenshots-Screencasts-Animated-Gifs/#2015-11-01", 
            "text": "", 
            "title": "2015-11-01"
        }, 
        {
            "location": "/ffmpeg-notes/", 
            "text": "Video Cropping\n\n\n-qscale\n sets the compression level (?) (higher is more compression).\n\ncrop\n is width, height, start x, start y.\n\n\nffmpeg -i inp.mp4 -qscale 10  -filter:v \ncrop=in_w:in_h-63:0:63\n out.mp4\n\n\n\n\n2015-11-05", 
            "title": "Ffmpeg notes"
        }, 
        {
            "location": "/ffmpeg-notes/#video-cropping", 
            "text": "-qscale  sets the compression level (?) (higher is more compression). crop  is width, height, start x, start y.  ffmpeg -i inp.mp4 -qscale 10  -filter:v  crop=in_w:in_h-63:0:63  out.mp4", 
            "title": "Video Cropping"
        }, 
        {
            "location": "/ffmpeg-notes/#2015-11-05", 
            "text": "", 
            "title": "2015-11-05"
        }, 
        {
            "location": "/Unix-y-notes/", 
            "text": "Remove highlights from less search\n\n\nESC\n \nu\n\n\nJump to line in less\n\n\nng\n - Jump to line \nn\n relative to top of file\n\n\nnG\n - Jump to line \nn\n relative to bottom of file\n\n\nGzip without timestamps\n\n\nBy default, gzip keeps timestamp information for the file you're compressing.  This is problematic when you want reproducibility.\n\n\n$ gzip -n inp.txt\n\n\n\n\nThis will create a file \ninp.txt.gz\n that, when uncompressed, will create a file with the current system timestamp.\n\n\nAs far as I know, \nbgzip\n does not keep file timestamp information.\n\n\nRead lines in a bash script\n\n\nhttp://stackoverflow.com/questions/10929453/bash-scripting-read-file-line-by-line\n\n\n#!/bin/bash\nwhile IFS='' read -r line || [[ -n \n$line\n ]]; do\n    echo $line\ndone \n \n( echo -e \nthis small script\\nreads multiple\\n lines\n )\n\n\n\n\n\n\nIFS='' (or IFS=) prevents leading/trailing whitespace from being trimmed.\n-r prevents backslash escapes from being interpreted.\n|| [[ -n $line ]] prevents the last line from being ignored if it doesn't end with a \\n (since read returns a non-zero exit code when it encounters EOF).\n\n\n\n\nsometimes you can just get away with this:\n\n\n#!/bin/bash\nwhile read line ; do\n  echo $line\ndone \n \n( echo -e \nthis small script\\nreads multiple\\n lines\n )\n\n\n\n\nDiff two streams\n\n\n$ diff \n( echo -e \nstream\\na\n ) \n( echo -e \nstream\\nb\n )\n2c2\n\n a\n---\n\n b\n\n\n\n\nFind all files ending in \n.md\n and do an \nls -l\n\n\n$ find . -type f -name '*.md' -exec ls -l {} \\;\n\n\n\n\nPut pairs of lines on their own line\n\n\n$ echo -e 'a\\nb\\nc\\nd\\ne\\nf' | paste - - | tr '\\t' ' '\na b\nc d\ne f\n\n\n\n\nDifferences, overlaps in two files\n\n\n$ comm \n( echo -e 'c\\na\\nb\\nd' | sort ) \n( echo -e 'e\\nb\\nd' | sort )\na\n                b\nc\n                d\n        e\n\n\n\n\nPrint formatted columns\n\n\n$ echo -e \ncolumn_0\\tcol1\\na\\tbbbb\\n\n\ncolumn_0        col1\na       bbbb\n$ echo -e \ncolumn_0\\tcol1\\na\\tbbbb\\n\n | column -t\ncolumn_0  col1\na         bbbb\n\n\n\n\nbgzip\n\n\n$ bgzip -i inp.txt\n$ bgzip --stdout --offset 100 --size 32 inp.txt.gz\n\n\n\n\nparallel\n\n\n#!/bin/bash\nfunction process {\n  z=$1\n  time ( echo sleeping $z \n sleep $z \n echo waking up \n($z)\n )\n}\nexport -f process\n\ntime echo -e '1\\n3\\n4' | parallel --max-procs 2 process {}\n\n\n\n\nsleeping 1\nwaking up (1)\n\nreal    0m1.002s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 3\nwaking up (3)\n\nreal    0m3.002s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 4\nwaking up (4)\n\nreal    0m4.003s\nuser    0m0.000s\nsys 0m0.000s\n\nreal    0m5.603s\nuser    0m0.140s\nsys 0m0.072s\n\n\n\n\nxargs (parallel)\n\n\n#!/bin/bash\nfunction process {\n  z=$1\n  time ( echo sleeping $z \n sleep $z \n echo waking up \n($z)\n )\n}\nexport -f process\n\ntime echo -e '1\\n3\\n4' | xargs -n 1 -P 2 -I{} bash -c 'process {}'\n\n\n\n\nsleeping 1\nsleeping 3\nwaking up (1)\n\nreal    0m1.003s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 4\nwaking up (3)\n\nreal    0m3.002s\nuser    0m0.000s\nsys 0m0.000s\nwaking up (4)\n\nreal    0m4.003s\nuser    0m0.000s\nsys 0m0.000s\n\nreal    0m5.019s\nuser    0m0.000s\nsys 0m0.000s\n\n\n\n\nsort on multiple fields\n\n\n$ echo -e \n5,cats,meow\\n7,cute,mew\\n2,cats,mewmew\\n10,cats,meowmeowmeow\\n2,cute,4you\\n8,cute,4ever\n\n5,cats,meow\n7,cute,mew\n2,cats,mewmew\n10,cats,meowmeowmeow\n2,cute,4you\n8,cute,4ever\n$ echo -e \n5,cats,meow\\n7,cute,mew\\n2,cats,mewmew\\n10,cats,meowmeowmeow\\n2,cute,4you\\n8,cute,4ever\n | \\\n  sort -k2,2 -k1,1nr -t,\n10,cats,meowmeowmeow\n5,cats,meow\n2,cats,mewmew\n8,cute,4ever\n7,cute,mew\n2,cute,4you\n\n\n\n\n\n\n-t\n field\n\n\n-k\nstart\n,\nstop\nopt\n key start and stop position along with opt (in the above \nn\n for numeric, \nr\n for reverse)\n\n\n\n\n2017-05-14", 
            "title": "Unix y notes"
        }, 
        {
            "location": "/Unix-y-notes/#remove-highlights-from-less-search", 
            "text": "ESC   u", 
            "title": "Remove highlights from less search"
        }, 
        {
            "location": "/Unix-y-notes/#jump-to-line-in-less", 
            "text": "ng  - Jump to line  n  relative to top of file  nG  - Jump to line  n  relative to bottom of file", 
            "title": "Jump to line in less"
        }, 
        {
            "location": "/Unix-y-notes/#gzip-without-timestamps", 
            "text": "By default, gzip keeps timestamp information for the file you're compressing.  This is problematic when you want reproducibility.  $ gzip -n inp.txt  This will create a file  inp.txt.gz  that, when uncompressed, will create a file with the current system timestamp.  As far as I know,  bgzip  does not keep file timestamp information.", 
            "title": "Gzip without timestamps"
        }, 
        {
            "location": "/Unix-y-notes/#read-lines-in-a-bash-script", 
            "text": "http://stackoverflow.com/questions/10929453/bash-scripting-read-file-line-by-line  #!/bin/bash\nwhile IFS='' read -r line || [[ -n  $line  ]]; do\n    echo $line\ndone    ( echo -e  this small script\\nreads multiple\\n lines  )   IFS='' (or IFS=) prevents leading/trailing whitespace from being trimmed.\n-r prevents backslash escapes from being interpreted.\n|| [[ -n $line ]] prevents the last line from being ignored if it doesn't end with a \\n (since read returns a non-zero exit code when it encounters EOF).   sometimes you can just get away with this:  #!/bin/bash\nwhile read line ; do\n  echo $line\ndone    ( echo -e  this small script\\nreads multiple\\n lines  )", 
            "title": "Read lines in a bash script"
        }, 
        {
            "location": "/Unix-y-notes/#diff-two-streams", 
            "text": "$ diff  ( echo -e  stream\\na  )  ( echo -e  stream\\nb  )\n2c2  a\n---  b", 
            "title": "Diff two streams"
        }, 
        {
            "location": "/Unix-y-notes/#find-all-files-ending-in-md-and-do-an-ls-l", 
            "text": "$ find . -type f -name '*.md' -exec ls -l {} \\;", 
            "title": "Find all files ending in .md and do an ls -l"
        }, 
        {
            "location": "/Unix-y-notes/#put-pairs-of-lines-on-their-own-line", 
            "text": "$ echo -e 'a\\nb\\nc\\nd\\ne\\nf' | paste - - | tr '\\t' ' '\na b\nc d\ne f", 
            "title": "Put pairs of lines on their own line"
        }, 
        {
            "location": "/Unix-y-notes/#differences-overlaps-in-two-files", 
            "text": "$ comm  ( echo -e 'c\\na\\nb\\nd' | sort )  ( echo -e 'e\\nb\\nd' | sort )\na\n                b\nc\n                d\n        e", 
            "title": "Differences, overlaps in two files"
        }, 
        {
            "location": "/Unix-y-notes/#print-formatted-columns", 
            "text": "$ echo -e  column_0\\tcol1\\na\\tbbbb\\n \ncolumn_0        col1\na       bbbb\n$ echo -e  column_0\\tcol1\\na\\tbbbb\\n  | column -t\ncolumn_0  col1\na         bbbb", 
            "title": "Print formatted columns"
        }, 
        {
            "location": "/Unix-y-notes/#bgzip", 
            "text": "$ bgzip -i inp.txt\n$ bgzip --stdout --offset 100 --size 32 inp.txt.gz", 
            "title": "bgzip"
        }, 
        {
            "location": "/Unix-y-notes/#parallel", 
            "text": "#!/bin/bash\nfunction process {\n  z=$1\n  time ( echo sleeping $z   sleep $z   echo waking up  ($z)  )\n}\nexport -f process\n\ntime echo -e '1\\n3\\n4' | parallel --max-procs 2 process {}  sleeping 1\nwaking up (1)\n\nreal    0m1.002s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 3\nwaking up (3)\n\nreal    0m3.002s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 4\nwaking up (4)\n\nreal    0m4.003s\nuser    0m0.000s\nsys 0m0.000s\n\nreal    0m5.603s\nuser    0m0.140s\nsys 0m0.072s", 
            "title": "parallel"
        }, 
        {
            "location": "/Unix-y-notes/#xargs-parallel", 
            "text": "#!/bin/bash\nfunction process {\n  z=$1\n  time ( echo sleeping $z   sleep $z   echo waking up  ($z)  )\n}\nexport -f process\n\ntime echo -e '1\\n3\\n4' | xargs -n 1 -P 2 -I{} bash -c 'process {}'  sleeping 1\nsleeping 3\nwaking up (1)\n\nreal    0m1.003s\nuser    0m0.000s\nsys 0m0.000s\nsleeping 4\nwaking up (3)\n\nreal    0m3.002s\nuser    0m0.000s\nsys 0m0.000s\nwaking up (4)\n\nreal    0m4.003s\nuser    0m0.000s\nsys 0m0.000s\n\nreal    0m5.019s\nuser    0m0.000s\nsys 0m0.000s", 
            "title": "xargs (parallel)"
        }, 
        {
            "location": "/Unix-y-notes/#sort-on-multiple-fields", 
            "text": "$ echo -e  5,cats,meow\\n7,cute,mew\\n2,cats,mewmew\\n10,cats,meowmeowmeow\\n2,cute,4you\\n8,cute,4ever \n5,cats,meow\n7,cute,mew\n2,cats,mewmew\n10,cats,meowmeowmeow\n2,cute,4you\n8,cute,4ever\n$ echo -e  5,cats,meow\\n7,cute,mew\\n2,cats,mewmew\\n10,cats,meowmeowmeow\\n2,cute,4you\\n8,cute,4ever  | \\\n  sort -k2,2 -k1,1nr -t,\n10,cats,meowmeowmeow\n5,cats,meow\n2,cats,mewmew\n8,cute,4ever\n7,cute,mew\n2,cute,4you   -t  field  -k start , stop opt  key start and stop position along with opt (in the above  n  for numeric,  r  for reverse)", 
            "title": "sort on multiple fields"
        }, 
        {
            "location": "/Unix-y-notes/#2017-05-14", 
            "text": "", 
            "title": "2017-05-14"
        }, 
        {
            "location": "/lattice-reduction/", 
            "text": "Lattice Reduction\n\n\nThere seem to be two main methods of using lattice reduction\ntechniques for other norms.  The first looks to be to use\na linear programming step in place of the 'weak reduction' step\n(the Gram-Schmidt reduction step).  The second is embedding\nthe base in a higher dimension with extra structure and giving\nbounds on how far it is from the different norm.\n\n\nReferences\n\n\n\n\nOther norms for Lattice reduction techniques (LLL, PSLQ)?\n\n\nOther norms for Lattice reduction techniques (LLL, PSLQ)?\n\n\n\"The generalized basis reduction algorithm\" by Laszlo Lovasz and Herbert Scarf\n\n\n\"Lattice Problems and Norm Embeddings\" by Oded Regev and Ricky Rosen\n\n\n\"Limits on the Hardness of Lattice Problems in lp Norms\" by Chris Peikert\n\n\n\"Lattice Basis Reduction in Infinity Norm\" by Vanya Ivanova (Bachelor Thesis)\n\n\n\n\n2015-11-30", 
            "title": "Lattice reduction"
        }, 
        {
            "location": "/lattice-reduction/#lattice-reduction", 
            "text": "There seem to be two main methods of using lattice reduction\ntechniques for other norms.  The first looks to be to use\na linear programming step in place of the 'weak reduction' step\n(the Gram-Schmidt reduction step).  The second is embedding\nthe base in a higher dimension with extra structure and giving\nbounds on how far it is from the different norm.", 
            "title": "Lattice Reduction"
        }, 
        {
            "location": "/lattice-reduction/#references", 
            "text": "Other norms for Lattice reduction techniques (LLL, PSLQ)?  Other norms for Lattice reduction techniques (LLL, PSLQ)?  \"The generalized basis reduction algorithm\" by Laszlo Lovasz and Herbert Scarf  \"Lattice Problems and Norm Embeddings\" by Oded Regev and Ricky Rosen  \"Limits on the Hardness of Lattice Problems in lp Norms\" by Chris Peikert  \"Lattice Basis Reduction in Infinity Norm\" by Vanya Ivanova (Bachelor Thesis)", 
            "title": "References"
        }, 
        {
            "location": "/lattice-reduction/#2015-11-30", 
            "text": "", 
            "title": "2015-11-30"
        }, 
        {
            "location": "/GCode-Conversion/", 
            "text": "GCode Conversion Tools\n\n\nAt one point, I had good success with an Inkscape plugin called \nGcodetools\n but\nit seems to have succumbed to bit-rot and doesn't work on my current Ubuntu installation (16.04).\n\n\nI'm settling on a rough toolchain that takes some base format (PostScript/PDF/SVG/etc.), converts\nto \"GNUPlot format\" then converts to GCocde.\n\n\nBasic Workflow\n\n\n\n\nOrig -\n SVG\n   Create object in whatever tool and export to SVG\n\n\nSVG  -\n PS\n    Use \nrsvg-convert\n to convert from SVG to PostScript\n\n\nPS   -\n GP\n    Use \npstoedit\n to convert to \"gnuplot\" polygon format\n\n\nGP   -\n GCode\n Order the polygons properly, removing duplicate boundaries and convert to GCode using \nclipcli\n, convert from GNUPlot format to GCode using \ngp2ngc\n and then rescale using other cli GCode tools.\n\n\n\n\nInstallation\n\n\nSome tools of relevance are:\n\n\n\n\nrsvg-convert\n\n\npstoedit\n\n\nclipcli\n\n\nabes_cnc_utilities\n\n\ngrecode\n\n\n\n\nUnder Ubuntu, some of the tools can be installed via:\n\n\nsudo apt-get install pstoedit librsvg2-bin\n\n\n\n\nConversion\n\n\nThough this is pretty hodge-podge, there are a few things to consider:\n\n\n\n\npstoedit\n loses units when converting to \nRS274\n GCode.  I believe this only considers PostScript with \"pixel\" units, regardless of original units, then converts a pixel to 1/72 inches.  A post scale has to be done if using \npstoedit\n to rescale to the appropriate units\n\n\nEven if \npstoedit\n is used, this creates a problem when trying to cut out shapes in the correct order.  \nclipcli\n has an option to print out polygons in 'tree' order which should print the inner polygons first.\n\n\nI'll be using some of the tools that I've created below to rescale/etc. but in theory anything could be used, including (maybe the more standard and robust?) \ngrecode\n as linked above.\n\n\n\n\nThe following is an example script to convert an input SVG file into GCode:\n\n\ninpsvg=\n$1\n\nsf=`echo '72/25.4' | bc -l`\npremul=`echo 1000000 | bc -l`\ninvmul=`echo \n1/$premul\n | bc -l`\n\nfrapid=\n\nfslow=\nF800\n\nS=\n1.0\n\n\nif [[ \n$inpsvg\n == \n ]] ; then\n  echo \nprovide input svg\n\n  exit 1\nfi\n\nrawtype=`file $inpsvg`\nchecktype=`file -b $inpsvg | cut -f1 -d' '`\nif [[ \n$checktype\n != \nSVG\n ]] ; then\n  echo -e \nfile $inpsvg is of type:\\n\\n$rawtype\\n\\nNnot an SVG file? Exiting.\\n\n\n  exit 1\nfi\n\nbn=`basename $inpsvg .svg`\n\n# causes duplicate paths otherwise\n#\nsed -i 's/fill=\n[^\n]*\n/fill=\nnone\n/g' $inpsvg\n\necho \ncreating $bn.ps\n\nrsvg-convert -f ps -o $bn.ps $inpsvg\n\npstoedit -f gnuplot $bn.ps $bn.gp\nclipcli -s $bn.gp -F -x $premul -T \n ${bn}-ord.gp\n\nsfx_slow=\n$frapid S$S\n\nsfx_rapid=\n$fslow S0\n\n\necho gp2ngc -i ${bn}-ord.gp -s \n$invmul\n --sfx-rapid \n$sfx_rapid\n --sfx-slow \n$sfx_slow\n -o ${bn}.ngc\ngp2ngc -i ${bn}-ord.gp --sfx-rapid \n$sfx_rapid\n --sfx-slow \n$sfx_slow\n | ngc_scale -s \n$invmul\n \n ${bn}.ngc\n\n\n\n\nMisc.\n\n\nIn theory, \npstoedit\n can be used to create GCode but \npstoedit\n converts to the \nRS274\n standard.  Among other things, the \nRS274\n includes variables so a substitution step needs to be involved in order to \"normalize\" to something that other GCode interpreters can understand (for example, the smoothieboard or grbl).\n\n\nThere's still the problem of polygon ordering but assuming that's not an issue, the following is a \"hacky\" script does the substitution  (no nested expressions, no non-trivial functions, run at your own risk):\n\n\n#!/usr/bin/python\n#\n# regexp substitution of variables.\n# Uses Python's \neval\n to evaluate interior\n# after variable substitution.\n#\n# AGPLv3 license\n#\nimport sys\nimport re\n\nvar_map = {}\n\n# variable decleration\n#\nvar_decl_pat = re.compile( r'\\s*#(\\d+)\\s*=\\s*([^\\s]+)\\s*(\\([^\\)]*\\))?\\s*$' )\n\n# not [], [], not []\n#\nexpr_pat = re.compile( r'([^\\[]*)\\[([^\\]]*)\\]([^\\[]*)' )\n\n# not #*, #\\d+, not #*\n#\nvar_sub_pat = re.compile( r'([^#]*)(#\\d+)([^#]*)' )\n\n# consider comments separately to avoid matching '#' and\n# other special characters\n#\ncomment_pat = re.compile( r'\\([^\\)]*\\)' )\n\nline_no = 0\nfor line in sys.stdin:\n  line_no += 1\n\n  line = line.rstrip()\n  comments = \n\n  for (comment) in re.findall(comment_pat, line):\n    comments = comments + comment\n\n  line = re.sub(comment_pat, '', line)\n  m = re.match(var_decl_pat, line)\n  if m:\n    var_map[ \n#\n + str(m.group(1)) ] = str(m.group(2))\n    continue\n\n  varsub_line = \n\n  for (pfx, var_subs, sfx) in re.findall(var_sub_pat, line):\n    if var_subs in var_map:\n      pass\n    else:\n      print \n ERROR on line\n, line_no, \n, no variable mapping for\n, var_subs\n      sys.exit(1)\n      continue\n\n    varsub_line += pfx\n    varsub_line += var_map[var_subs]\n    varsub_line += sfx\n\n  if varsub_line == \n:\n    varsub_line = line\n\n  xpr_match = re.search(expr_pat, varsub_line)\n  if not xpr_match:\n    print varsub_line + comments\n    continue\n\n  cur_line = \n\n  for (pfx, xpr, sfx) in re.findall(expr_pat, varsub_line):\n    xpr_val = eval(xpr)\n    cur_line += pfx + str(xpr_val) + sfx\n\n  print cur_line +  comments\n\n\n\n\n2016-09-19", 
            "title": "GCode Conversion"
        }, 
        {
            "location": "/GCode-Conversion/#gcode-conversion-tools", 
            "text": "At one point, I had good success with an Inkscape plugin called  Gcodetools  but\nit seems to have succumbed to bit-rot and doesn't work on my current Ubuntu installation (16.04).  I'm settling on a rough toolchain that takes some base format (PostScript/PDF/SVG/etc.), converts\nto \"GNUPlot format\" then converts to GCocde.", 
            "title": "GCode Conversion Tools"
        }, 
        {
            "location": "/GCode-Conversion/#basic-workflow", 
            "text": "Orig -  SVG    Create object in whatever tool and export to SVG  SVG  -  PS     Use  rsvg-convert  to convert from SVG to PostScript  PS   -  GP     Use  pstoedit  to convert to \"gnuplot\" polygon format  GP   -  GCode  Order the polygons properly, removing duplicate boundaries and convert to GCode using  clipcli , convert from GNUPlot format to GCode using  gp2ngc  and then rescale using other cli GCode tools.", 
            "title": "Basic Workflow"
        }, 
        {
            "location": "/GCode-Conversion/#installation", 
            "text": "Some tools of relevance are:   rsvg-convert  pstoedit  clipcli  abes_cnc_utilities  grecode   Under Ubuntu, some of the tools can be installed via:  sudo apt-get install pstoedit librsvg2-bin", 
            "title": "Installation"
        }, 
        {
            "location": "/GCode-Conversion/#conversion", 
            "text": "Though this is pretty hodge-podge, there are a few things to consider:   pstoedit  loses units when converting to  RS274  GCode.  I believe this only considers PostScript with \"pixel\" units, regardless of original units, then converts a pixel to 1/72 inches.  A post scale has to be done if using  pstoedit  to rescale to the appropriate units  Even if  pstoedit  is used, this creates a problem when trying to cut out shapes in the correct order.   clipcli  has an option to print out polygons in 'tree' order which should print the inner polygons first.  I'll be using some of the tools that I've created below to rescale/etc. but in theory anything could be used, including (maybe the more standard and robust?)  grecode  as linked above.   The following is an example script to convert an input SVG file into GCode:  inpsvg= $1 \nsf=`echo '72/25.4' | bc -l`\npremul=`echo 1000000 | bc -l`\ninvmul=`echo  1/$premul  | bc -l`\n\nfrapid= \nfslow= F800 \nS= 1.0 \n\nif [[  $inpsvg  ==   ]] ; then\n  echo  provide input svg \n  exit 1\nfi\n\nrawtype=`file $inpsvg`\nchecktype=`file -b $inpsvg | cut -f1 -d' '`\nif [[  $checktype  !=  SVG  ]] ; then\n  echo -e  file $inpsvg is of type:\\n\\n$rawtype\\n\\nNnot an SVG file? Exiting.\\n \n  exit 1\nfi\n\nbn=`basename $inpsvg .svg`\n\n# causes duplicate paths otherwise\n#\nsed -i 's/fill= [^ ]* /fill= none /g' $inpsvg\n\necho  creating $bn.ps \nrsvg-convert -f ps -o $bn.ps $inpsvg\n\npstoedit -f gnuplot $bn.ps $bn.gp\nclipcli -s $bn.gp -F -x $premul -T   ${bn}-ord.gp\n\nsfx_slow= $frapid S$S \nsfx_rapid= $fslow S0 \n\necho gp2ngc -i ${bn}-ord.gp -s  $invmul  --sfx-rapid  $sfx_rapid  --sfx-slow  $sfx_slow  -o ${bn}.ngc\ngp2ngc -i ${bn}-ord.gp --sfx-rapid  $sfx_rapid  --sfx-slow  $sfx_slow  | ngc_scale -s  $invmul    ${bn}.ngc", 
            "title": "Conversion"
        }, 
        {
            "location": "/GCode-Conversion/#misc", 
            "text": "In theory,  pstoedit  can be used to create GCode but  pstoedit  converts to the  RS274  standard.  Among other things, the  RS274  includes variables so a substitution step needs to be involved in order to \"normalize\" to something that other GCode interpreters can understand (for example, the smoothieboard or grbl).  There's still the problem of polygon ordering but assuming that's not an issue, the following is a \"hacky\" script does the substitution  (no nested expressions, no non-trivial functions, run at your own risk):  #!/usr/bin/python\n#\n# regexp substitution of variables.\n# Uses Python's  eval  to evaluate interior\n# after variable substitution.\n#\n# AGPLv3 license\n#\nimport sys\nimport re\n\nvar_map = {}\n\n# variable decleration\n#\nvar_decl_pat = re.compile( r'\\s*#(\\d+)\\s*=\\s*([^\\s]+)\\s*(\\([^\\)]*\\))?\\s*$' )\n\n# not [], [], not []\n#\nexpr_pat = re.compile( r'([^\\[]*)\\[([^\\]]*)\\]([^\\[]*)' )\n\n# not #*, #\\d+, not #*\n#\nvar_sub_pat = re.compile( r'([^#]*)(#\\d+)([^#]*)' )\n\n# consider comments separately to avoid matching '#' and\n# other special characters\n#\ncomment_pat = re.compile( r'\\([^\\)]*\\)' )\n\nline_no = 0\nfor line in sys.stdin:\n  line_no += 1\n\n  line = line.rstrip()\n  comments =  \n  for (comment) in re.findall(comment_pat, line):\n    comments = comments + comment\n\n  line = re.sub(comment_pat, '', line)\n  m = re.match(var_decl_pat, line)\n  if m:\n    var_map[  #  + str(m.group(1)) ] = str(m.group(2))\n    continue\n\n  varsub_line =  \n  for (pfx, var_subs, sfx) in re.findall(var_sub_pat, line):\n    if var_subs in var_map:\n      pass\n    else:\n      print   ERROR on line , line_no,  , no variable mapping for , var_subs\n      sys.exit(1)\n      continue\n\n    varsub_line += pfx\n    varsub_line += var_map[var_subs]\n    varsub_line += sfx\n\n  if varsub_line ==  :\n    varsub_line = line\n\n  xpr_match = re.search(expr_pat, varsub_line)\n  if not xpr_match:\n    print varsub_line + comments\n    continue\n\n  cur_line =  \n  for (pfx, xpr, sfx) in re.findall(expr_pat, varsub_line):\n    xpr_val = eval(xpr)\n    cur_line += pfx + str(xpr_val) + sfx\n\n  print cur_line +  comments", 
            "title": "Misc."
        }, 
        {
            "location": "/GCode-Conversion/#2016-09-19", 
            "text": "", 
            "title": "2016-09-19"
        }, 
        {
            "location": "/Git-Rename-Master/", 
            "text": "Renaming \nmaster\n branch to \nrelease\n\n\nFrom \nAdam Dymitruk on SO\n\n\ngit checkout -b release master    # create and switch to the release branch\ngit push -u origin release        # push the release branch to the remote and track it\ngit branch -d master              # delete local master\n\n\n\n\nIf you're using GitHub (as I am), issuing the next needed command (\ngit push --delete origin master\n) will\nfail because GitHub won't let you delete the default branch, which is stil \nmaster\n.\n\n\nIn order to successfully be able to delete the remote \nmaster\n branch, you have to set the default\nbranch on GitHub to be the newly created branch (i.e. \nrelease\n).\n\n\n\n\nAfter the default branch has been changed to the newly created branch (\nrelease\n in this case), issuing\nthe following commands will now work:\n\n\ngit push --delete origin master   # delete remote master\ngit remote prune origin           # delete the remote tracking branch\n\n\n\n\nNOTE\n\n\nApparantly GitHub does not allow wikis to be anything other than the master branch.\nThis is why I had to move to my own hosting service to continue this dev blog.\n\n\n2016-09-21", 
            "title": "Git Rename Master"
        }, 
        {
            "location": "/Git-Rename-Master/#renaming-master-branch-to-release", 
            "text": "From  Adam Dymitruk on SO  git checkout -b release master    # create and switch to the release branch\ngit push -u origin release        # push the release branch to the remote and track it\ngit branch -d master              # delete local master  If you're using GitHub (as I am), issuing the next needed command ( git push --delete origin master ) will\nfail because GitHub won't let you delete the default branch, which is stil  master .  In order to successfully be able to delete the remote  master  branch, you have to set the default\nbranch on GitHub to be the newly created branch (i.e.  release ).   After the default branch has been changed to the newly created branch ( release  in this case), issuing\nthe following commands will now work:  git push --delete origin master   # delete remote master\ngit remote prune origin           # delete the remote tracking branch", 
            "title": "Renaming master branch to release"
        }, 
        {
            "location": "/Git-Rename-Master/#note", 
            "text": "Apparantly GitHub does not allow wikis to be anything other than the master branch.\nThis is why I had to move to my own hosting service to continue this dev blog.", 
            "title": "NOTE"
        }, 
        {
            "location": "/Git-Rename-Master/#2016-09-21", 
            "text": "", 
            "title": "2016-09-21"
        }, 
        {
            "location": "/MkDocs-Quickstart/", 
            "text": "MkDocs Static Site - Quickstart\n\n\nsudo pip install mkdocs\nmkdocs new $site\ncd $site\n\n\n\n\nAssume the following all work under \n$site\n.\n\n\nCreate the directory structure:\n\n\nmkdir dev_theme dev_theme/css dev_theme/js\nwget https://raw.githubusercontent.com/abetusk/minimal/master/stylesheets/pygment_trac.css -O dev_theme/css/pygment_trac.css\nwget https://raw.githubusercontent.com/abetusk/minimal/master/stylesheets/styles.css -O dev_theme/css/styles.css\nwget https://raw.githubusercontent.com/abetusk/minimal/master/javascripts/scale.fix.js -O dev_theme/js/scale.fix.js\n\n\n\n\nmkdocs.yml\n using the \nminimal theme\n:\n\n\nsite_name: dev\npages:\n  - index.md\n  - \nTextile-Cheat-Sheet.md\n\n  - \nImage-Resize.md\n\n  - \nScreenshots-Screencasts-Animated-Gifs.md\n\n  - \nffmpeg-notes.md\n\n  - \nUnix-y-notes.md\n\n  - \nlattice-reduction.md\n\n  - \nGCode-Conversion.md\n\n  - \nGit-Rename-Master.md\n\n  - \nMkDocs-Quickstart.md\n\n\ndocs_dir: 'wiki'\ntheme_dir: 'dev_theme'\nextra:\n  base : \n/dev/\n\n\n\n\n\nMkDocs uses \njinja2\n for\ntemplates.\n\n\nTo test (note, you need to change \nconfig.extra.base\n for this setup):\n\n\nmkdocs serve\n\n\n\n\nTo build the static site in the \nsite\n subdir:\n\n\nmkdocs build\n\n\n\n\n2016-09-28", 
            "title": "MkDocs Quickstart"
        }, 
        {
            "location": "/MkDocs-Quickstart/#mkdocs-static-site-quickstart", 
            "text": "sudo pip install mkdocs\nmkdocs new $site\ncd $site  Assume the following all work under  $site .  Create the directory structure:  mkdir dev_theme dev_theme/css dev_theme/js\nwget https://raw.githubusercontent.com/abetusk/minimal/master/stylesheets/pygment_trac.css -O dev_theme/css/pygment_trac.css\nwget https://raw.githubusercontent.com/abetusk/minimal/master/stylesheets/styles.css -O dev_theme/css/styles.css\nwget https://raw.githubusercontent.com/abetusk/minimal/master/javascripts/scale.fix.js -O dev_theme/js/scale.fix.js  mkdocs.yml  using the  minimal theme :  site_name: dev\npages:\n  - index.md\n  -  Textile-Cheat-Sheet.md \n  -  Image-Resize.md \n  -  Screenshots-Screencasts-Animated-Gifs.md \n  -  ffmpeg-notes.md \n  -  Unix-y-notes.md \n  -  lattice-reduction.md \n  -  GCode-Conversion.md \n  -  Git-Rename-Master.md \n  -  MkDocs-Quickstart.md \n\ndocs_dir: 'wiki'\ntheme_dir: 'dev_theme'\nextra:\n  base :  /dev/   MkDocs uses  jinja2  for\ntemplates.  To test (note, you need to change  config.extra.base  for this setup):  mkdocs serve  To build the static site in the  site  subdir:  mkdocs build", 
            "title": "MkDocs Static Site - Quickstart"
        }, 
        {
            "location": "/MkDocs-Quickstart/#2016-09-28", 
            "text": "", 
            "title": "2016-09-28"
        }, 
        {
            "location": "/GPG-Notes/", 
            "text": "Install Dependencies\n\n\nsudo apt-get install gpa gnupg2\n\n\n\n\nGenerate Key Pair\n\n\ngpg --gen-key\n\n\n\n\nSuggestions\n\n\n\n\nUse \nRSA and RSA\n (the default)\n\n\nUse \n4096\n bits for the keysize\n\n\nChoose no expiration for key (\n0\n option, default)\n\n\n\n\nNote: \nReal name\n, \nEmail address\n, \nComment\n and \npassphrase\n are needed.\n\n\nList Keys\n\n\ngpg --list-keys\n\n\n\n\nExport ASCII Public Key\n\n\ngpg --armor --export user@example.com\n\n\n\n\nExport Binary Public Key\n\n\ngpg --output user.gpg --export user@example.com\n\n\n\n\nExport Private Key (careful)\n\n\ngpg --export-secret-key -a user@example.net \n private.key\n\n\n\n\nAdd Binary Public Key\n\n\ngpg --import friend.gpg\n\n\n\n\nAdd Private Key\n\n\ngpg --import private.key\n\n\n\n\nEncrypt Message\n\n\ngpg -e -u \nSender ID\n -r \nRecipient ID\n plaintext-message\n\n\n\n\n'human readable' ASCII armor encrypted message:\n\n\ngpg -a -e -u \nSender ID\n -r \nRecipient ID\n plaintext-message\n\n\n\n\nDecrypt Message\n\n\ngpg -d encrypted-message\n\n\n\n\nFin\n\n\ngpg --armor --export abetusk@mechaelephant.com\n\n\n\n\n-----BEGIN PGP PUBLIC KEY BLOCK-----\nVersion: GnuPG v1\n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\nIPY2\n=tdhS\n-----END PGP PUBLIC KEY BLOCK-----\n\n\n\n\n2017-02-09", 
            "title": "GPG Notes"
        }, 
        {
            "location": "/GPG-Notes/#install-dependencies", 
            "text": "sudo apt-get install gpa gnupg2", 
            "title": "Install Dependencies"
        }, 
        {
            "location": "/GPG-Notes/#generate-key-pair", 
            "text": "gpg --gen-key", 
            "title": "Generate Key Pair"
        }, 
        {
            "location": "/GPG-Notes/#suggestions", 
            "text": "Use  RSA and RSA  (the default)  Use  4096  bits for the keysize  Choose no expiration for key ( 0  option, default)   Note:  Real name ,  Email address ,  Comment  and  passphrase  are needed.", 
            "title": "Suggestions"
        }, 
        {
            "location": "/GPG-Notes/#list-keys", 
            "text": "gpg --list-keys", 
            "title": "List Keys"
        }, 
        {
            "location": "/GPG-Notes/#export-ascii-public-key", 
            "text": "gpg --armor --export user@example.com", 
            "title": "Export ASCII Public Key"
        }, 
        {
            "location": "/GPG-Notes/#export-binary-public-key", 
            "text": "gpg --output user.gpg --export user@example.com", 
            "title": "Export Binary Public Key"
        }, 
        {
            "location": "/GPG-Notes/#export-private-key-careful", 
            "text": "gpg --export-secret-key -a user@example.net   private.key", 
            "title": "Export Private Key (careful)"
        }, 
        {
            "location": "/GPG-Notes/#add-binary-public-key", 
            "text": "gpg --import friend.gpg", 
            "title": "Add Binary Public Key"
        }, 
        {
            "location": "/GPG-Notes/#add-private-key", 
            "text": "gpg --import private.key", 
            "title": "Add Private Key"
        }, 
        {
            "location": "/GPG-Notes/#encrypt-message", 
            "text": "gpg -e -u  Sender ID  -r  Recipient ID  plaintext-message  'human readable' ASCII armor encrypted message:  gpg -a -e -u  Sender ID  -r  Recipient ID  plaintext-message", 
            "title": "Encrypt Message"
        }, 
        {
            "location": "/GPG-Notes/#decrypt-message", 
            "text": "gpg -d encrypted-message", 
            "title": "Decrypt Message"
        }, 
        {
            "location": "/GPG-Notes/#fin", 
            "text": "gpg --armor --export abetusk@mechaelephant.com  -----BEGIN PGP PUBLIC KEY BLOCK-----\nVersion: GnuPG v1\n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\nIPY2\n=tdhS\n-----END PGP PUBLIC KEY BLOCK-----", 
            "title": "Fin"
        }, 
        {
            "location": "/GPG-Notes/#2017-02-09", 
            "text": "", 
            "title": "2017-02-09"
        }, 
        {
            "location": "/Git-Notes/", 
            "text": "Git User Settings\n\n\nLocal:\n\n\n$ git config user.name\nabevoid\n$ git config user.email\nabevoid@abevoid.com\n$ git config user.name abetusk\nabetusk\n$ git config user.email abetusk@mechaelephant.com\nabetusk@mechaelephant.com\n$ git config user.name\nabetusk\n$ git config user.email\nabetusk@mechaelephant.com\n\n\n\n\nGlobal:\n\n\n$ git config --global user.name\nabevoid\n$ git config --global user.email\nabevoid@abevoid.com\n$ git config --global user.name abetusk\nabetusk\n$ git config --global user.email abetusk@mechaelephant.com\nabetusk@mechaelephant.com\n$ git config --global user.name\nabetusk\n$ git config --global user.email\nabetusk@mechaelephant.com\n\n\n\n\nGit Log\n\n\ngit log --decorate=full --graph\n\n\n\n\nMerge Branches and Keep DAG History\n\n\ngit checkout -b alt-branch\n...\ngit commit\ngit checkout fin-branch\ngit merge --no-ff alt-branch\n\n\n\n\nCreating and Deleting Branches\n\n\ngit checkout -b x-branch\n...\ngit commit \ngit push -u origin x-branch\ngit checkout release\ngit merge --no-ff x-branch\ngit commit \ngit push\n...\ngit branch -d x-branch\ngit push origin :x-branch\n\n\n\n\nDestroy Local Changes To Files\n\n\ngit fetch ; git reset --hard origin/release\n\n\n\n\nMove Local Changes to New Branch\n\n\ngit branch newbranch\ngit reset --hard origin/master\ngit checkout newbranch\n\n\n\n\nCreate a branch but don't switch to it.\nRemove local commits back to \norigin/master\n.\nNow switch to the new branch and continue work.\n\n\nComparing Changes\n\n\nLocal changes since last commit:\n\n\ngit diff\n\n\n\n\nTwo commits ago:\n\n\ngit diff HEAD^^\n\n\n\n\nor:\n\n\ngit diff HEAD@{2}\n\n\n\n\nRestore File\n\n\nSingle file:\n\n\ngit checkout -- fn\n\n\n\n\nEverything in a repo:\n\n\n#!/bin/bash\n\nfor f in `git ls-files -d`\ndo\n\n  echo restoring $f\n  git checkout -- $f\n\ndone\n\n\n\n\nCaching Git Password\n\n\ngit config --global credentail.helper 'cache --timeout=3600'\n\n\n\n\nClear Git Credential Cache (Clear Git Cached Password)\n\n\ngit credential-cache exit\n\n\n\n\nTracking Remote Branch\n\n\ngit remote add origin https://github.com/user/repo.git\n\n\n\n\ngit remote -v\n\n\n\n\nChecking Out Submodules\n\n\ngit clone --recursive https://github.com/user/repo\n\n\n\n\ngit submodule update --init --recursive\n\n\n\n\nApplying Inverse\n\n\nCreate (add) a new commit that applies the inverse operation of the given \nSHA\n.\n\n\ngit revert \nSHA\n\n\n\n\n\nReferences\n\n\n\n\nHow to undo (almost) anything with Git\n\n\n\n\n2017-02-10", 
            "title": "Git Notes"
        }, 
        {
            "location": "/Git-Notes/#git-user-settings", 
            "text": "Local:  $ git config user.name\nabevoid\n$ git config user.email\nabevoid@abevoid.com\n$ git config user.name abetusk\nabetusk\n$ git config user.email abetusk@mechaelephant.com\nabetusk@mechaelephant.com\n$ git config user.name\nabetusk\n$ git config user.email\nabetusk@mechaelephant.com  Global:  $ git config --global user.name\nabevoid\n$ git config --global user.email\nabevoid@abevoid.com\n$ git config --global user.name abetusk\nabetusk\n$ git config --global user.email abetusk@mechaelephant.com\nabetusk@mechaelephant.com\n$ git config --global user.name\nabetusk\n$ git config --global user.email\nabetusk@mechaelephant.com", 
            "title": "Git User Settings"
        }, 
        {
            "location": "/Git-Notes/#git-log", 
            "text": "git log --decorate=full --graph", 
            "title": "Git Log"
        }, 
        {
            "location": "/Git-Notes/#merge-branches-and-keep-dag-history", 
            "text": "git checkout -b alt-branch\n...\ngit commit\ngit checkout fin-branch\ngit merge --no-ff alt-branch", 
            "title": "Merge Branches and Keep DAG History"
        }, 
        {
            "location": "/Git-Notes/#creating-and-deleting-branches", 
            "text": "git checkout -b x-branch\n...\ngit commit \ngit push -u origin x-branch\ngit checkout release\ngit merge --no-ff x-branch\ngit commit \ngit push\n...\ngit branch -d x-branch\ngit push origin :x-branch", 
            "title": "Creating and Deleting Branches"
        }, 
        {
            "location": "/Git-Notes/#destroy-local-changes-to-files", 
            "text": "git fetch ; git reset --hard origin/release", 
            "title": "Destroy Local Changes To Files"
        }, 
        {
            "location": "/Git-Notes/#move-local-changes-to-new-branch", 
            "text": "git branch newbranch\ngit reset --hard origin/master\ngit checkout newbranch  Create a branch but don't switch to it.\nRemove local commits back to  origin/master .\nNow switch to the new branch and continue work.", 
            "title": "Move Local Changes to New Branch"
        }, 
        {
            "location": "/Git-Notes/#comparing-changes", 
            "text": "Local changes since last commit:  git diff  Two commits ago:  git diff HEAD^^  or:  git diff HEAD@{2}", 
            "title": "Comparing Changes"
        }, 
        {
            "location": "/Git-Notes/#restore-file", 
            "text": "Single file:  git checkout -- fn  Everything in a repo:  #!/bin/bash\n\nfor f in `git ls-files -d`\ndo\n\n  echo restoring $f\n  git checkout -- $f\n\ndone", 
            "title": "Restore File"
        }, 
        {
            "location": "/Git-Notes/#caching-git-password", 
            "text": "git config --global credentail.helper 'cache --timeout=3600'", 
            "title": "Caching Git Password"
        }, 
        {
            "location": "/Git-Notes/#clear-git-credential-cache-clear-git-cached-password", 
            "text": "git credential-cache exit", 
            "title": "Clear Git Credential Cache (Clear Git Cached Password)"
        }, 
        {
            "location": "/Git-Notes/#tracking-remote-branch", 
            "text": "git remote add origin https://github.com/user/repo.git  git remote -v", 
            "title": "Tracking Remote Branch"
        }, 
        {
            "location": "/Git-Notes/#checking-out-submodules", 
            "text": "git clone --recursive https://github.com/user/repo  git submodule update --init --recursive", 
            "title": "Checking Out Submodules"
        }, 
        {
            "location": "/Git-Notes/#applying-inverse", 
            "text": "Create (add) a new commit that applies the inverse operation of the given  SHA .  git revert  SHA", 
            "title": "Applying Inverse"
        }, 
        {
            "location": "/Git-Notes/#references", 
            "text": "How to undo (almost) anything with Git", 
            "title": "References"
        }, 
        {
            "location": "/Git-Notes/#2017-02-10", 
            "text": "", 
            "title": "2017-02-10"
        }, 
        {
            "location": "/Shannon-Entropy/", 
            "text": "Shannon Entropy\n\n\nClaude E. Shannon's book, \"The Mathematical Theory of Communication\", is\nvery accessible.  The main points about how entropy is defined and derived\nalong with the \"Fundamental Theorem for a Discrete Channel With Noise\" is\ndigested below.\n\n\nEntropy\n\n\nEntropy can be defined as the number of bits it takes to describe a system.\n\n\nGiven $n$ symbols, each occurring with probability $p_k$ for $k \\in (0, 1, \\dots, n-1)$,\nwe ask how many configurations are there for a very long message, say of $T$\ntransmitted symbols.\n\n\nFor the sake of clarity, we assume $T$ large and $T \\cdot p_k \\cdot n$ is integral.\n\n\nThe number of ways to arrange $T \\cdot n$ elements comprised of $n$ symbols each\noccurring with $T \\cdot p_k \\cdot n$ frequency is the multinomial:\n\n\n$$ { T \\cdot n \\choose (T \\cdot p_0 \\cdot n), (T \\cdot p_1 \\cdot n), \\dots, (T \\cdot p_{n-1} \\cdot n) } $$\n$$ = \\frac{(T \\cdot n)!}{\\prod_{k=0}^{n-1} (T \\cdot p_k \\cdot n)!} $$\n\n\nIf we concern ourselves with the bits it takes to represent the total number of\nconfigurations, we find (where $\\lg(\\cdot) = \\log_2(\\cdot)$):\n\n\n$$ \\lg( \\frac{(T \\cdot n)!}{\\prod_{k=0}^{n-1} (T \\cdot p_k \\cdot n)!} ) $$\n$$ = \\lg( (T \\cdot n)! ) - \\sum_{k=0}^{n-1} \\lg( (T \\cdot p_k \\cdot n)! ) $$\n\n\n$$ \\approx (T \\cdot n) lg( T \\cdot n ) - (T \\cdot n) - \\sum_{k=0}^{n-1} [ (T \\cdot p_k \\cdot n) \\lg(T \\cdot p_k \\cdot n) - (T \\cdot p_k \\cdot n) ] $$\n\n\nBy definition, $\\sum_{k=0}^{n-1} p_k = 1$, we can reduce to find:\n\n\n$$ = - T \\sum_{k=0}^{n-1} p_k \\lg(p_k) $$\n\n\nWe define $H$ to be our entropy, the average number of bits needed to represent our system.\nSince the above is the total number of bits needed, we divide by $T$ to find the average:\n\n\n$$ H = - \\sum_{k=0}^{n-1} p_k \\lg(p_k) $$\n\n\nTransmission Over a Noisy Channel\n\n\nIf we transmit $H$ bits per symbol over a noisy line and assume each symbol's error\nover the line is independent, label the number of bits, whole or partial, that succumb\nto error as $r$.\nThat is, of the $H$ bits per symbol, $r$ are 'eaten' by noise in the channel.\n\n\nCall the channel capacity $C = H - r$.\nThis is the number of useful bits that remain after we take away the noise from\nthe number of bits needed to encode symbols.\n\n\nAs above, consider a long message of $T$ transmitted symbols.\nFirst allocate some bits for error correction and choose $S$ such that:\n\n\n$$ S \n C = H - r $$\n\n\nFurther\n\n\n$$ S = C - \\eta = H - r - \\eta $$\n\n\nWhere the number of error correcting bits is just shy of $T \\cdot \\eta$.\nChoose codewords in the source representation so that there are\n$2^{T \\cdot S}$ codewords that sit in $2^{T \\cdot H}$ total\nconfigurations.\n\n\nSent messages will be from the restricted set of codewords and has\nprobability:\n\n\n$$ \\frac{2^{T \\cdot S}}{2^{T \\cdot H}} = 2^{T \\cdot (S - H)} $$\n\n\nA received message of $T \\cdot H$ bits long will have $T \\cdot r$\ncorrupted by error.\nThe number of possible source configurations that could have sent\nthe received message is:\n\n\n$$ 2^{T \\cdot r} $$\n\n\nThe probability that there is another codeword in the $2^{T \\cdot r}$\nnumber of theoretical sent messages, aside from the source codeword,\nis the probability that none of the other codewords are hit:\n\n\n$$ [ 1 - 2^{ T \\cdot (S - H) } ]^{ 2^{T \\cdot r} } $$\n$$ = [ 1 - \\frac{2^{ -T \\cdot \\eta}}{2^{T \\cdot r}} ]^{2^{T \\cdot r}} $$\n\n\nAs $T$ becomes large:\n\n\n$$ \\approx e^{ -2^{ -T \\cdot \\eta } } $$\n$$ = 1 - 2^{ -T \\cdot \\eta } + O( 2^{-2 \\cdot T \\cdot \\eta} ) $$\n$$ \\approx 1 - 2^{ -T \\cdot \\eta } $$\n\n\nWhich approaches 0.\n\n\nSo the chance of our transmitted encoded codeword being mistaken for\nanother codeword is vanishingly small.\nAs long as we choose $S$ to be less than the channel capacity $C$ and\nthe message is long enough ($T$ is big enough) we have a low chance\nof a source codeword colliding after transmission with a channel error\nrate of $r$.\n\n\n2017-06-12", 
            "title": "Shannon Entropy"
        }, 
        {
            "location": "/Shannon-Entropy/#shannon-entropy", 
            "text": "Claude E. Shannon's book, \"The Mathematical Theory of Communication\", is\nvery accessible.  The main points about how entropy is defined and derived\nalong with the \"Fundamental Theorem for a Discrete Channel With Noise\" is\ndigested below.", 
            "title": "Shannon Entropy"
        }, 
        {
            "location": "/Shannon-Entropy/#entropy", 
            "text": "Entropy can be defined as the number of bits it takes to describe a system.  Given $n$ symbols, each occurring with probability $p_k$ for $k \\in (0, 1, \\dots, n-1)$,\nwe ask how many configurations are there for a very long message, say of $T$\ntransmitted symbols.  For the sake of clarity, we assume $T$ large and $T \\cdot p_k \\cdot n$ is integral.  The number of ways to arrange $T \\cdot n$ elements comprised of $n$ symbols each\noccurring with $T \\cdot p_k \\cdot n$ frequency is the multinomial:  $$ { T \\cdot n \\choose (T \\cdot p_0 \\cdot n), (T \\cdot p_1 \\cdot n), \\dots, (T \\cdot p_{n-1} \\cdot n) } $$\n$$ = \\frac{(T \\cdot n)!}{\\prod_{k=0}^{n-1} (T \\cdot p_k \\cdot n)!} $$  If we concern ourselves with the bits it takes to represent the total number of\nconfigurations, we find (where $\\lg(\\cdot) = \\log_2(\\cdot)$):  $$ \\lg( \\frac{(T \\cdot n)!}{\\prod_{k=0}^{n-1} (T \\cdot p_k \\cdot n)!} ) $$\n$$ = \\lg( (T \\cdot n)! ) - \\sum_{k=0}^{n-1} \\lg( (T \\cdot p_k \\cdot n)! ) $$  $$ \\approx (T \\cdot n) lg( T \\cdot n ) - (T \\cdot n) - \\sum_{k=0}^{n-1} [ (T \\cdot p_k \\cdot n) \\lg(T \\cdot p_k \\cdot n) - (T \\cdot p_k \\cdot n) ] $$  By definition, $\\sum_{k=0}^{n-1} p_k = 1$, we can reduce to find:  $$ = - T \\sum_{k=0}^{n-1} p_k \\lg(p_k) $$  We define $H$ to be our entropy, the average number of bits needed to represent our system.\nSince the above is the total number of bits needed, we divide by $T$ to find the average:  $$ H = - \\sum_{k=0}^{n-1} p_k \\lg(p_k) $$", 
            "title": "Entropy"
        }, 
        {
            "location": "/Shannon-Entropy/#transmission-over-a-noisy-channel", 
            "text": "If we transmit $H$ bits per symbol over a noisy line and assume each symbol's error\nover the line is independent, label the number of bits, whole or partial, that succumb\nto error as $r$.\nThat is, of the $H$ bits per symbol, $r$ are 'eaten' by noise in the channel.  Call the channel capacity $C = H - r$.\nThis is the number of useful bits that remain after we take away the noise from\nthe number of bits needed to encode symbols.  As above, consider a long message of $T$ transmitted symbols.\nFirst allocate some bits for error correction and choose $S$ such that:  $$ S   C = H - r $$  Further  $$ S = C - \\eta = H - r - \\eta $$  Where the number of error correcting bits is just shy of $T \\cdot \\eta$.\nChoose codewords in the source representation so that there are\n$2^{T \\cdot S}$ codewords that sit in $2^{T \\cdot H}$ total\nconfigurations.  Sent messages will be from the restricted set of codewords and has\nprobability:  $$ \\frac{2^{T \\cdot S}}{2^{T \\cdot H}} = 2^{T \\cdot (S - H)} $$  A received message of $T \\cdot H$ bits long will have $T \\cdot r$\ncorrupted by error.\nThe number of possible source configurations that could have sent\nthe received message is:  $$ 2^{T \\cdot r} $$  The probability that there is another codeword in the $2^{T \\cdot r}$\nnumber of theoretical sent messages, aside from the source codeword,\nis the probability that none of the other codewords are hit:  $$ [ 1 - 2^{ T \\cdot (S - H) } ]^{ 2^{T \\cdot r} } $$\n$$ = [ 1 - \\frac{2^{ -T \\cdot \\eta}}{2^{T \\cdot r}} ]^{2^{T \\cdot r}} $$  As $T$ becomes large:  $$ \\approx e^{ -2^{ -T \\cdot \\eta } } $$\n$$ = 1 - 2^{ -T \\cdot \\eta } + O( 2^{-2 \\cdot T \\cdot \\eta} ) $$\n$$ \\approx 1 - 2^{ -T \\cdot \\eta } $$  Which approaches 0.  So the chance of our transmitted encoded codeword being mistaken for\nanother codeword is vanishingly small.\nAs long as we choose $S$ to be less than the channel capacity $C$ and\nthe message is long enough ($T$ is big enough) we have a low chance\nof a source codeword colliding after transmission with a channel error\nrate of $r$.", 
            "title": "Transmission Over a Noisy Channel"
        }, 
        {
            "location": "/Shannon-Entropy/#2017-06-12", 
            "text": "", 
            "title": "2017-06-12"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/", 
            "text": "Enabling HTTPS Using Let's Encrypt\n\n\nLet's Encrypt\n is a certificate authority that\ngives out digital certificates to the community free of charge.\n\n\nUsing thir \n\"shell access\"\n method,\none can install a program called \ncertbot\n that\ngives quick start instructions for installing and running certbot to\nissue a certificate for your host and system.\n\n\nDetailed below is what I did for some of my servers (HAProxy on Ubuntu and\nApache on Ubuntu).\n\n\nHAProxy on Ubuntu\n\n\nsudo apt-get install software-properties-common\nsudo add-apt-repository ppa:certbot/certbot\nsudo apt-get update\nsudo apt-get install certbot \n\n\n\n\ncertbot certonly --webroot -w /var/www -d meowcad.com -d www.meowcad.com\n\n\n\n\nI had to create a \nmeow.pem\n for my version of HAProxy to work:\n\n\ncd /etc/letsencrypt/live/meowcad.com\ncat private.pem fullchain.pem \n meow.pem\n\n\n\n\nApache on Ubuntu\n\n\nsudo apt-get install software-properties-common\nsudo add-apt-repository ppa:certbot/certbot\nsudo apt-get update\nsudo apt-get install python-certbot-apache \n\n\n\n\ncertbot certonly -n --agree-tos --email $EMAIL --domain mechaelephant.com --domain www.mechaelephant.com --webroot --webroot-path /var/www/  --expand\n\n\n\n\nNotes\n\n\n\n\nMake sure to add the extra domain so that both \nwww.domain.com\n and \ndomain.com\n work.\n\n\nIf you've already issued a certificate and want to add a domain like I needed to for \nwww.mechalephant.com\n, adding the domain \nmechaelephant.com\n because\n  I forgot the non \nwww\n prefixed web page, then I think the \n--expand\n flag will work to add an additional domain.\n\n\nI'm still not sure how to renew or automatically renew the certs...\n\n\n\n\n2017-06-12", 
            "title": "Enabling Server HTTPS"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/#enabling-https-using-lets-encrypt", 
            "text": "Let's Encrypt  is a certificate authority that\ngives out digital certificates to the community free of charge.  Using thir  \"shell access\"  method,\none can install a program called  certbot  that\ngives quick start instructions for installing and running certbot to\nissue a certificate for your host and system.  Detailed below is what I did for some of my servers (HAProxy on Ubuntu and\nApache on Ubuntu).", 
            "title": "Enabling HTTPS Using Let's Encrypt"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/#haproxy-on-ubuntu", 
            "text": "sudo apt-get install software-properties-common\nsudo add-apt-repository ppa:certbot/certbot\nsudo apt-get update\nsudo apt-get install certbot   certbot certonly --webroot -w /var/www -d meowcad.com -d www.meowcad.com  I had to create a  meow.pem  for my version of HAProxy to work:  cd /etc/letsencrypt/live/meowcad.com\ncat private.pem fullchain.pem   meow.pem", 
            "title": "HAProxy on Ubuntu"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/#apache-on-ubuntu", 
            "text": "sudo apt-get install software-properties-common\nsudo add-apt-repository ppa:certbot/certbot\nsudo apt-get update\nsudo apt-get install python-certbot-apache   certbot certonly -n --agree-tos --email $EMAIL --domain mechaelephant.com --domain www.mechaelephant.com --webroot --webroot-path /var/www/  --expand", 
            "title": "Apache on Ubuntu"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/#notes", 
            "text": "Make sure to add the extra domain so that both  www.domain.com  and  domain.com  work.  If you've already issued a certificate and want to add a domain like I needed to for  www.mechalephant.com , adding the domain  mechaelephant.com  because\n  I forgot the non  www  prefixed web page, then I think the  --expand  flag will work to add an additional domain.  I'm still not sure how to renew or automatically renew the certs...", 
            "title": "Notes"
        }, 
        {
            "location": "/Enabling-Server-HTTPS/#2017-06-12", 
            "text": "", 
            "title": "2017-06-12"
        }, 
        {
            "location": "/BGZF-Example/", 
            "text": "BGZF Example\n\n\nBGZIP\n allows for quick random access to a \nbgzip\n file by creating an index.\nAs an example, here is a way to compress a file with \nbgzip\n and access a random\nportion of it:\n\n\n$ ls -la\ntotal 685104\ndrwxrwxr-x 2 abetusk abetusk      4096 Jun 12 17:33 .\ndrwxrwxr-x 5 abetusk abetusk      4096 Jun 12 17:33 ..\n-rw-rw-r-- 1 abetusk abetusk 701533731 Jun 12 17:33 hu826751.gff\n$ bgzip -i hu826751.gff \n$ ls\nhu826751.gff.gz  hu826751.gff.gz.gzi\n$ bgzip -h\n\nVersion: 1.4.1\nUsage:   bgzip [OPTIONS] [FILE] ...\nOptions:\n   -b, --offset INT        decompress at virtual file pointer (0-based uncompressed offset)\n   -c, --stdout            write on standard output, keep original files unchanged\n   -d, --decompress        decompress\n   -f, --force             overwrite files without asking\n   -h, --help              give this help\n   -i, --index             compress and create BGZF index\n   -I, --index-name FILE   name of BGZF index file [file.gz.gzi]\n   -r, --reindex           (re)index compressed file\n   -g, --rebgzip           use an index file to bgzip a file\n   -s, --size INT          decompress INT bytes (uncompressed size)\n   -@, --threads INT       number of compression threads to use [1]\n\n$ time bgzip -b 100000000 -s 100 hu826751.gff.gz\n54      .       +       .       alleles C/T;db_xref dbsnp.120:rs11035863;ref_allele C\nchr11   CGI     REF     40509955        40510029        .       +       .\nreal    0m0.009s\nuser    0m0.004s\nsys     0m0.004s\n\n\n\n\nC Example\n\n\nHere's a \nC\n example:\n\n\n#include \nstdio.h\n\n#include \nstdlib.h\n\n#include \nstdint.h\n\n\n#include \nbgzf.h\n\n\n#include \nvector\n\n#include \nstring\n\n\nint main(int argc, char **argv) {\n  int i, j, k, r;\n  BGZF *bgzfp;\n  std::string ifn, idx_fn;\n  int64_t pos=-1;\n  char buf[1024];\n  ssize_t s;\n  size_t buflen=1024;\n\n  if (argc\n2) {\n    printf(\nprovide bgzip file\\n\n);\n    exit(-1);\n  }\n  ifn = argv[1];\n\n  printf(\nloading bgzip file %s\\n\n, ifn.c_str());\n  bgzfp = bgzf_open(ifn.c_str(), \nr\n);\n  if (!bgzfp) {\n    fprintf(stderr, \nerror opening file %s\\n\n, ifn.c_str());\n    exit(1);\n  }\n\n  printf(\nloading index bgzip file %s%s\\n\n, ifn.c_str(), \n.gzi\n);\n  r = bgzf_index_load(bgzfp, ifn.c_str(), \n.gzi\n);\n  printf(\ngot %i\\n\n, r);\n\n  r = bgzf_useek(bgzfp, 100000000, SEEK_SET);\n  printf(\ngot %i\\n\n, r);\n  if (r\n0) {\n    perror(\n...\n);\n    exit(-1);\n  }\n  s = bgzf_read(bgzfp, buf, sizeof(char)*buflen);\n  printf(\n...%i\\n\n, (int)s);\n\n  printf(\n---\\n\n);\n  for (i=0; i\ns; i++) { printf(\n%c\n, buf[i]); }\n  printf(\n\\n---\\n\n);\n\n  bgzf_close(bgzfp);\n\n}\n\n\n\n\nTo compile:\n\n\ng++ -I $HTSDIR/htslib-1.4.1/htslib -lhts bgzf-example.cpp -o bgzf-example -L $HTSLIB/htslib-1.4.1 -lhts\n\n\n\n\nTo run:\n\n\nLD_LIBRARY_PATH=$HOME/htslib-1.4.1 ./bgzf-example hu826751.gff.gz\n\n\n\n\nWhich assumes the \nhu826751.gff.gz.gzi\n file is in the same directory as the \nhu826751.gff.gz\n file.\n\n\nThis assumes \nhtslib\n is installed under the directory pointed to by the \nHTSLIB\n environment variable.\n\n\nSee the \nhtslib\n repo for details on how to download and install.\n\n\n2017-06-12", 
            "title": "BGZF Example"
        }, 
        {
            "location": "/BGZF-Example/#bgzf-example", 
            "text": "BGZIP  allows for quick random access to a  bgzip  file by creating an index.\nAs an example, here is a way to compress a file with  bgzip  and access a random\nportion of it:  $ ls -la\ntotal 685104\ndrwxrwxr-x 2 abetusk abetusk      4096 Jun 12 17:33 .\ndrwxrwxr-x 5 abetusk abetusk      4096 Jun 12 17:33 ..\n-rw-rw-r-- 1 abetusk abetusk 701533731 Jun 12 17:33 hu826751.gff\n$ bgzip -i hu826751.gff \n$ ls\nhu826751.gff.gz  hu826751.gff.gz.gzi\n$ bgzip -h\n\nVersion: 1.4.1\nUsage:   bgzip [OPTIONS] [FILE] ...\nOptions:\n   -b, --offset INT        decompress at virtual file pointer (0-based uncompressed offset)\n   -c, --stdout            write on standard output, keep original files unchanged\n   -d, --decompress        decompress\n   -f, --force             overwrite files without asking\n   -h, --help              give this help\n   -i, --index             compress and create BGZF index\n   -I, --index-name FILE   name of BGZF index file [file.gz.gzi]\n   -r, --reindex           (re)index compressed file\n   -g, --rebgzip           use an index file to bgzip a file\n   -s, --size INT          decompress INT bytes (uncompressed size)\n   -@, --threads INT       number of compression threads to use [1]\n\n$ time bgzip -b 100000000 -s 100 hu826751.gff.gz\n54      .       +       .       alleles C/T;db_xref dbsnp.120:rs11035863;ref_allele C\nchr11   CGI     REF     40509955        40510029        .       +       .\nreal    0m0.009s\nuser    0m0.004s\nsys     0m0.004s", 
            "title": "BGZF Example"
        }, 
        {
            "location": "/BGZF-Example/#c-example", 
            "text": "Here's a  C  example:  #include  stdio.h \n#include  stdlib.h \n#include  stdint.h \n\n#include  bgzf.h \n\n#include  vector \n#include  string \n\nint main(int argc, char **argv) {\n  int i, j, k, r;\n  BGZF *bgzfp;\n  std::string ifn, idx_fn;\n  int64_t pos=-1;\n  char buf[1024];\n  ssize_t s;\n  size_t buflen=1024;\n\n  if (argc 2) {\n    printf( provide bgzip file\\n );\n    exit(-1);\n  }\n  ifn = argv[1];\n\n  printf( loading bgzip file %s\\n , ifn.c_str());\n  bgzfp = bgzf_open(ifn.c_str(),  r );\n  if (!bgzfp) {\n    fprintf(stderr,  error opening file %s\\n , ifn.c_str());\n    exit(1);\n  }\n\n  printf( loading index bgzip file %s%s\\n , ifn.c_str(),  .gzi );\n  r = bgzf_index_load(bgzfp, ifn.c_str(),  .gzi );\n  printf( got %i\\n , r);\n\n  r = bgzf_useek(bgzfp, 100000000, SEEK_SET);\n  printf( got %i\\n , r);\n  if (r 0) {\n    perror( ... );\n    exit(-1);\n  }\n  s = bgzf_read(bgzfp, buf, sizeof(char)*buflen);\n  printf( ...%i\\n , (int)s);\n\n  printf( ---\\n );\n  for (i=0; i s; i++) { printf( %c , buf[i]); }\n  printf( \\n---\\n );\n\n  bgzf_close(bgzfp);\n\n}  To compile:  g++ -I $HTSDIR/htslib-1.4.1/htslib -lhts bgzf-example.cpp -o bgzf-example -L $HTSLIB/htslib-1.4.1 -lhts  To run:  LD_LIBRARY_PATH=$HOME/htslib-1.4.1 ./bgzf-example hu826751.gff.gz  Which assumes the  hu826751.gff.gz.gzi  file is in the same directory as the  hu826751.gff.gz  file.  This assumes  htslib  is installed under the directory pointed to by the  HTSLIB  environment variable.  See the  htslib  repo for details on how to download and install.", 
            "title": "C Example"
        }, 
        {
            "location": "/BGZF-Example/#2017-06-12", 
            "text": "", 
            "title": "2017-06-12"
        }, 
        {
            "location": "/Kelly-Criterion/", 
            "text": "Kelly Criterion\n\n\nThe Wikipedia article on the \nKelly criterion\n might\nsay more, but here is a simple derivation.\n\n\nAssuming you have a coin with probability $p$ of coming up heads and odds of $b:1$, the Kelly\ncriterion states:\n\n\n$$\nf^* = \\frac{bp-q}{b}\n$$\n\n\nWhere $f^*$ is the fraction of your money pot the Kelly criterion tells you to bet and $q=1-p$.\n\n\nThat is:\n\n\n$$\nf^* = \\frac{bp-(1-p)}{b} \\\n    = \\frac{p(b+1)-1}{b}\n$$\n\n\nAssuming the strategy is to bet a fraction of your bank roll every round, with $W_0$ as the initial\nbank roll, $n$ time units and $W_n$ as your winnings at time $n$:\n\n\n$$\nW_n = (1 + br)^{pn} (1 - r)^{(1-p)n} W_0\n$$\n\n\nTaking logarithms, setting the derivative with respect to $r$ and solving:\n\n\n$$\n\\begin{array}\n.   \n \\frac{d}{dr} \\ln(W_n) \n= \\frac{d}{dr} ( pn \\ln(1+br) + (1-p)n \\ln(1-r) + \\ln(W_0) ) \\\\\n\\to \n 0                   \n= \\frac{pnb}{1+br} - \\frac{(1-p)n}{1-r} \\\\\n\\to \n \\frac{(1-p)n}{1-r}  \n= \\frac{pnb}{1+br} \\\\\n\\to \n \\frac{1-p}{1-r}     \n= \\frac{pb}{1+br} \\\\\n\\to \n (1-p) (1+br)        \n= pb (1-r) \\\\\n\\to \n 1 - p + br - pbr  \n= pb - pbr \\\\\n\\to \n 1 - p + br        \n= pb \\\\\n\\to \n r                 \n= \\frac{pb + p - 1}{b} \\\\\n\\to \n r                 \n= \\frac{b(p + 1) - 1}{b} \\\\\n\\end{array}\n$$\n\n\n2017-08-18", 
            "title": "Kelly Criterion"
        }, 
        {
            "location": "/Kelly-Criterion/#kelly-criterion", 
            "text": "The Wikipedia article on the  Kelly criterion  might\nsay more, but here is a simple derivation.  Assuming you have a coin with probability $p$ of coming up heads and odds of $b:1$, the Kelly\ncriterion states:  $$\nf^* = \\frac{bp-q}{b}\n$$  Where $f^*$ is the fraction of your money pot the Kelly criterion tells you to bet and $q=1-p$.  That is:  $$\nf^* = \\frac{bp-(1-p)}{b} \\\n    = \\frac{p(b+1)-1}{b}\n$$  Assuming the strategy is to bet a fraction of your bank roll every round, with $W_0$ as the initial\nbank roll, $n$ time units and $W_n$ as your winnings at time $n$:  $$\nW_n = (1 + br)^{pn} (1 - r)^{(1-p)n} W_0\n$$  Taking logarithms, setting the derivative with respect to $r$ and solving:  $$\n\\begin{array}\n.     \\frac{d}{dr} \\ln(W_n)  = \\frac{d}{dr} ( pn \\ln(1+br) + (1-p)n \\ln(1-r) + \\ln(W_0) ) \\\\\n\\to   0                    = \\frac{pnb}{1+br} - \\frac{(1-p)n}{1-r} \\\\\n\\to   \\frac{(1-p)n}{1-r}   = \\frac{pnb}{1+br} \\\\\n\\to   \\frac{1-p}{1-r}      = \\frac{pb}{1+br} \\\\\n\\to   (1-p) (1+br)         = pb (1-r) \\\\\n\\to   1 - p + br - pbr   = pb - pbr \\\\\n\\to   1 - p + br         = pb \\\\\n\\to   r                  = \\frac{pb + p - 1}{b} \\\\\n\\to   r                  = \\frac{b(p + 1) - 1}{b} \\\\\n\\end{array}\n$$", 
            "title": "Kelly Criterion"
        }, 
        {
            "location": "/Kelly-Criterion/#2017-08-18", 
            "text": "", 
            "title": "2017-08-18"
        }, 
        {
            "location": "/C-Project-Template/", 
            "text": "Example C Project Template\n\n\nThis is a basic template for using automake tools for creating the \nconfigure\n and \nMakefile\n\nin a C/C++ program.\n\n\nRequirements\n\n\n\n\nautomake\n - e.g. \nsudo apt-get install automake\n\n\ngcc\n\n\n\n\nmain.c\n\n\n#include \nstdio.h\n\n#include \nstdlib.h\n\n\nint main(int argc, char **argv) {\n  printf(\nhello, friend\\n\n);\n}\n\n\n\n\nconfigure.in\n\n\nAC_INIT([hellofriend], [0.1], [abetusk@mechaelephant.com])\nAM_INIT_AUTOMAKE\nAC_PROG_CC\nAC_CONFIG_FILES([Makefile])\nAC_OUTPUT\n\n\n\n\nMakefile.am\n\n\nAUTOMAKE_OPTIONS = foreign\nbin_PROGRAMS = hellofriend\nhellofriend_SOURCES = main.c\n\n\n\n\nRun automake\n\n\naclocal\nautoconf\nautomake --add-missing\n\n\n\n\nconfigure, make, make install\n\n\n./configure\nmake\nmake install\n\n\n\n\nReferences\n\n\n\n\nThe magic behind configure, make, make install\n\n\n\n\n2017-08-05", 
            "title": "C Project Template"
        }, 
        {
            "location": "/C-Project-Template/#example-c-project-template", 
            "text": "This is a basic template for using automake tools for creating the  configure  and  Makefile \nin a C/C++ program.", 
            "title": "Example C Project Template"
        }, 
        {
            "location": "/C-Project-Template/#requirements", 
            "text": "automake  - e.g.  sudo apt-get install automake  gcc", 
            "title": "Requirements"
        }, 
        {
            "location": "/C-Project-Template/#mainc", 
            "text": "#include  stdio.h \n#include  stdlib.h \n\nint main(int argc, char **argv) {\n  printf( hello, friend\\n );\n}", 
            "title": "main.c"
        }, 
        {
            "location": "/C-Project-Template/#configurein", 
            "text": "AC_INIT([hellofriend], [0.1], [abetusk@mechaelephant.com])\nAM_INIT_AUTOMAKE\nAC_PROG_CC\nAC_CONFIG_FILES([Makefile])\nAC_OUTPUT", 
            "title": "configure.in"
        }, 
        {
            "location": "/C-Project-Template/#makefileam", 
            "text": "AUTOMAKE_OPTIONS = foreign\nbin_PROGRAMS = hellofriend\nhellofriend_SOURCES = main.c", 
            "title": "Makefile.am"
        }, 
        {
            "location": "/C-Project-Template/#run-automake", 
            "text": "aclocal\nautoconf\nautomake --add-missing", 
            "title": "Run automake"
        }, 
        {
            "location": "/C-Project-Template/#configure-make-make-install", 
            "text": "./configure\nmake\nmake install", 
            "title": "configure, make, make install"
        }, 
        {
            "location": "/C-Project-Template/#references", 
            "text": "The magic behind configure, make, make install", 
            "title": "References"
        }, 
        {
            "location": "/C-Project-Template/#2017-08-05", 
            "text": "", 
            "title": "2017-08-05"
        }, 
        {
            "location": "/Project-Organization/", 
            "text": "Project Organization\n\n\nThese are notes on \"best practices\" for Git project\norganization.\n\n\nDirectory Structure\n\n\n\n\n\n\n\n\nFile or Directory\n\n\nDescription\n\n\nMisc\n\n\n\n\n\n\n\n\n\n\nsrc/\n\n\nSource files.\n\n\n\n\n\n\n\n\ndist/\n or \nbin/\n\n\nShould remain empty in repo.  Populated on compilation.\n\n\n\n\n\n\n\n\ntests/\n\n\nTest suite.\n\n\n\n\n\n\n\n\nexamples/\n\n\nExample usage\n\n\n\n\n\n\n\n\nREADME.md\n\n\nProject description\n\n\n\n\n\n\n\n\nLICENSE\n\n\nLicense file for source\n\n\n\n\n\n\n\n\n.gitignore\n\n\nGit ignore file.\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nsrc/\n\n\nThe source files of the project.\n\n\ndist/\n\n\nThe destination directory for compiled source files.\nThis directory should remain empty in the main Git repo.\n\n\ntests/\n\n\nThe test suite to make sure the running code passes testing.\n\n\nexamples/\n\n\nExample usage of your program on small datasets (where applicable).\n\n\nREADME.md\n\n\nA description of the project.\nThis should contain the following, preferably in this order:\n\n\n\n\nScreenshot\n\n\nDescription of what the project is\n\n\nA \"quick start\" section\n\n\nMotivation for why the project exists\n\n\nHow to compile (if applicable)\n\n\nHow to run\n\n\nExample usage\n\n\nThe license it's under, even if you have a \nLICENSE\n file.\n  If there are multiple licenses then describe what each portion\n  of the project falls under which license or where to find that\n  information out.\n\n\nCredits (if applicable)\n\n\nReferences (if applicable)\n\n\n\n\nIf a screenshot isn't appropriate for the project (say it's a simple command line\nprogram) then either a block of test with a sample run or an arbitrary picture\nshould be used.\nIf it's unclear what to use as a screenshot, use a free/libre licensed cat picture.\n\n\nLICENSE\n\n\nThe license of the software.\nIf there are multiple licenses, some options are to make a file per license used\nwith some description either in the file or outside, as to which files in the project\nfall under which license or to concatenate all licenses into a single file.\n\n\n.gitignore\n\n\nThe files for Git to ignore.\n\n\nSome common options are :\n\n\n\n\n*~\n - ignore \nvi\n auto save files\n\n\n*.swp\n - ignore \nvi\n file lock files\n\n\n\n\nLanguage Dependent Files\n\n\nJavaScript\n\n\n\n\npackage.json\n - dependencies for your \nnpm\n package\n\n\nbower.json\n - front end dependencies for your JavaScript package\n\n\n\n\nC/C++\n\n\n\n\nconfigure.ac\n\n\nMakefile.am\n\n\nconfigure\n\n\nMakefile.in\n\n\n\n\nReferences\n\n\n\n\n\"Maintaining an Open Source Project: Project Organization\"\n by Jacob Wenger\n\n\n\n\n2017-08-05", 
            "title": "Project Organization"
        }, 
        {
            "location": "/Project-Organization/#project-organization", 
            "text": "These are notes on \"best practices\" for Git project\norganization.", 
            "title": "Project Organization"
        }, 
        {
            "location": "/Project-Organization/#directory-structure", 
            "text": "File or Directory  Description  Misc      src/  Source files.     dist/  or  bin/  Should remain empty in repo.  Populated on compilation.     tests/  Test suite.     examples/  Example usage     README.md  Project description     LICENSE  License file for source     .gitignore  Git ignore file.", 
            "title": "Directory Structure"
        }, 
        {
            "location": "/Project-Organization/#description", 
            "text": "", 
            "title": "Description"
        }, 
        {
            "location": "/Project-Organization/#src", 
            "text": "The source files of the project.", 
            "title": "src/"
        }, 
        {
            "location": "/Project-Organization/#dist", 
            "text": "The destination directory for compiled source files.\nThis directory should remain empty in the main Git repo.", 
            "title": "dist/"
        }, 
        {
            "location": "/Project-Organization/#tests", 
            "text": "The test suite to make sure the running code passes testing.", 
            "title": "tests/"
        }, 
        {
            "location": "/Project-Organization/#examples", 
            "text": "Example usage of your program on small datasets (where applicable).", 
            "title": "examples/"
        }, 
        {
            "location": "/Project-Organization/#readmemd", 
            "text": "A description of the project.\nThis should contain the following, preferably in this order:   Screenshot  Description of what the project is  A \"quick start\" section  Motivation for why the project exists  How to compile (if applicable)  How to run  Example usage  The license it's under, even if you have a  LICENSE  file.\n  If there are multiple licenses then describe what each portion\n  of the project falls under which license or where to find that\n  information out.  Credits (if applicable)  References (if applicable)   If a screenshot isn't appropriate for the project (say it's a simple command line\nprogram) then either a block of test with a sample run or an arbitrary picture\nshould be used.\nIf it's unclear what to use as a screenshot, use a free/libre licensed cat picture.", 
            "title": "README.md"
        }, 
        {
            "location": "/Project-Organization/#license", 
            "text": "The license of the software.\nIf there are multiple licenses, some options are to make a file per license used\nwith some description either in the file or outside, as to which files in the project\nfall under which license or to concatenate all licenses into a single file.", 
            "title": "LICENSE"
        }, 
        {
            "location": "/Project-Organization/#gitignore", 
            "text": "The files for Git to ignore.  Some common options are :   *~  - ignore  vi  auto save files  *.swp  - ignore  vi  file lock files", 
            "title": ".gitignore"
        }, 
        {
            "location": "/Project-Organization/#language-dependent-files", 
            "text": "", 
            "title": "Language Dependent Files"
        }, 
        {
            "location": "/Project-Organization/#javascript", 
            "text": "package.json  - dependencies for your  npm  package  bower.json  - front end dependencies for your JavaScript package", 
            "title": "JavaScript"
        }, 
        {
            "location": "/Project-Organization/#cc", 
            "text": "configure.ac  Makefile.am  configure  Makefile.in", 
            "title": "C/C++"
        }, 
        {
            "location": "/Project-Organization/#references", 
            "text": "\"Maintaining an Open Source Project: Project Organization\"  by Jacob Wenger", 
            "title": "References"
        }, 
        {
            "location": "/Project-Organization/#2017-08-05", 
            "text": "", 
            "title": "2017-08-05"
        }, 
        {
            "location": "/File-Naming-Conventions/", 
            "text": "File Naming Conventions\n\n\nThree principles:\n\n\n\n\nMachine readable\n\n\nHuman Readable\n\n\nPlays well with default ordering\n\n\n\n\nConventions\n\n\n\n\n-\n (dash) separate words in concept\n\n\n_\n (underscore) separate units of meta-data\n\n\npad numbers to allow for default file sort\n\n\nuse YYYY-MM-DD or YYYYMMDD format for dates (\nISO 8601\n)\n\n\nput dates first to help with default ordering (where appropriate)\n\n\nprefer lower case to mixed case\n\n\nprefer upper case to mixed case\n\n\nprefer consistent case\n\n\n\n\nExamples\n\n\nGood\n\n\n2017-08-18_article01.md\n2017-08-18_article02.md\n2017-08-18_article10.md\n2016-01-08_roy_wg.vcf.gz\n2016-02-14_priss_wg.vcf.gz\n2016-06-12_zora_wg.vcf.gz\n2017-04-10_leon_wg.vcf.gz\n\n\n\n\nBad\n\n\nacticle1.md\narticle2.md\narticle10.md\npriss2142015.vcf.gz\nleon17410.vcf.gz\nzora16612.vcf.gz\nroy1618.vcf.gz\npriss16214.vcf.gz\n\n\n\n\nReferences\n\n\n\n\nnaming things by Jenny Bryan\n\n\n\n\n2017-08-18", 
            "title": "File Naming Conventions"
        }, 
        {
            "location": "/File-Naming-Conventions/#file-naming-conventions", 
            "text": "Three principles:   Machine readable  Human Readable  Plays well with default ordering", 
            "title": "File Naming Conventions"
        }, 
        {
            "location": "/File-Naming-Conventions/#conventions", 
            "text": "-  (dash) separate words in concept  _  (underscore) separate units of meta-data  pad numbers to allow for default file sort  use YYYY-MM-DD or YYYYMMDD format for dates ( ISO 8601 )  put dates first to help with default ordering (where appropriate)  prefer lower case to mixed case  prefer upper case to mixed case  prefer consistent case", 
            "title": "Conventions"
        }, 
        {
            "location": "/File-Naming-Conventions/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/File-Naming-Conventions/#good", 
            "text": "2017-08-18_article01.md\n2017-08-18_article02.md\n2017-08-18_article10.md\n2016-01-08_roy_wg.vcf.gz\n2016-02-14_priss_wg.vcf.gz\n2016-06-12_zora_wg.vcf.gz\n2017-04-10_leon_wg.vcf.gz", 
            "title": "Good"
        }, 
        {
            "location": "/File-Naming-Conventions/#bad", 
            "text": "acticle1.md\narticle2.md\narticle10.md\npriss2142015.vcf.gz\nleon17410.vcf.gz\nzora16612.vcf.gz\nroy1618.vcf.gz\npriss16214.vcf.gz", 
            "title": "Bad"
        }, 
        {
            "location": "/File-Naming-Conventions/#references", 
            "text": "naming things by Jenny Bryan", 
            "title": "References"
        }, 
        {
            "location": "/File-Naming-Conventions/#2017-08-18", 
            "text": "", 
            "title": "2017-08-18"
        }, 
        {
            "location": "/Command-Line-Option-Loose-Standard/", 
            "text": "Loose Standards for Command Line Options\n\n\n\n\n\n\n\n\noption\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\n-a\n\n\nall\n\n\n\n\n\n\n-b\n\n\nbuffer / block size\n\n\n\n\n\n\n-c\n\n\ncomand\n\n\n\n\n\n\n-d\n\n\ndebug or delete\n\n\n\n\n\n\n-D\n\n\ndefine\n\n\n\n\n\n\n-e\n\n\nexecute\n\n\n\n\n\n\n-f\n\n\nfile (input)\n\n\n\n\n\n\n-h\n\n\nhelp\n\n\n\n\n\n\n-i\n\n\ninteractive / initialize\n\n\n\n\n\n\n-I\n\n\ninclude\n\n\n\n\n\n\n-k\n\n\nkeep / kill\n\n\n\n\n\n\n-l\n\n\nlist / load / login / length / lock\n\n\n\n\n\n\n-m\n\n\nmessage / mode\n\n\n\n\n\n\n-n\n\n\nnumber\n\n\n\n\n\n\n-o\n\n\noutput\n\n\n\n\n\n\n-p\n\n\nport / protocol\n\n\n\n\n\n\n-q\n\n\nquiet\n\n\n\n\n\n\n-r / -R\n\n\nrecurse\n\n\n\n\n\n\n-s\n\n\nsilent / subject\n\n\n\n\n\n\n-t\n\n\ntag\n\n\n\n\n\n\n-u\n\n\nuser\n\n\n\n\n\n\n-v\n\n\nverbose / version\n\n\n\n\n\n\n-V\n\n\nversion\n\n\n\n\n\n\n-w\n\n\nwidth / warning\n\n\n\n\n\n\n-x\n\n\ndebug / extract\n\n\n\n\n\n\n-y\n\n\nyes\n\n\n\n\n\n\n-z\n\n\ncompress\n\n\n\n\n\n\n\n\nFrom an answer on \nSO\n,\na good convention seems to be:\n\n\n\n\nWhen no options are given, show help and print to \nstderr\n with an error code\n\n\nWhen the \n-h\n or \n--help\n option are given, provide help on \nstdout\n and give no error\n\n\n\n\nReferences\n\n\n\n\ntaoup ch. 10\n\n\nSO: Should the command line \u201cusage\u201d be printed on stdout or stderr?\n\n\n\n\n2017-12-25", 
            "title": "Command Line Option Loose Standard"
        }, 
        {
            "location": "/Command-Line-Option-Loose-Standard/#loose-standards-for-command-line-options", 
            "text": "option  description      -a  all    -b  buffer / block size    -c  comand    -d  debug or delete    -D  define    -e  execute    -f  file (input)    -h  help    -i  interactive / initialize    -I  include    -k  keep / kill    -l  list / load / login / length / lock    -m  message / mode    -n  number    -o  output    -p  port / protocol    -q  quiet    -r / -R  recurse    -s  silent / subject    -t  tag    -u  user    -v  verbose / version    -V  version    -w  width / warning    -x  debug / extract    -y  yes    -z  compress     From an answer on  SO ,\na good convention seems to be:   When no options are given, show help and print to  stderr  with an error code  When the  -h  or  --help  option are given, provide help on  stdout  and give no error", 
            "title": "Loose Standards for Command Line Options"
        }, 
        {
            "location": "/Command-Line-Option-Loose-Standard/#references", 
            "text": "taoup ch. 10  SO: Should the command line \u201cusage\u201d be printed on stdout or stderr?", 
            "title": "References"
        }, 
        {
            "location": "/Command-Line-Option-Loose-Standard/#2017-12-25", 
            "text": "", 
            "title": "2017-12-25"
        }, 
        {
            "location": "/PCB-Notes/", 
            "text": "PCB Notes\n\n\nPCB Thickness\n\n\nCopper thickness is commonly expressed in \noz\n, for example \n1 oz Cu\n.\nThis is shorthand for the height of copper if spread over a square foot\nsurface.\n\n\nTo calculate the height for \n1 oz\n \nCu\n, we need a few conversions:\n\n\n\n\n$ 1\\ \\mathrm{oz} = 0.0625\\ \\mathrm{lbs}$\n\n\n$\\mathrm{Cu}\\ \\mathrm{density} = 8.96 \\frac{\\mathrm{g}}{\\mathrm{cm}^3} $\n\n\n$ 1\\ \\mathrm{g} \\approx 0.00220462\\ \\mathrm{lbs} $\n\n\n$ 1\\ \\mathrm{cm} \\approx 0.393701\\ \\mathrm{in} $\n\n\n\n\nThis implies:\n\n\n\n\n$\\mathrm{Cu}\\ \\mathrm{density} = \\frac{8.96 \\cdot 0.00220462\\ \\mathrm{lbs}}{(0.393701^3)\\ \\mathrm{in}^3} \\approx 0.324 \\frac{\\mathrm{lbs}}{\\mathrm{in}^3} $\n\n\n$ h\\ \\mathrm{in} = \\frac{1\\ \\mathrm{oz}}{ 1\\ \\mathrm{ft}^2 } = \\frac{0.0625\\ \\mathrm{lbs}}{ 144\\ \\mathrm{in}^2 } \\approx .00134 $\n\n\n\n\nOr, in general,\n\n\n$$ z\\ \\mathrm{oz}\\ \\mathrm{Cu} \\rightarrow z \\cdot 1.34\\ \\mathrm{mil} $$\n\n\nWhere $1\\ \\mathrm{mil} = \\frac{1}{1000}\\ \\mathrm{in}$.\n\n\n\n\nDecoupling Capacitors\n\n\n\n\nEither one 100nF or two, one of 0.1uF and another of 10uF \n\n\nPlace as close to the chip as possible\n\n\nPlace the decoupling capacitor across the power supply (3.3v or 5v)\n\n\n\n\n(\nsrc\n)\n\n\nSMD Sizes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSMD\n\n\nmm\n\n\ninch\n\n\n\n\n\n\n\n\n\n\n2920\n\n\n7.4 x 5.1\n\n\n0.29 x 0.20\n\n\n\n\n\n\n2725\n\n\n6.9 x 6.3\n\n\n0.27 x 0.25\n\n\n\n\n\n\n2512\n\n\n6.3 x 3.2\n\n\n0.25 x 0.125\n\n\n\n\n\n\n2010\n\n\n5.0 x 2.5\n\n\n0.20 x 0.10\n\n\n\n\n\n\n1825\n\n\n4.5 x 6.4\n\n\n0.18 x 0.25\n\n\n\n\n\n\n1812\n\n\n4.6 x 3.0\n\n\n0.18 x 0.125\n\n\n\n\n\n\n1806\n\n\n4.5 x 1.6\n\n\n0.18 x 0.06\n\n\n\n\n\n\n1210\n\n\n3.2 x 2.5\n\n\n0.125 x 0.10\n\n\n\n\n\n\n1206\n\n\n3.0 x 1.5\n\n\n0.12 x 0.06\n\n\n\n\n\n\n1008\n\n\n2.5 x 2.0\n\n\n0.10 x 0.08\n\n\n\n\n\n\n0805\n\n\n2.0 x 1.3\n\n\n0.08 x 0.05\n\n\n\n\n\n\n0603\n\n\n1.5 x 0.8\n\n\n0.06 x 0.03\n\n\n\n\n\n\n0402\n\n\n1.0 x 0.5\n\n\n0.04 x 0.02\n\n\n\n\n\n\n0201\n\n\n0.6 x 0.3\n\n\n0.02 x 0.01\n\n\n\n\n\n\n01005\n\n\n0.4 x 0.2\n\n\n0.016 x 0.008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\n\n\nPitch (mm)\n\n\n\n\n\n\n\n\n\n\nSOIC\n\n\n1.27\n\n\n\n\n\n\nTSOP\n\n\n0.5\n\n\n\n\n\n\nSSOP\n\n\n0.635\n\n\n\n\n\n\nQSOP\n\n\n0.635\n\n\n\n\n\n\nVSOP\n\n\n0.4, 0.5, 0.65\n\n\n\n\n\n\nLQFP\n\n\n1.4\n\n\n\n\n\n\nPLCC\n\n\n1.27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018-02-03", 
            "title": "PCB Notes"
        }, 
        {
            "location": "/PCB-Notes/#pcb-notes", 
            "text": "", 
            "title": "PCB Notes"
        }, 
        {
            "location": "/PCB-Notes/#pcb-thickness", 
            "text": "Copper thickness is commonly expressed in  oz , for example  1 oz Cu .\nThis is shorthand for the height of copper if spread over a square foot\nsurface.  To calculate the height for  1 oz   Cu , we need a few conversions:   $ 1\\ \\mathrm{oz} = 0.0625\\ \\mathrm{lbs}$  $\\mathrm{Cu}\\ \\mathrm{density} = 8.96 \\frac{\\mathrm{g}}{\\mathrm{cm}^3} $  $ 1\\ \\mathrm{g} \\approx 0.00220462\\ \\mathrm{lbs} $  $ 1\\ \\mathrm{cm} \\approx 0.393701\\ \\mathrm{in} $   This implies:   $\\mathrm{Cu}\\ \\mathrm{density} = \\frac{8.96 \\cdot 0.00220462\\ \\mathrm{lbs}}{(0.393701^3)\\ \\mathrm{in}^3} \\approx 0.324 \\frac{\\mathrm{lbs}}{\\mathrm{in}^3} $  $ h\\ \\mathrm{in} = \\frac{1\\ \\mathrm{oz}}{ 1\\ \\mathrm{ft}^2 } = \\frac{0.0625\\ \\mathrm{lbs}}{ 144\\ \\mathrm{in}^2 } \\approx .00134 $   Or, in general,  $$ z\\ \\mathrm{oz}\\ \\mathrm{Cu} \\rightarrow z \\cdot 1.34\\ \\mathrm{mil} $$  Where $1\\ \\mathrm{mil} = \\frac{1}{1000}\\ \\mathrm{in}$.", 
            "title": "PCB Thickness"
        }, 
        {
            "location": "/PCB-Notes/#decoupling-capacitors", 
            "text": "Either one 100nF or two, one of 0.1uF and another of 10uF   Place as close to the chip as possible  Place the decoupling capacitor across the power supply (3.3v or 5v)   ( src )", 
            "title": "Decoupling Capacitors"
        }, 
        {
            "location": "/PCB-Notes/#smd-sizes", 
            "text": "SMD  mm  inch      2920  7.4 x 5.1  0.29 x 0.20    2725  6.9 x 6.3  0.27 x 0.25    2512  6.3 x 3.2  0.25 x 0.125    2010  5.0 x 2.5  0.20 x 0.10    1825  4.5 x 6.4  0.18 x 0.25    1812  4.6 x 3.0  0.18 x 0.125    1806  4.5 x 1.6  0.18 x 0.06    1210  3.2 x 2.5  0.125 x 0.10    1206  3.0 x 1.5  0.12 x 0.06    1008  2.5 x 2.0  0.10 x 0.08    0805  2.0 x 1.3  0.08 x 0.05    0603  1.5 x 0.8  0.06 x 0.03    0402  1.0 x 0.5  0.04 x 0.02    0201  0.6 x 0.3  0.02 x 0.01    01005  0.4 x 0.2  0.016 x 0.008        Package  Pitch (mm)      SOIC  1.27    TSOP  0.5    SSOP  0.635    QSOP  0.635    VSOP  0.4, 0.5, 0.65    LQFP  1.4    PLCC  1.27", 
            "title": "SMD Sizes"
        }, 
        {
            "location": "/PCB-Notes/#2018-02-03", 
            "text": "", 
            "title": "2018-02-03"
        }, 
        {
            "location": "/Coding-Style/", 
            "text": "Elements of Coding Style\n\n\nThis is meant as a light style guide for coding.\nRules here are guides and not meant to be used\nwhen common sense dictates otherwise.\n\n\nThe following rules are mostly semantic and are\ndone with a 'polyglot' point of view even though\nJavaScript is mostly used for coding examples.\n\n\nThese are coding format rules that I mostly\ngravitate towards and is my attempt at formalizing\nthem in some way.\n\n\nPrefer two space indentation to tab or four spaces\n\n\nTwo space indentation should be preferred to four spaces or tabs for indentation.\nFour spaces causes code to gravitate too far to the right.\nTabs are inconsistently rendered, annoying to manipulate and camouflage themselves\nas spaces.\n\n\nfunction f() {\n  console.log(\nhello\n);\n  if (true) {\n    console.log(\nhello, friend\n);\n  }\n}\n\n\n\n\nPrefer start block token on the same line as control statements and function headings\n\n\nFor languages that have a start block token, a \n{\n say,\nprefer to put them on the same line as the function heading.\nPutting start blocks only increases vertical length with no real\nbenefit.\nIf breaks in text are needed, add returns as needed.\n\n\nfunction f() {\n\n  for (var i=0; i\n1; i++) {\n    console.log(\nhello\n);\n  }\n\n}\n\n\n\n\nEncase conditional blocks within block tokens even if the language allows otherwise\n\n\nEven if the language allows you to forgo block tokens to encase the control block\nof a conditional, encase them in the block tokens anyway.\nIf statements are extended, it's an easy mistake to think the added code\nfalls within the same conditional if not encased in the block tokens.\n\n\n  if (true) {\n    console.log(\nhello\n);\n  }\n\n\n\n\nPlace small conditional statements on a single line\n\n\nIf the conditional expression and statement body is small enough, place it all on the same line.\nIf the line is too long, this should be avoided but for small statements, terseness wins\nover beauty.\n\n\n  if (true) { console.log(\nhello\n; }\n\n\n\n\nPrefer alternate \nelse\n conditionals on their own line\n\n\nFor ease of reading, put \nelse\n and \nelse if\n conditionals on their own line.\nEach alternate conditional is easier to read, align and comment if necessary\nif they're as independent as possible from the surrounding sibling conditionals.\n\n\n  if (ok) {\n    console.log(\nhello\n);\n  }\n  else if (ko) {\n    console.log(\ngoodbye\n);\n  }\n  else {\n    console.log(\nhello and goodbye\n);\n  }\n\n\n\n\nPrefer ternary conditional assignment over \nif/else\n assignment\n\n\nIf the language allows for ternary expressions, use them for alternate assignments.\nTerseness wins out over beauty.\n\n\n  var v = ( vv ? true : false );\n\n\n\n\nPrefer putting comments at the top of statement blocks and put a blank comment line after the comment text\n\n\nComments should appear on their own line, indented appropriately, above the logic\nit's commenting on, where appropriate.\nIn the cases that comments need to go into a statement block instead of above\nit, they should appear at the top of the statement block.\nInline comments should be avoided.\n\n\nComments should describe what the high level concept of a piece of code is.\nThe least it should do is to remind the author of the intent of the code were it to be\nrevisited after a time.\nComment blocks should have a trailing 'blank' comment line to ease of reading.\n\n\n  // If everything is 'ok',\n  // provide a friendly greeting.\n  //\n  if (ok) {\n    console.log(\nhello\n);\n  }\n\n\n\n\nEnd of function returns should have no blank line between the ending block token\n\n\nTrailing newlines after the last return should be culled for conciseness.\n\n\nfunction f() {\n\n  console.log(\nhello\n);\n\n  return true;\n}\n\n\n\n\nNo trailing whitespace at end of lines\n\n\nTrailing whitespace should be culled at the end of the line.\nUse whitespace highlighting in your editor to notice it.\n\n\nWhen doing many variable assignments, align them for readability\n\n\nWhen assigning variables values, on initialization say, prefer\nto format them so they can easily be read by aligning the equals\nsign and putting multiple variables on a single line if need be.\nSmall differences are more noticeable when aligned in this way.\nStructure and intent of why the variables are being assigned\nis sometimes more apparent when aligned properly.\n\n\nAdd space between the end of the variable and the \n=\n if need be.\nGroup in blocks to ease readability.\n\n\n  var x00 = 0, x01 = 1,\n      x10 = 1, x11 = 0;\n\n  var mammal  = 'cat',\n      reptile = 'chameleon',\n      fish    = 'catfish',\n      insect  = 'ladybug',\n\n      dinosaur         = 'brontosaurus',\n      extinct_elephant = 'woolly mammoth';\n\n\n\n\n\nPlace a single space between parent expression and nested sub expressions, aligning inner expressions with proper indentation.  Place Boolean operations at end of line, where appropriate.\n\n\nFor a parent control statement expression, put a space between the outer parenthesis and the inner expression.\nFor the expressions within the control statement, align them for readability with proper indentation\nif the control is nested.\n\n\nBoolean tokens should be placed at the end of the line so the first relevant piece of information\non the line is relevant logic.\n\n\nNested multi-line conditionals are hard enough to read, try to ease the cognitive load on the reader\nas much as possible.\n\n\nfunction f(v) {\n  var k=0;\n  while ( (v\n10) \n\n          (k\nv) \n\n          ( ((k+v) \n 100) || \n            ((k-v) \n 50) ) ) {\n    console.log(\nhello\n);\n  }\n}\n\n\n\n\nUse parenthesis for explicit order of operations\n\n\nUse parenthesis to explicitly show what the order of\noperations should be for an expression or statement.\nIt puts a lot of cognitive load on the reader to\nremember which order of operations takes precedence\nin the language that the code is written in.\n\n\nSometimes order of operations aren't the same\nbetween languages.\nSometimes a token is overloaded and mean different\nthings in different contexts, often within the same\nline.\n\n\nEase the readers burden by explicitly spelling it out\nfor them.\n\n\n  while ( ((*p) != 0) \n\n          ((5*(*p)) \n 100) ) {\n    p++;\n  }\n\n\n\n\nContents of commenting\n\n\nComments should be a high level description of what the code does.\nThe code describes what the code does so a comments job is to\nenlighten what the code is doing and give motivation for why\nit's doing it, not repeat the logic verbatim.\n\n\nA good rule of thumb is to write a comment that you will be\nable to understand in 6 months time (or whatever unit of time\ncauses forgetfulness) should you look at the code again.\n\n\n2018-02-17", 
            "title": "Coding Style"
        }, 
        {
            "location": "/Coding-Style/#elements-of-coding-style", 
            "text": "This is meant as a light style guide for coding.\nRules here are guides and not meant to be used\nwhen common sense dictates otherwise.  The following rules are mostly semantic and are\ndone with a 'polyglot' point of view even though\nJavaScript is mostly used for coding examples.  These are coding format rules that I mostly\ngravitate towards and is my attempt at formalizing\nthem in some way.", 
            "title": "Elements of Coding Style"
        }, 
        {
            "location": "/Coding-Style/#prefer-two-space-indentation-to-tab-or-four-spaces", 
            "text": "Two space indentation should be preferred to four spaces or tabs for indentation.\nFour spaces causes code to gravitate too far to the right.\nTabs are inconsistently rendered, annoying to manipulate and camouflage themselves\nas spaces.  function f() {\n  console.log( hello );\n  if (true) {\n    console.log( hello, friend );\n  }\n}", 
            "title": "Prefer two space indentation to tab or four spaces"
        }, 
        {
            "location": "/Coding-Style/#prefer-start-block-token-on-the-same-line-as-control-statements-and-function-headings", 
            "text": "For languages that have a start block token, a  {  say,\nprefer to put them on the same line as the function heading.\nPutting start blocks only increases vertical length with no real\nbenefit.\nIf breaks in text are needed, add returns as needed.  function f() {\n\n  for (var i=0; i 1; i++) {\n    console.log( hello );\n  }\n\n}", 
            "title": "Prefer start block token on the same line as control statements and function headings"
        }, 
        {
            "location": "/Coding-Style/#encase-conditional-blocks-within-block-tokens-even-if-the-language-allows-otherwise", 
            "text": "Even if the language allows you to forgo block tokens to encase the control block\nof a conditional, encase them in the block tokens anyway.\nIf statements are extended, it's an easy mistake to think the added code\nfalls within the same conditional if not encased in the block tokens.    if (true) {\n    console.log( hello );\n  }", 
            "title": "Encase conditional blocks within block tokens even if the language allows otherwise"
        }, 
        {
            "location": "/Coding-Style/#place-small-conditional-statements-on-a-single-line", 
            "text": "If the conditional expression and statement body is small enough, place it all on the same line.\nIf the line is too long, this should be avoided but for small statements, terseness wins\nover beauty.    if (true) { console.log( hello ; }", 
            "title": "Place small conditional statements on a single line"
        }, 
        {
            "location": "/Coding-Style/#prefer-alternate-else-conditionals-on-their-own-line", 
            "text": "For ease of reading, put  else  and  else if  conditionals on their own line.\nEach alternate conditional is easier to read, align and comment if necessary\nif they're as independent as possible from the surrounding sibling conditionals.    if (ok) {\n    console.log( hello );\n  }\n  else if (ko) {\n    console.log( goodbye );\n  }\n  else {\n    console.log( hello and goodbye );\n  }", 
            "title": "Prefer alternate else conditionals on their own line"
        }, 
        {
            "location": "/Coding-Style/#prefer-ternary-conditional-assignment-over-ifelse-assignment", 
            "text": "If the language allows for ternary expressions, use them for alternate assignments.\nTerseness wins out over beauty.    var v = ( vv ? true : false );", 
            "title": "Prefer ternary conditional assignment over if/else assignment"
        }, 
        {
            "location": "/Coding-Style/#prefer-putting-comments-at-the-top-of-statement-blocks-and-put-a-blank-comment-line-after-the-comment-text", 
            "text": "Comments should appear on their own line, indented appropriately, above the logic\nit's commenting on, where appropriate.\nIn the cases that comments need to go into a statement block instead of above\nit, they should appear at the top of the statement block.\nInline comments should be avoided.  Comments should describe what the high level concept of a piece of code is.\nThe least it should do is to remind the author of the intent of the code were it to be\nrevisited after a time.\nComment blocks should have a trailing 'blank' comment line to ease of reading.    // If everything is 'ok',\n  // provide a friendly greeting.\n  //\n  if (ok) {\n    console.log( hello );\n  }", 
            "title": "Prefer putting comments at the top of statement blocks and put a blank comment line after the comment text"
        }, 
        {
            "location": "/Coding-Style/#end-of-function-returns-should-have-no-blank-line-between-the-ending-block-token", 
            "text": "Trailing newlines after the last return should be culled for conciseness.  function f() {\n\n  console.log( hello );\n\n  return true;\n}", 
            "title": "End of function returns should have no blank line between the ending block token"
        }, 
        {
            "location": "/Coding-Style/#no-trailing-whitespace-at-end-of-lines", 
            "text": "Trailing whitespace should be culled at the end of the line.\nUse whitespace highlighting in your editor to notice it.", 
            "title": "No trailing whitespace at end of lines"
        }, 
        {
            "location": "/Coding-Style/#when-doing-many-variable-assignments-align-them-for-readability", 
            "text": "When assigning variables values, on initialization say, prefer\nto format them so they can easily be read by aligning the equals\nsign and putting multiple variables on a single line if need be.\nSmall differences are more noticeable when aligned in this way.\nStructure and intent of why the variables are being assigned\nis sometimes more apparent when aligned properly.  Add space between the end of the variable and the  =  if need be.\nGroup in blocks to ease readability.    var x00 = 0, x01 = 1,\n      x10 = 1, x11 = 0;\n\n  var mammal  = 'cat',\n      reptile = 'chameleon',\n      fish    = 'catfish',\n      insect  = 'ladybug',\n\n      dinosaur         = 'brontosaurus',\n      extinct_elephant = 'woolly mammoth';", 
            "title": "When doing many variable assignments, align them for readability"
        }, 
        {
            "location": "/Coding-Style/#place-a-single-space-between-parent-expression-and-nested-sub-expressions-aligning-inner-expressions-with-proper-indentation-place-boolean-operations-at-end-of-line-where-appropriate", 
            "text": "For a parent control statement expression, put a space between the outer parenthesis and the inner expression.\nFor the expressions within the control statement, align them for readability with proper indentation\nif the control is nested.  Boolean tokens should be placed at the end of the line so the first relevant piece of information\non the line is relevant logic.  Nested multi-line conditionals are hard enough to read, try to ease the cognitive load on the reader\nas much as possible.  function f(v) {\n  var k=0;\n  while ( (v 10)  \n          (k v)  \n          ( ((k+v)   100) || \n            ((k-v)   50) ) ) {\n    console.log( hello );\n  }\n}", 
            "title": "Place a single space between parent expression and nested sub expressions, aligning inner expressions with proper indentation.  Place Boolean operations at end of line, where appropriate."
        }, 
        {
            "location": "/Coding-Style/#use-parenthesis-for-explicit-order-of-operations", 
            "text": "Use parenthesis to explicitly show what the order of\noperations should be for an expression or statement.\nIt puts a lot of cognitive load on the reader to\nremember which order of operations takes precedence\nin the language that the code is written in.  Sometimes order of operations aren't the same\nbetween languages.\nSometimes a token is overloaded and mean different\nthings in different contexts, often within the same\nline.  Ease the readers burden by explicitly spelling it out\nfor them.    while ( ((*p) != 0)  \n          ((5*(*p))   100) ) {\n    p++;\n  }", 
            "title": "Use parenthesis for explicit order of operations"
        }, 
        {
            "location": "/Coding-Style/#contents-of-commenting", 
            "text": "Comments should be a high level description of what the code does.\nThe code describes what the code does so a comments job is to\nenlighten what the code is doing and give motivation for why\nit's doing it, not repeat the logic verbatim.  A good rule of thumb is to write a comment that you will be\nable to understand in 6 months time (or whatever unit of time\ncauses forgetfulness) should you look at the code again.", 
            "title": "Contents of commenting"
        }, 
        {
            "location": "/Coding-Style/#2018-02-17", 
            "text": "", 
            "title": "2018-02-17"
        }, 
        {
            "location": "/Energy-Consumption-Stats/", 
            "text": "Energy Consumption Stats\n\n\nFrom the \nU.S. Energy Information Administration\n:\n\n\n\n\nAverage yearly houshold usage of 10.812 MWh (Megawatthours)\n\n\n~30 kWh daily household usage\n\n\n\n\nHighs of 15.435 MWh (~42.28 kWh/day) to lows of 6.166 MWh (~17 kWh/day).\n\n\nAs of now, for a consumer solar it's about \n$\n1 per Watt of solar.\nAssuming a 12 hour window of sun at full power, and 36 kWh usage, thats 3 kW or\nabout \n$\n3k for the solar panels (at about .6x1x.035 m^3).\n\n\nAs of now, for consumer deep cycle lead acid batteries, it's about \n$\n.15 / (Watt hour).\nAt 36 kWh, thats about \n$\n5400.\n\n\nA LiFePO4 32650 5.5 Ah 3.2 V rechargeable battery goes for ~\n$\n120.00 / 80 units.\nAt 36 kWh, that works out to about (120 / (80 \n 5.5 \n 3.2)) \n 36000 = \n$\n3070\n\n\nThis does not include all the control hardware and electronics that are needed\nfor proper usage.\n\n\nAs a rough estimate, New York average price for \n$\n.1854 / kWh at 601 kWh / month\nfor about \n$\n111.32 / month or \n$\n1335.84 / year.\n\n\nFuture\n\n\n\n\nGalactic Scale Energy\n\n\nAnnual Energy Review\n\n\n\n\nInterestingly, I think the blog post was trying to point out the absurdity of\ncontinue economic growth but I take it as a rough time frame for our progression\non moving up the Kardashev scale.\n\n\nThere's some talk about wealth and CO2 emissions going hand in hand, with\nsome suggesting \na total civilization collapse\n (from \n\"Decline of the Empire\" blog\n).\n\n\nOne post claims solar produces \n20-30x less CO2 than coal\n,\nso I'm not sure if apocalyptic forecasts are to be believed.\n\n\n2017-09-21", 
            "title": "Energy Consumption Stats"
        }, 
        {
            "location": "/Energy-Consumption-Stats/#energy-consumption-stats", 
            "text": "From the  U.S. Energy Information Administration :   Average yearly houshold usage of 10.812 MWh (Megawatthours)  ~30 kWh daily household usage   Highs of 15.435 MWh (~42.28 kWh/day) to lows of 6.166 MWh (~17 kWh/day).  As of now, for a consumer solar it's about  $ 1 per Watt of solar.\nAssuming a 12 hour window of sun at full power, and 36 kWh usage, thats 3 kW or\nabout  $ 3k for the solar panels (at about .6x1x.035 m^3).  As of now, for consumer deep cycle lead acid batteries, it's about  $ .15 / (Watt hour).\nAt 36 kWh, thats about  $ 5400.  A LiFePO4 32650 5.5 Ah 3.2 V rechargeable battery goes for ~ $ 120.00 / 80 units.\nAt 36 kWh, that works out to about (120 / (80   5.5   3.2))   36000 =  $ 3070  This does not include all the control hardware and electronics that are needed\nfor proper usage.  As a rough estimate, New York average price for  $ .1854 / kWh at 601 kWh / month\nfor about  $ 111.32 / month or  $ 1335.84 / year.", 
            "title": "Energy Consumption Stats"
        }, 
        {
            "location": "/Energy-Consumption-Stats/#future", 
            "text": "Galactic Scale Energy  Annual Energy Review   Interestingly, I think the blog post was trying to point out the absurdity of\ncontinue economic growth but I take it as a rough time frame for our progression\non moving up the Kardashev scale.  There's some talk about wealth and CO2 emissions going hand in hand, with\nsome suggesting  a total civilization collapse  (from  \"Decline of the Empire\" blog ).  One post claims solar produces  20-30x less CO2 than coal ,\nso I'm not sure if apocalyptic forecasts are to be believed.", 
            "title": "Future"
        }, 
        {
            "location": "/Energy-Consumption-Stats/#2017-09-21", 
            "text": "", 
            "title": "2017-09-21"
        }, 
        {
            "location": "/Simple-Sum/", 
            "text": "Simple Sums\n\n\n$$ 0 \n p \n 1, p  \\in \\mathbb{R}$$\n\n\n\n\n$$\n\\begin{align}\n\\sum_{k=0}^{\\infty} p^k = \\frac{1}{1-p}\n\\end{align}\n$$\n\n\nProof:\n\n\n$$\n\\begin{align}\nS \n = \\sum_{k=0}^{\\infty} p^k\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\n\\sum_{k=0}^{\\infty} p^k \n = 1 + \\sum_{k=1}^{\\infty} p^k\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\np S \n= \\sum_{k=0}^{\\infty} p^{k+1} \\\\\n \n= \\sum_{k=1}^{\\infty} p^k \\\\\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\nS - p S   \n= 1 \\\\\nS \n= \\frac{1}{1-p} \\\\\n\\end{align}\n$$\n\n\n\n\n$$\n\\begin{align}\n\\sum_{k=0}^{s-1} p^k = \\frac{1-p^s}{1-p} \\\\\n\\sum_{k=s}^{\\infty} p^k = \\frac{p^s}{1-p}\n\\end{align}\n$$\n\n\nProof:\n\n\n$$\n\\begin{align}\n\\sum_{k=0}^{s-1} p^k \n= \\sum_{k=0}^{\\infty} p^k - \\sum_{k=s}^{\\infty} p^k \\\\\n  \n= \\sum_{k=0}^{\\infty} p^k - p^s \\sum_{k=0}^{\\infty} p^k \\\\\n  \n= \\frac{1}{1-p} - \\frac{p^s}{1-p} \\\\\n  \n= \\frac{1 - p^s}{1-p} \\\\\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\n\\sum_{k=s}^{\\infty} p^k \n= p^s \\sum_{k=0}^{\\infty} p^k \\\\\n   \n= \\frac{p^s}{1-p} \\\\\n\\end{align}\n$$\n\n\n\n\n$$\n\\begin{align}\n\\sum_{k=0}^{\\infty} k p^k = \\frac{p}{(1-p)^2}\n\\end{align}\n$$\n\n\nProof:\n\n\n$$\n\\begin{align}\nS' \n= \\sum_{k=0}^{\\infty} k p^k \\\\\np S' \n= \\sum_{k=0}^{\\infty} k p^{k+1} \\\\\n \n= \\sum_{k=1}^{\\infty} (k - 1) p^{k} \\\\\n \n=  \\sum_{k=1} k p^k - \\sum_{k=1} p^k \\\\\n \n=  S' - \\frac{p}{1-p} \\\\\np S' - S' \n= - \\frac{p}{1-p} \\\\\nS' (p - 1) \n= - \\frac{p}{1-p} \\\\\nS' (1 - p) \n= \\frac{p}{1-p} \\\\\nS' \n= \\frac{p}{(1-p)^2} \\\\\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\n\\end{align}\n$$\n\n\n2018-05-25", 
            "title": "Simple Sum"
        }, 
        {
            "location": "/Simple-Sum/#simple-sums", 
            "text": "$$ 0   p   1, p  \\in \\mathbb{R}$$   $$\n\\begin{align}\n\\sum_{k=0}^{\\infty} p^k = \\frac{1}{1-p}\n\\end{align}\n$$  Proof:  $$\n\\begin{align}\nS   = \\sum_{k=0}^{\\infty} p^k\n\\end{align}\n$$  $$\n\\begin{align}\n\\sum_{k=0}^{\\infty} p^k   = 1 + \\sum_{k=1}^{\\infty} p^k\n\\end{align}\n$$  $$\n\\begin{align}\np S  = \\sum_{k=0}^{\\infty} p^{k+1} \\\\\n  = \\sum_{k=1}^{\\infty} p^k \\\\\n\\end{align}\n$$  $$\n\\begin{align}\nS - p S    = 1 \\\\\nS  = \\frac{1}{1-p} \\\\\n\\end{align}\n$$   $$\n\\begin{align}\n\\sum_{k=0}^{s-1} p^k = \\frac{1-p^s}{1-p} \\\\\n\\sum_{k=s}^{\\infty} p^k = \\frac{p^s}{1-p}\n\\end{align}\n$$  Proof:  $$\n\\begin{align}\n\\sum_{k=0}^{s-1} p^k  = \\sum_{k=0}^{\\infty} p^k - \\sum_{k=s}^{\\infty} p^k \\\\\n   = \\sum_{k=0}^{\\infty} p^k - p^s \\sum_{k=0}^{\\infty} p^k \\\\\n   = \\frac{1}{1-p} - \\frac{p^s}{1-p} \\\\\n   = \\frac{1 - p^s}{1-p} \\\\\n\\end{align}\n$$  $$\n\\begin{align}\n\\sum_{k=s}^{\\infty} p^k  = p^s \\sum_{k=0}^{\\infty} p^k \\\\\n    = \\frac{p^s}{1-p} \\\\\n\\end{align}\n$$   $$\n\\begin{align}\n\\sum_{k=0}^{\\infty} k p^k = \\frac{p}{(1-p)^2}\n\\end{align}\n$$  Proof:  $$\n\\begin{align}\nS'  = \\sum_{k=0}^{\\infty} k p^k \\\\\np S'  = \\sum_{k=0}^{\\infty} k p^{k+1} \\\\\n  = \\sum_{k=1}^{\\infty} (k - 1) p^{k} \\\\\n  =  \\sum_{k=1} k p^k - \\sum_{k=1} p^k \\\\\n  =  S' - \\frac{p}{1-p} \\\\\np S' - S'  = - \\frac{p}{1-p} \\\\\nS' (p - 1)  = - \\frac{p}{1-p} \\\\\nS' (1 - p)  = \\frac{p}{1-p} \\\\\nS'  = \\frac{p}{(1-p)^2} \\\\\n\\end{align}\n$$  $$\n\\begin{align}\n\\end{align}\n$$", 
            "title": "Simple Sums"
        }, 
        {
            "location": "/Simple-Sum/#2018-05-25", 
            "text": "", 
            "title": "2018-05-25"
        }, 
        {
            "location": "/Fisher-Yates-Shuffle/", 
            "text": "Fisher-Yates Shuffle\n\n\nThe \nFisher-Yates shuffle algorithm\n is used to create a random permutation.\nThe derivation is relatively straight forward:\n\n\nfunction fisher_yates_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i\n(n-1); i++) {\n    var idx = i + Math.floor(Math.random()*(n-i));\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}\n\n\n\n\nWe choose the first element at random, then\nproceed to choose subsequent entries from the remaining elements.\n\n\nAs a spot check, we can confirm that there are $n!$ configurations\nyielding approximately $ n (lg(n) - 1) $ bits of entropy.\nEach poll of the random number generator is for $ lg(n-i) $ bits\nover $n-1$ entries:\n\n\n$$ lg(2) + lg(3) + \\cdots + lg(n) = \\sum_{k=1}^{n} lg(k) = lg(n!) $$\n\n\nThe Wrong Way\n\n\nOne can consider the following incorrect way to do the shuffle:\n\n\nfunction nofish_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i\nn; i++) {\n    var idx = Math.floor(Math.random()*n);\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}\n\n\n\n\na slight variant:\n\n\nfunction noyaks_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i\nn; i++) {\n    var idx = Math.floor(Math.random()*(n-1));\n    if (idx==i) { idx = n-1; }\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}\n\n\n\n\nand another:\n\n\nfunction nomaar_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i\nn; i++) {\n    var idx0 = Math.floor(Math.random()*n);\n    var idx1 = Math.floor(Math.random()*n);\n    t = a[idx0];\n    a[idx0] = a[idx1];\n    a[idx1] = t;\n  }\n}\n\n\n\n\nWhere the difference in \nnofish_shuffle\n and \nnoyaks_shuffle\n\nis to skip the current index when considering which element to permute.\n\nnomaar_shuffle\n is yet another variant where each two elements are\nchosen at random and swapped $n$ times.\n\n\nA friend of mine suggested an nice proof to show the above two\nshuffle algorithms provide incorrect results.\n\n\nAs above, there are $n!$ possible shuffles we want to choose from, with\nequal probability.\nSince \nnofish_shuffle\n is choosing each element to permute from the whole\narray, there are $n^n$ possible choices for the permutation, where\nsome permutations might be represented more than once.\n\n\nProducing multiple configurations is permissible so long as \nnofish_shuffle\n\nwould produce an equal distribution for each of the $n!$ configurations.\nSince $ n! \\nmid n^n $ for $n\n2$, there must be some configurations that\nappear more often by the pigeonhole principle.\n\n\nnoyaks_shuffle\n doesn't fare much better since there are $n^{n-1}$ possible\nchoices of permutation schedules and $n! \\nmid n^{n-1}$ for $n\n2$.\nThe same type of analysis works for the \nnomaar_shuffle\n by noticing\nthat the number of permutation schedules is $n^{2 n}$ and that still $n! \\nmid n^{2 n}$.\n\n\nThough hidden in such a large configuration space, \nnofish_shuffle\n,\n\nnoyaks_shuffle\n and \nnomaar_shuffle\n produce configurations that are not uniformly\ndistributed.\n\n\n\n\nAddendum\n\n\nSattalo's algorithm creates a random single cycle permutation.\nThe algorithm is similar to Fisher-Yates but does not allow the\nchoice of the current index element when swapping:\n\n\nfunction sattalo_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i\n(n-1); i++) {\n    var idx = i + 1 + Math.floor(Math.random()*(n-i-1));\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}\n\n\n\n\nThere are $(n-1)!$ configurations, so we know the above algorithm\nsubsamples from the space of all permutation possibilities.\n\n\nTo see that it produces a single cycle, note that swapping elements\nhas two possibilities:\n\n\n\n\n\n\nIf both elements are in the same cycle, swapping elements creates\n  two disjoint cycles\n\n\nIf both elements are in different cycles, swapping elements creates\n  a single cycle\n\n\n\n\nThe swap step in Sattalo's algorithm can be thought of as swapping\na cycle of length one, the current index position, with another cycle pointed\nto by the chosen random index.\nSince these are two distinct cycles, they join to create a single cycle.\nThis is done $(n-1)$ times forcing a single large cycle.\n\n\nTo see that this draws uniformly from single cycle permutations, \nproceed inductively by noticing that if a single cycle of length $(n-1)$\nis produced uniformly at random, then extending it to a single cycle of\nlength $n$ by the above method will favor each of the $(n-1)$ possible\nextensions equally.\n\n\n2018-06-13", 
            "title": "Fisher Yates Shuffle"
        }, 
        {
            "location": "/Fisher-Yates-Shuffle/#fisher-yates-shuffle", 
            "text": "The  Fisher-Yates shuffle algorithm  is used to create a random permutation.\nThe derivation is relatively straight forward:  function fisher_yates_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i (n-1); i++) {\n    var idx = i + Math.floor(Math.random()*(n-i));\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}  We choose the first element at random, then\nproceed to choose subsequent entries from the remaining elements.  As a spot check, we can confirm that there are $n!$ configurations\nyielding approximately $ n (lg(n) - 1) $ bits of entropy.\nEach poll of the random number generator is for $ lg(n-i) $ bits\nover $n-1$ entries:  $$ lg(2) + lg(3) + \\cdots + lg(n) = \\sum_{k=1}^{n} lg(k) = lg(n!) $$", 
            "title": "Fisher-Yates Shuffle"
        }, 
        {
            "location": "/Fisher-Yates-Shuffle/#the-wrong-way", 
            "text": "One can consider the following incorrect way to do the shuffle:  function nofish_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i n; i++) {\n    var idx = Math.floor(Math.random()*n);\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}  a slight variant:  function noyaks_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i n; i++) {\n    var idx = Math.floor(Math.random()*(n-1));\n    if (idx==i) { idx = n-1; }\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}  and another:  function nomaar_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i n; i++) {\n    var idx0 = Math.floor(Math.random()*n);\n    var idx1 = Math.floor(Math.random()*n);\n    t = a[idx0];\n    a[idx0] = a[idx1];\n    a[idx1] = t;\n  }\n}  Where the difference in  nofish_shuffle  and  noyaks_shuffle \nis to skip the current index when considering which element to permute. nomaar_shuffle  is yet another variant where each two elements are\nchosen at random and swapped $n$ times.  A friend of mine suggested an nice proof to show the above two\nshuffle algorithms provide incorrect results.  As above, there are $n!$ possible shuffles we want to choose from, with\nequal probability.\nSince  nofish_shuffle  is choosing each element to permute from the whole\narray, there are $n^n$ possible choices for the permutation, where\nsome permutations might be represented more than once.  Producing multiple configurations is permissible so long as  nofish_shuffle \nwould produce an equal distribution for each of the $n!$ configurations.\nSince $ n! \\nmid n^n $ for $n 2$, there must be some configurations that\nappear more often by the pigeonhole principle.  noyaks_shuffle  doesn't fare much better since there are $n^{n-1}$ possible\nchoices of permutation schedules and $n! \\nmid n^{n-1}$ for $n 2$.\nThe same type of analysis works for the  nomaar_shuffle  by noticing\nthat the number of permutation schedules is $n^{2 n}$ and that still $n! \\nmid n^{2 n}$.  Though hidden in such a large configuration space,  nofish_shuffle , noyaks_shuffle  and  nomaar_shuffle  produce configurations that are not uniformly\ndistributed.", 
            "title": "The Wrong Way"
        }, 
        {
            "location": "/Fisher-Yates-Shuffle/#addendum", 
            "text": "Sattalo's algorithm creates a random single cycle permutation.\nThe algorithm is similar to Fisher-Yates but does not allow the\nchoice of the current index element when swapping:  function sattalo_shuffle(a) {\n  var t, n = a.length;\n  for (var i=0; i (n-1); i++) {\n    var idx = i + 1 + Math.floor(Math.random()*(n-i-1));\n    t = a[i];\n    a[i] = a[idx];\n    a[idx] = t;\n  }\n}  There are $(n-1)!$ configurations, so we know the above algorithm\nsubsamples from the space of all permutation possibilities.  To see that it produces a single cycle, note that swapping elements\nhas two possibilities:    If both elements are in the same cycle, swapping elements creates\n  two disjoint cycles  If both elements are in different cycles, swapping elements creates\n  a single cycle   The swap step in Sattalo's algorithm can be thought of as swapping\na cycle of length one, the current index position, with another cycle pointed\nto by the chosen random index.\nSince these are two distinct cycles, they join to create a single cycle.\nThis is done $(n-1)$ times forcing a single large cycle.  To see that this draws uniformly from single cycle permutations, \nproceed inductively by noticing that if a single cycle of length $(n-1)$\nis produced uniformly at random, then extending it to a single cycle of\nlength $n$ by the above method will favor each of the $(n-1)$ possible\nextensions equally.", 
            "title": "Addendum"
        }, 
        {
            "location": "/Fisher-Yates-Shuffle/#2018-06-13", 
            "text": "", 
            "title": "2018-06-13"
        }, 
        {
            "location": "/Halting-Problem/", 
            "text": "Halting Problem\n\n\nThe Halting Problem asks whether there exists a program that takes other programs\nas input and determines whether they loop forever or halt.\n\n\nAssume such a program exists and call it \nHP\n.\n\n\nThe program \nHP(P,X)\n assumes:\n\n\n\n\nHP\n is a finite program\n\n\nHP\n stops in finite time\n\n\nHP\n takes as input a program, \nP\n, with input, \nX\n, both of finite length\n\n\nHP\n can access arbitrarily long memory such as a tape in a Turing Machine model.\n\n\n\n\nThough a bit far afield from the current topic, there also needs to be constraints on\nthe time it takes to access distant memory so as not to 'hide' computation in memory\naccess.\nFor example, assuming memory is a linear tape and the time to reach a distance, \nd\n,\nfrom the current location takes time proportional to \nd\n.\n\n\nConsider the program SPITE:\n\n\nSPITE(P) {\n\n  if (HP(P,P) reports P halts with P as input) {\n    while (true) {} // loop forever\n  }\n\n  else if (HP(P,P) reports P loops forever with P as input) {\n    halt // return\n  }\n\n}\n\n\n\n\nWhen we run \nSPITE(SPITE)\n (\nSPITE\n with itself as input), there are two cases:\n\n\n\n\nSPITE(SPITE)\n halts, in which case the first condition would have been hit, contradicting the subsequent action of looping forever.\n\n\nSPITE(SPITE)\n loops forever, in which case the second condition would have been hit, contradicting the subsequent action of halting.\n\n\n\n\nNo matter the path we take, we get a contradiction, proving the impossibility of \nHP\n existing with our given assumptions.\n\n\n\n\nA quick note as it applies to statement verification.\n\n\nThe proof is very much the same. \n\n\nTo proceed via a proof by contradiction, we assume a function called \nVerifier\n, which takes in a statement\nand returns whether that statement is true or false.\n\n\nWe have to allow for functions (\nVerifier\n is one after all) and so we need to differentiate between\nfunction evaluation and writing out a statement without evaluation.\n\n\nBelow, the convention \n{.}\n will be used to denote the \"source\" of a statement rather than it's evaluation.\nThat is, \n{f(s)}\n is the statement \nf(s)\n rather than the evaluation of the function \nf\n on statement \ns\n.\n\n\nWe construct the following functions:\n\n\nfunc FunctionVerifier(f,s)\n  if Verifier( { f(s) } ) return True\n  else return False\n\nfunc Spite(f)\n  if FunctionVerifier(f,f) return False\n  else return True\n\n\n\n\nWe then get a contradiction by asking what the return value of \nSpite(Spite)\n is.\n\n\nThe above is a bit sloppy because of the differentiation between function, function evaluation, statement, etc. and\nis why I prefer the Turing Machine model (or any more formal programming language model) but hopefully the intent\nshould be clear.\n\n\n2018-06-13", 
            "title": "Halting Problem"
        }, 
        {
            "location": "/Halting-Problem/#halting-problem", 
            "text": "The Halting Problem asks whether there exists a program that takes other programs\nas input and determines whether they loop forever or halt.  Assume such a program exists and call it  HP .  The program  HP(P,X)  assumes:   HP  is a finite program  HP  stops in finite time  HP  takes as input a program,  P , with input,  X , both of finite length  HP  can access arbitrarily long memory such as a tape in a Turing Machine model.   Though a bit far afield from the current topic, there also needs to be constraints on\nthe time it takes to access distant memory so as not to 'hide' computation in memory\naccess.\nFor example, assuming memory is a linear tape and the time to reach a distance,  d ,\nfrom the current location takes time proportional to  d .  Consider the program SPITE:  SPITE(P) {\n\n  if (HP(P,P) reports P halts with P as input) {\n    while (true) {} // loop forever\n  }\n\n  else if (HP(P,P) reports P loops forever with P as input) {\n    halt // return\n  }\n\n}  When we run  SPITE(SPITE)  ( SPITE  with itself as input), there are two cases:   SPITE(SPITE)  halts, in which case the first condition would have been hit, contradicting the subsequent action of looping forever.  SPITE(SPITE)  loops forever, in which case the second condition would have been hit, contradicting the subsequent action of halting.   No matter the path we take, we get a contradiction, proving the impossibility of  HP  existing with our given assumptions.   A quick note as it applies to statement verification.  The proof is very much the same.   To proceed via a proof by contradiction, we assume a function called  Verifier , which takes in a statement\nand returns whether that statement is true or false.  We have to allow for functions ( Verifier  is one after all) and so we need to differentiate between\nfunction evaluation and writing out a statement without evaluation.  Below, the convention  {.}  will be used to denote the \"source\" of a statement rather than it's evaluation.\nThat is,  {f(s)}  is the statement  f(s)  rather than the evaluation of the function  f  on statement  s .  We construct the following functions:  func FunctionVerifier(f,s)\n  if Verifier( { f(s) } ) return True\n  else return False\n\nfunc Spite(f)\n  if FunctionVerifier(f,f) return False\n  else return True  We then get a contradiction by asking what the return value of  Spite(Spite)  is.  The above is a bit sloppy because of the differentiation between function, function evaluation, statement, etc. and\nis why I prefer the Turing Machine model (or any more formal programming language model) but hopefully the intent\nshould be clear.", 
            "title": "Halting Problem"
        }, 
        {
            "location": "/Halting-Problem/#2018-06-13", 
            "text": "", 
            "title": "2018-06-13"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/", 
            "text": "Assorted Small Probability Problems\n\n\nCoupon Collector\n\n\nFind the expected time, $T$, to wait to collect $n$ different coupons, each appearing with probability $\\frac{1}{n}$.\n\n\nAssign the random variable $X_t$ to be the time taken to see a new coupon once $t$ have already been collected.\n\n\n$$ X_0 = 1 $$\n\n\n$$\n\\begin{align}\nE[X_t] \n = \\sum_{k=1}^{\\infty} k (\\frac{t}{n})^{k-1} (1 - \\frac{t}{n}) \\\\\n  \n = (1 - \\frac{t}{n}) ( \\sum_{k=0}^{\\infty} k (\\frac{t}{n})^k + \\sum_{k=0}^{\\infty} (\\frac{t}{n})^k ) \\\\\n  \n = (1 - \\frac{t}{n}) ( \\frac{ \\frac{t}{n}  }{ (1 - \\frac{t}{n} )^2 } + \\frac{1}{1 - \\frac{t}{n}} ) \\\\\n  \n = \\frac{n}{n-t}\n\\end{align}\n$$\n\n\n$$\nE[T] = E[ \\sum_{t=0}^{n-1} X_t ]\n$$\n\n\nSince the expectation is independent\n\n\n$$\n\\begin{align}\nE[ \\sum_{t=0}^{n-1} X_t ] \n = \\sum_{t=0}^{n-1} E[X_t] \\\\\n \n = \\frac{n}{n} + \\frac{n}{n-1} + \\frac{n}{n-2} + \\cdots + \\frac{n}{1} \\\\\n \n = \\sum_{t=0}^{n-1} \\frac{n}{n-t} \\\\\n \n = n ( \\sum_{t=0}^{n-1} \\frac{1}{n-t} ) \\\\\n \n = n \\cdot H_n\n\\end{align}\n$$\n\n\nWhere $H_n$ is the $n$-th harmonic number.\n\n\n$$\n\\begin{align}\nE[T] \n = n \\cdot H_n \\\\\n \n = n \\log n + \\gamma n + \\frac{1}{2} + O(\\frac{1}{n}) \\\\\n \n \\approx n \\log n \n \n\\end{align}\n$$\n\n\nBirthday Problem\n\n\n$n$ people are assigned a random integer uniformly at random from $[1,m]$.\nFor a given probability $p$, what is the relationship to $n$ and $m$ that\nat least two people have the same number.\n\n\n\n\n$Q_{n,m}$ the probability that no two of $n$ people with $m$ numbers have a number in common\n\n\n\n\n$$\n\\begin{align}\nQ_{n,m} \n = \\prod_{t=1}^{n} (1 - \\frac{t}{m}) \\\\\n \n \\le \\prod_{t=1}^{n} e^{-\\frac{t}{m}} \\\\\n \n = \\exp( -\\sum_{t=1}^{n} \\frac{t}{m} ) \\\\\n \n = \\exp( -\\frac{ {n+1 \\choose 2 } }{m} ) \\\\\n \n = \\exp( -\\frac{n (n+1)}{2 m} )\n\\end{align}\n$$\n\n\n$$\np \\approx 1 - \\exp( -\\frac{n (n+1)}{2 m} )\n$$\n\n\n$$\n\\to \\log \\frac{1}{1-p} \\approx \\frac{ n (n+1)}{2 m}\n$$\n\n\nFor $n \n 1$ we can approximate further:\n\n\n$$\n\\begin{align}\n \n \\to \\log \\frac{1}{1-p} \\approx \\frac{ n^2 }{2 m} \\\\\n \n \\to n \\approx \\sqrt{ 2 m \\log \\frac{1}{1-p} } \\\\\n\\end{align}\n$$\n\n\nFor $m=365$ we get $n \\approx 22.494...$.\n\n\nBest Choice Problem\n\n\n$n$ candidates, with each that can be ranked relative to the others.\nThe candidates file in one at a time and are ranked relative to the candidates\nalready seen.\nWhen each candidate is first seen, a decision is made to accept or reject them.\n\n\nFind the optimal stopping point to maximize the likelihood of getting the ideal candidate.\n\n\nOne strategy is a \"wait then choose\" strategy, where $r$ of $n$ candidates are considered\nand then the next candidate chosen that is better than all of the $r$ previously seen.\n\n\nWith this in mind, the probability becomes:\n\n\n$$\n\\begin{align}\nP(r) \n = \\sum_{k=1}^{n} \\Pr \\{ \\text{ candidate k chosen } \\\n \\text{ candidate k is best } \\} \\\\\n \n = \\sum_{k=1}^{n} \\Pr \\{ \\text{ next best candidate in} \\in [1 \\dots r] | \\text{ candidate k is best } \\} \\\\\n \n = \\sum_{k=r+1}^{n} \\frac{r}{k-1} \\cdot \\frac{1}{n} \\\\\n \n = \\frac{r}{n} \\sum_{k=r}^{n-1} \\frac{1}{k} \\\\\n \n = \\frac{r}{n} ( H_{n-1} - H_{r} )\n\\end{align}\n$$\n\n\nConsider\n\n\n$$\n\\begin{align}\nf(r) \n = \\frac{r}{n} ( H_{n-1} - H_{r} ) \\\\\n \n \\approx \\frac{r}{n} ( \\ln(n) - \\ln(r) )\n\\end{align}\n$$\n\n\nIf $f(r)$ was continuous and had a single global maximum in the range of $[1 \\dots n]$,\nwe could find the maximum by evaluating the derivative of $f(r)$ at 0.\n\n\nThat is:\n\n\n$$\n\\begin{align}\n \\frac{d}{dr} f(r) \n \\approx \\frac{d}{dr} ( \\frac{r}{n} ( \\ln(n) - \\ln(r) ) \\\\\n \n = \\ln(n) - \\ln(r) - 1\n\\end{align}\n$$\n\n\n$$\n\\begin{align}\n\\to \n \\ln(n) - \\ln(r) - 1 \n = 0 \\\\\n\\to \n \\frac{r}{n} = \\frac{1}{e}\n\\end{align}\n$$\n\n\nMeaning, the best strategy is to wait to see $\\frac{n}{e}$ candidates and then take the\nnext best one.\n\n\nHat Derangement\n\n\n$n$ people each take a random hat out of a bag after throwing them all in.\nFind the probability of no person getting their own hat back.\n\n\nA crude way to do this is just consider the probability of a person randomly choosing a hat\nwithout considering the previously drawn hats.\nUsing this approximation, there are $(1-\\frac{1}{n})$ choices for some other hat,\nleaving the probability of no person chooses their own hat as:\n\n\n$$\n(1 - \\frac{1}{n})^{n} \\to \\frac{1}{e}\n$$\n\n\nThe more complete solution is to make an inclusion-exclusion argument\nby counting the number of possibilities.\nCall $S$ the set of all permutations, and $F_k$ be the set of all permutations\nthat fixes position $k$, then the number of permutations is:\n\n\n$$\n\\begin{align}\n \n |S| - |F_0 \\cup F_1 \\cup F_2 \\cup \\dots \\cup F_{n-1}| \\\\\n \n = |S| - \\sum_{k=0}^{n-1} |F_k| + \\sum_{k=0}^{n-1} \\sum_{k'=k+1}^{n-1} |F_k \\cap F_{k'}| - \\dots + (-1)^{n-1} |F_0 \\cap F_1 \\cap \\dots \\cap F_{n-1}|\n\\end{align}\n$$\n\n\nSymmetry of the sets allows us to consolidate the counts:\n\n\n$$\n\\begin{align}\n \n = n! - \\binom{n}{1} (n-1)! + \\binom{n}{2} (n-2)! - \\binom{n}{3} (n-3)! + \\dots + (-1)^{n-1} \\binom{n}{n} 1! \\\\\n \n = \\sum_{k=0}^{n-1} (-1)^k \\binom{n}{k} (n-k)!  \\\\\n \n = n! ( \\sum_{k=0}^{n} \\frac{ (-1)^k }{ k! } ) \\\\\n \n \\approx n! e^{-1}\n\\end{align}\n$$\n\n\nSince there are $n!$ total configurations, the probability of a permutation not leaving any position fixed is:\n\n\n$$\n\\begin{align}\n \n = \\frac{n! e^{-1} }{n!}  \\\\\n \n = \\frac{1}{e}\n\\end{align}\n$$\n\n\nLabeled Box Problem\n\n\nThere are $n$ boxes each assigned randomly a unique number from $1$ to $n$ (inclusive) and\n$n$ participants each assigned a unique number from $1$ to $n$ (inclusive).\nEach participant can examine half of the boxes, with the ability to choose later\nboxes depending on what was seen previously.\nNo participant is allowed to communicate once the process starts.\n\n\nFind a reasonable lower bound on the probability of each participant seeing their own\nnumber.\n\n\nBy considering the numbers in the boxes as permutations, each participant can\nstart with the box position of the number they've been assigned and continue on,\njumping to the subsequent box positions from the revealed number after each box opening.\n\n\nThe probability each participant sees their own number in this process is the the chance\nthat the \"box permutation\" has a maximum cycle less than or equal to $\\lfloor \\frac{n}{2} \\rfloor$.\n\n\nThe trivial cycle permutation $(1,2,3,\\dots,n)$ has $\\binom{n}{l}$ ways to choose a\nparticular cycle of length $l$.\nIn disjoint cycle notation, it should be clear that for a cycle of length $l$, there are\n$l!$ different presentations.\nThe remaining elements can be permuted arbitrarily yielding the number of cycles of length $l$:\n\n\n$$\n\\begin{align}\n\n \\binom{n}{l}  \\cdot l! \\cdot (n-l)! \\\\\n\n = \\frac{n!}{l}\n\\end{align}\n$$\n\n\nSumming over all cycles of length $l \n \\lfloor \\frac{n}{2} \\rfloor$:\n\n\n$$\n\\begin{align}\n \n \\sum_{l=\\lfloor \\frac{n}{2} \\rfloor +1} \\frac{n!}{l} \\\\\n \n = n! \\sum_{l=\\lfloor \\frac{n}{2} \\rfloor + 1} \\frac{1}{l} \\\\\n \n = n! ( H_n - H_{\\lfloor \\frac{n}{2} \\rfloor + 1} )\n\\end{align}\n$$\n\n\nThe total number of permutations is $n!$, so the resulting probability of having no cycle\ngreater than $\\lfloor \\frac{n}{2} \\rfloor$ is:\n\n\n$$\n1 - (H_{n} - H_{\\lfloor \\frac{n}{2} \\rfloor + 1})\n$$\n\n\nSince\n\n\n$$ \\lim_{n \\to \\infty} (H_n - \\ln n) = \\gamma $$\n\n\nwe get:\n\n\n$$\n\\begin{align}\n \n \\lim_{n \\to \\infty} ( 1 - (H_{n} - H_{\\lfloor \\frac{n}{2} \\rfloor + 1} ) ) \\\\\n \n = 1 - (\\gamma - \\gamma) - \\ln 2 \\\\\n \n = 1 - \\ln 2\n\\end{align}\n$$\n\n\nUnfair Coin\n\n\nGiven an unfair coin with unknown probability $p$ of landing heads, find a reasonably efficient\nprocess that yields $0.5$ probability and estimate the time it takes to 'draw'\nfrom the resulting fair distribution.\n\n\n$$\n\\Pr \\{ H T \\} = \\Pr \\{ T H \\} = p (1-p) = (1-p) p\n$$", 
            "title": "Assorted Small Probability Problems"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#assorted-small-probability-problems", 
            "text": "", 
            "title": "Assorted Small Probability Problems"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#coupon-collector", 
            "text": "Find the expected time, $T$, to wait to collect $n$ different coupons, each appearing with probability $\\frac{1}{n}$.  Assign the random variable $X_t$ to be the time taken to see a new coupon once $t$ have already been collected.  $$ X_0 = 1 $$  $$\n\\begin{align}\nE[X_t]   = \\sum_{k=1}^{\\infty} k (\\frac{t}{n})^{k-1} (1 - \\frac{t}{n}) \\\\\n    = (1 - \\frac{t}{n}) ( \\sum_{k=0}^{\\infty} k (\\frac{t}{n})^k + \\sum_{k=0}^{\\infty} (\\frac{t}{n})^k ) \\\\\n    = (1 - \\frac{t}{n}) ( \\frac{ \\frac{t}{n}  }{ (1 - \\frac{t}{n} )^2 } + \\frac{1}{1 - \\frac{t}{n}} ) \\\\\n    = \\frac{n}{n-t}\n\\end{align}\n$$  $$\nE[T] = E[ \\sum_{t=0}^{n-1} X_t ]\n$$  Since the expectation is independent  $$\n\\begin{align}\nE[ \\sum_{t=0}^{n-1} X_t ]   = \\sum_{t=0}^{n-1} E[X_t] \\\\\n   = \\frac{n}{n} + \\frac{n}{n-1} + \\frac{n}{n-2} + \\cdots + \\frac{n}{1} \\\\\n   = \\sum_{t=0}^{n-1} \\frac{n}{n-t} \\\\\n   = n ( \\sum_{t=0}^{n-1} \\frac{1}{n-t} ) \\\\\n   = n \\cdot H_n\n\\end{align}\n$$  Where $H_n$ is the $n$-th harmonic number.  $$\n\\begin{align}\nE[T]   = n \\cdot H_n \\\\\n   = n \\log n + \\gamma n + \\frac{1}{2} + O(\\frac{1}{n}) \\\\\n   \\approx n \\log n   \n\\end{align}\n$$", 
            "title": "Coupon Collector"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#birthday-problem", 
            "text": "$n$ people are assigned a random integer uniformly at random from $[1,m]$.\nFor a given probability $p$, what is the relationship to $n$ and $m$ that\nat least two people have the same number.   $Q_{n,m}$ the probability that no two of $n$ people with $m$ numbers have a number in common   $$\n\\begin{align}\nQ_{n,m}   = \\prod_{t=1}^{n} (1 - \\frac{t}{m}) \\\\\n   \\le \\prod_{t=1}^{n} e^{-\\frac{t}{m}} \\\\\n   = \\exp( -\\sum_{t=1}^{n} \\frac{t}{m} ) \\\\\n   = \\exp( -\\frac{ {n+1 \\choose 2 } }{m} ) \\\\\n   = \\exp( -\\frac{n (n+1)}{2 m} )\n\\end{align}\n$$  $$\np \\approx 1 - \\exp( -\\frac{n (n+1)}{2 m} )\n$$  $$\n\\to \\log \\frac{1}{1-p} \\approx \\frac{ n (n+1)}{2 m}\n$$  For $n   1$ we can approximate further:  $$\n\\begin{align}\n   \\to \\log \\frac{1}{1-p} \\approx \\frac{ n^2 }{2 m} \\\\\n   \\to n \\approx \\sqrt{ 2 m \\log \\frac{1}{1-p} } \\\\\n\\end{align}\n$$  For $m=365$ we get $n \\approx 22.494...$.", 
            "title": "Birthday Problem"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#best-choice-problem", 
            "text": "$n$ candidates, with each that can be ranked relative to the others.\nThe candidates file in one at a time and are ranked relative to the candidates\nalready seen.\nWhen each candidate is first seen, a decision is made to accept or reject them.  Find the optimal stopping point to maximize the likelihood of getting the ideal candidate.  One strategy is a \"wait then choose\" strategy, where $r$ of $n$ candidates are considered\nand then the next candidate chosen that is better than all of the $r$ previously seen.  With this in mind, the probability becomes:  $$\n\\begin{align}\nP(r)   = \\sum_{k=1}^{n} \\Pr \\{ \\text{ candidate k chosen } \\  \\text{ candidate k is best } \\} \\\\\n   = \\sum_{k=1}^{n} \\Pr \\{ \\text{ next best candidate in} \\in [1 \\dots r] | \\text{ candidate k is best } \\} \\\\\n   = \\sum_{k=r+1}^{n} \\frac{r}{k-1} \\cdot \\frac{1}{n} \\\\\n   = \\frac{r}{n} \\sum_{k=r}^{n-1} \\frac{1}{k} \\\\\n   = \\frac{r}{n} ( H_{n-1} - H_{r} )\n\\end{align}\n$$  Consider  $$\n\\begin{align}\nf(r)   = \\frac{r}{n} ( H_{n-1} - H_{r} ) \\\\\n   \\approx \\frac{r}{n} ( \\ln(n) - \\ln(r) )\n\\end{align}\n$$  If $f(r)$ was continuous and had a single global maximum in the range of $[1 \\dots n]$,\nwe could find the maximum by evaluating the derivative of $f(r)$ at 0.  That is:  $$\n\\begin{align}\n \\frac{d}{dr} f(r)   \\approx \\frac{d}{dr} ( \\frac{r}{n} ( \\ln(n) - \\ln(r) ) \\\\\n   = \\ln(n) - \\ln(r) - 1\n\\end{align}\n$$  $$\n\\begin{align}\n\\to   \\ln(n) - \\ln(r) - 1   = 0 \\\\\n\\to   \\frac{r}{n} = \\frac{1}{e}\n\\end{align}\n$$  Meaning, the best strategy is to wait to see $\\frac{n}{e}$ candidates and then take the\nnext best one.", 
            "title": "Best Choice Problem"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#hat-derangement", 
            "text": "$n$ people each take a random hat out of a bag after throwing them all in.\nFind the probability of no person getting their own hat back.  A crude way to do this is just consider the probability of a person randomly choosing a hat\nwithout considering the previously drawn hats.\nUsing this approximation, there are $(1-\\frac{1}{n})$ choices for some other hat,\nleaving the probability of no person chooses their own hat as:  $$\n(1 - \\frac{1}{n})^{n} \\to \\frac{1}{e}\n$$  The more complete solution is to make an inclusion-exclusion argument\nby counting the number of possibilities.\nCall $S$ the set of all permutations, and $F_k$ be the set of all permutations\nthat fixes position $k$, then the number of permutations is:  $$\n\\begin{align}\n   |S| - |F_0 \\cup F_1 \\cup F_2 \\cup \\dots \\cup F_{n-1}| \\\\\n   = |S| - \\sum_{k=0}^{n-1} |F_k| + \\sum_{k=0}^{n-1} \\sum_{k'=k+1}^{n-1} |F_k \\cap F_{k'}| - \\dots + (-1)^{n-1} |F_0 \\cap F_1 \\cap \\dots \\cap F_{n-1}|\n\\end{align}\n$$  Symmetry of the sets allows us to consolidate the counts:  $$\n\\begin{align}\n   = n! - \\binom{n}{1} (n-1)! + \\binom{n}{2} (n-2)! - \\binom{n}{3} (n-3)! + \\dots + (-1)^{n-1} \\binom{n}{n} 1! \\\\\n   = \\sum_{k=0}^{n-1} (-1)^k \\binom{n}{k} (n-k)!  \\\\\n   = n! ( \\sum_{k=0}^{n} \\frac{ (-1)^k }{ k! } ) \\\\\n   \\approx n! e^{-1}\n\\end{align}\n$$  Since there are $n!$ total configurations, the probability of a permutation not leaving any position fixed is:  $$\n\\begin{align}\n   = \\frac{n! e^{-1} }{n!}  \\\\\n   = \\frac{1}{e}\n\\end{align}\n$$", 
            "title": "Hat Derangement"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#labeled-box-problem", 
            "text": "There are $n$ boxes each assigned randomly a unique number from $1$ to $n$ (inclusive) and\n$n$ participants each assigned a unique number from $1$ to $n$ (inclusive).\nEach participant can examine half of the boxes, with the ability to choose later\nboxes depending on what was seen previously.\nNo participant is allowed to communicate once the process starts.  Find a reasonable lower bound on the probability of each participant seeing their own\nnumber.  By considering the numbers in the boxes as permutations, each participant can\nstart with the box position of the number they've been assigned and continue on,\njumping to the subsequent box positions from the revealed number after each box opening.  The probability each participant sees their own number in this process is the the chance\nthat the \"box permutation\" has a maximum cycle less than or equal to $\\lfloor \\frac{n}{2} \\rfloor$.  The trivial cycle permutation $(1,2,3,\\dots,n)$ has $\\binom{n}{l}$ ways to choose a\nparticular cycle of length $l$.\nIn disjoint cycle notation, it should be clear that for a cycle of length $l$, there are\n$l!$ different presentations.\nThe remaining elements can be permuted arbitrarily yielding the number of cycles of length $l$:  $$\n\\begin{align}  \\binom{n}{l}  \\cdot l! \\cdot (n-l)! \\\\  = \\frac{n!}{l}\n\\end{align}\n$$  Summing over all cycles of length $l   \\lfloor \\frac{n}{2} \\rfloor$:  $$\n\\begin{align}\n   \\sum_{l=\\lfloor \\frac{n}{2} \\rfloor +1} \\frac{n!}{l} \\\\\n   = n! \\sum_{l=\\lfloor \\frac{n}{2} \\rfloor + 1} \\frac{1}{l} \\\\\n   = n! ( H_n - H_{\\lfloor \\frac{n}{2} \\rfloor + 1} )\n\\end{align}\n$$  The total number of permutations is $n!$, so the resulting probability of having no cycle\ngreater than $\\lfloor \\frac{n}{2} \\rfloor$ is:  $$\n1 - (H_{n} - H_{\\lfloor \\frac{n}{2} \\rfloor + 1})\n$$  Since  $$ \\lim_{n \\to \\infty} (H_n - \\ln n) = \\gamma $$  we get:  $$\n\\begin{align}\n   \\lim_{n \\to \\infty} ( 1 - (H_{n} - H_{\\lfloor \\frac{n}{2} \\rfloor + 1} ) ) \\\\\n   = 1 - (\\gamma - \\gamma) - \\ln 2 \\\\\n   = 1 - \\ln 2\n\\end{align}\n$$", 
            "title": "Labeled Box Problem"
        }, 
        {
            "location": "/Assorted-Small-Probability-Problems/#unfair-coin", 
            "text": "Given an unfair coin with unknown probability $p$ of landing heads, find a reasonably efficient\nprocess that yields $0.5$ probability and estimate the time it takes to 'draw'\nfrom the resulting fair distribution.  $$\n\\Pr \\{ H T \\} = \\Pr \\{ T H \\} = p (1-p) = (1-p) p\n$$", 
            "title": "Unfair Coin"
        }, 
        {
            "location": "/Probability-Notes/", 
            "text": "Probability Notes\n\n\nBy convention:\n\n\n$$\nE^n[X] \\stackrel{def}{=} (E[X])^n\n$$\n\n\nIndependence of Expectation (finite)\n\n\nClaim\n:\n\n\n$$\nE[ \\sum_{k=0}^{n-1} X_k ] = \\sum_{k=0}^{n-1} E[X_k]\n$$\n\n\nProof\n:\n\n\n$$\n\\begin{align}\nE[ X + Y ] \n = \\int \\int (s + t) \\Pr\\{ X = s \\  \\\n \\ Y = t \\} \\ ds \\ dt \\\\\n \n = \\int \\int s \\Pr \\{ X = s \\ \\\n \\  Y = t \\} \\ ds \\ dt + \\int \\int t \\Pr \\{ X = s \\ \\\n \\ Y = t \\} \\ ds \\ dt \\\\\n \n = \\int \\int s \\Pr \\{ X = s \\ \\\n \\ Y = t \\} \\ dt \\ ds + \\int \\int t \\Pr \\{ X = s \\ \\\n \\ Y = t \\} \\ ds \\ dt \\\\\n \n = \\int s \\Pr \\{ X = s \\} \\ ds + \\int t \\Pr \\{ Y = t \\} \\ dt \\\\\n \n = E[X] + E[Y]\n\\end{align}\n$$\n\n\nInduction can be used to extend to the general case:\n\n\n$$\nE[ \\sum_{k=0}^{n-1} X_k ] = \\sum_{k=0}^{n-1} E[X_k]\n$$\n\n\nBayes' Theorem\n\n\n$$\n\\Pr\\{ A | B \\} = \\frac{ \\Pr\\{ A \\\n B \\} }{ \\Pr\\{ B \\} }\n$$\n\n\n$$\n\\Pr\\{ B | A \\} = \\frac{ \\Pr\\{ A \\\n B \\} }{ \\Pr\\{ A \\} }\n$$\n\n\n$$\n\\Pr\\{ A | B \\} = \\frac{ \\Pr\\{ B | A \\} \\Pr\\{ A \\} }{ \\Pr\\{ B \\} }\n$$\n\n\nVariance\n\n\n$$ \\mathrm{Var}[X] \\stackrel{def}{=} E[(X - E[X])^2] = E[X^2] - (E[X])^2 $$\n\n\nMoment Generating Functions\n\n\n$$\nM_X(t) \\stackrel{def}{=} E[ e^{t X} ] = \\sum_{k=0}^{\\infty} \\frac{t^k E[X^k]}{k!}\n$$\n\n\n\n\nIf $X$ and $Y$ and independent random variables, then:\n\n\n$$\nM_{X + Y}(t) = E[ e^{t(X + Y)} ] = E[ e^{tX} e^{tY} ] = M_X(t) \\cdot M_Y(t)\n$$\n\n\n\n\n$$\n\\begin{align}\n\\frac{d^n}{dt} M_X(t) \n = \\frac{d^{(n)}}{dt} (  \\sum_{k=0}^{\\infty} \\frac{t^n E[X^n]}{k!} ) \\\\\n \n = \\sum_{k=n} \\frac{t^{k-n} E[X^k]}{(k-n)!} \\\\\n\\to \\frac{d^n}{dt} M_X(0) \n = E[X^n]\n\\end{align}\n$$\n\n\nJensen's Inequality\n\n\nClaim\n:\n\n\nIf $f(x)$ is a convex function, then:\n\n\n$$\nE[f(X)] \\ge f(E[X])\n$$\n\n\nProof\n:\n\n\nTaylor's theorem gives us:\n\n\n$$\n\\exists\\ c : f(x) = f(\\mu) + f'(\\mu)(x - \\mu) + \\frac{f''(c)(x-\\mu)^2}{2}\n$$\n\n\nSince $f(x)$ is concave, we know:\n\n\n$$\nf(\\mu) + f'(\\mu)(x - \\mu) + \\frac{f''(c)(x-\\mu)^2}{2} \\ge f(\\mu) + f'(\\mu)(x-\\mu)\n$$\n\n\nThis gives us:\n\n\n$$\nE[f(X)] \\ge E[ f(\\mu) + f'(\\mu)(X - \\mu) ]\n$$\n\n\nChoose $ \\mu = E[X] $:\n\n\n$$\n\\begin{align}\nE[ f(\\mu) + f'(\\mu)(X-\\mu) ] \n = E[ f(E[X]) + f'(E[X])(X - E[X]) ] \\\\\n \n = E[ f( E[X] ) ]  + f'(E[X])(E[X] - E[E[X]]) \\\\\n \n = f(E[X]) + 0 \\\\\n\\end{align}\n$$\n\n\n$$\n\\to E[f(X)] \\ge f(E[X])\n$$\n\n\nMarkov's Inequality\n\n\nClaim\n:\n\n\n$$\nX \\ge 0, a \n 0\n$$\n\n\n$$\n\\Pr \\{ X \\ge a \\} \\le \\frac{E[X]}{a}\n$$\n\n\nProof\n:\n\n\nSince $X \\ge 0$ and $a \n 0$:\n\n\n$$\n\\begin{align}\nE[X] \n = \\int_0^{\\infty} t\\ p_X(t) dt \\\\\n \n = \\int_0^{a} t\\ p_X(t) dt + \\int_a^{\\infty} t\\ p_X(t) dt \\\\\n \n \\ge \\int_{a}^{\\infty} t\\ p_X(t) dt \\\\\n \n \\ge \\int_{a}^{\\infty} a\\ p_X(t) dt \\\\\n \n = a \\int_{a}^{\\infty} p_X(t) dt \\\\\n \n = a \\Pr\\{ X \\ge a \\} \\\\\n\\end{align}\n$$\n\n\n$a \n 0$, so we can divide:\n\n\n$$\n\\to \\Pr\\{X \\ge a \\} \\le \\frac{E[X]}{a}\n$$\n\n\nChebyshev's Inequality\n\n\nClaim\n:\n\n\n$$\na \n 0\n$$\n\n\n$$\n\\Pr\\{|X - E[X]| \\ge a \\} \\le \\frac{ \\mathrm{Var}[X] }{a^2}\n$$\n\n\nProof\n:\n\n\n$$\n\\begin{align}\n\\Pr\\{ |X - E[X]| \\ge a \\} \n = \\Pr\\{ (X - E[X])^2 \\ge a^2 \\} \\\\\n \n \\le \\frac{E[ (X-E[X])^2 ]}{a^2} \\\\\n \n = \\frac{\\mathrm{Var}[X]}{a^2}\n\\end{align}\n$$\n\n\nBy Markov's and the definition of variance.\n\n\nChernoff Bound\n\n\n$$\nX \\ge 0, a \n 0\n$$\n\n\n$$\n\\Pr\\{ X \\ge a \\} = \\Pr\\{ e^{tX} \\ge e^{ta} \\} \\le \\frac{E[e^{tX}]}{e^{ta}}\n$$\n\n\n$$\n\\Pr\\{ X \\ge a \\} \\le \\min_{t\n0} \\frac{E[e^{tX}]}{e^{ta}}\n$$\n\n\nThis can be seen by a straight forward application of Markov's inequality.\nThe parameter $t$ can be chosen to taste.\n\n\n\n\nGeneralized extreme value distribution (GEV) or Fisher Tippett Gnedenko theorem:\n\n\n$$\nX_0, X_1, \\cdots, X_{n-1} \n \\ \\ \\ \\text{  i.i.d. RVs}  \\\\\n\\lim_{n \\to \\infty} P( \\frac{max(X_0, X_1, \\cdots, X_{n-1}) - b_n}{a_n}  \\le x) \n \\ \\ = G(x) \\\\\nG_{\\gamma,a,b}(x) = \\exp( -(1 + (\\frac{x-b}{a})\\gamma)^{-\\frac{1}{\\gamma}}), \\ \\ \\ \\  \n 1 + (\\frac{x-b}{a}) \\gamma  \n 0\n\\end{align}\n$$\n\n\nWhere $G_{\\gamma,a,b}(x)$ above is the general form of the special cases of Gumbel, Frechet and the Weibull family of distributions.\n\n\nwiki\n\n\n2018-08-04", 
            "title": "Probability Notes"
        }, 
        {
            "location": "/Probability-Notes/#probability-notes", 
            "text": "By convention:  $$\nE^n[X] \\stackrel{def}{=} (E[X])^n\n$$", 
            "title": "Probability Notes"
        }, 
        {
            "location": "/Probability-Notes/#independence-of-expectation-finite", 
            "text": "Claim :  $$\nE[ \\sum_{k=0}^{n-1} X_k ] = \\sum_{k=0}^{n-1} E[X_k]\n$$  Proof :  $$\n\\begin{align}\nE[ X + Y ]   = \\int \\int (s + t) \\Pr\\{ X = s \\  \\  \\ Y = t \\} \\ ds \\ dt \\\\\n   = \\int \\int s \\Pr \\{ X = s \\ \\  \\  Y = t \\} \\ ds \\ dt + \\int \\int t \\Pr \\{ X = s \\ \\  \\ Y = t \\} \\ ds \\ dt \\\\\n   = \\int \\int s \\Pr \\{ X = s \\ \\  \\ Y = t \\} \\ dt \\ ds + \\int \\int t \\Pr \\{ X = s \\ \\  \\ Y = t \\} \\ ds \\ dt \\\\\n   = \\int s \\Pr \\{ X = s \\} \\ ds + \\int t \\Pr \\{ Y = t \\} \\ dt \\\\\n   = E[X] + E[Y]\n\\end{align}\n$$  Induction can be used to extend to the general case:  $$\nE[ \\sum_{k=0}^{n-1} X_k ] = \\sum_{k=0}^{n-1} E[X_k]\n$$", 
            "title": "Independence of Expectation (finite)"
        }, 
        {
            "location": "/Probability-Notes/#bayes-theorem", 
            "text": "$$\n\\Pr\\{ A | B \\} = \\frac{ \\Pr\\{ A \\  B \\} }{ \\Pr\\{ B \\} }\n$$  $$\n\\Pr\\{ B | A \\} = \\frac{ \\Pr\\{ A \\  B \\} }{ \\Pr\\{ A \\} }\n$$  $$\n\\Pr\\{ A | B \\} = \\frac{ \\Pr\\{ B | A \\} \\Pr\\{ A \\} }{ \\Pr\\{ B \\} }\n$$", 
            "title": "Bayes' Theorem"
        }, 
        {
            "location": "/Probability-Notes/#variance", 
            "text": "$$ \\mathrm{Var}[X] \\stackrel{def}{=} E[(X - E[X])^2] = E[X^2] - (E[X])^2 $$", 
            "title": "Variance"
        }, 
        {
            "location": "/Probability-Notes/#moment-generating-functions", 
            "text": "$$\nM_X(t) \\stackrel{def}{=} E[ e^{t X} ] = \\sum_{k=0}^{\\infty} \\frac{t^k E[X^k]}{k!}\n$$   If $X$ and $Y$ and independent random variables, then:  $$\nM_{X + Y}(t) = E[ e^{t(X + Y)} ] = E[ e^{tX} e^{tY} ] = M_X(t) \\cdot M_Y(t)\n$$   $$\n\\begin{align}\n\\frac{d^n}{dt} M_X(t)   = \\frac{d^{(n)}}{dt} (  \\sum_{k=0}^{\\infty} \\frac{t^n E[X^n]}{k!} ) \\\\\n   = \\sum_{k=n} \\frac{t^{k-n} E[X^k]}{(k-n)!} \\\\\n\\to \\frac{d^n}{dt} M_X(0)   = E[X^n]\n\\end{align}\n$$", 
            "title": "Moment Generating Functions"
        }, 
        {
            "location": "/Probability-Notes/#jensens-inequality", 
            "text": "Claim :  If $f(x)$ is a convex function, then:  $$\nE[f(X)] \\ge f(E[X])\n$$  Proof :  Taylor's theorem gives us:  $$\n\\exists\\ c : f(x) = f(\\mu) + f'(\\mu)(x - \\mu) + \\frac{f''(c)(x-\\mu)^2}{2}\n$$  Since $f(x)$ is concave, we know:  $$\nf(\\mu) + f'(\\mu)(x - \\mu) + \\frac{f''(c)(x-\\mu)^2}{2} \\ge f(\\mu) + f'(\\mu)(x-\\mu)\n$$  This gives us:  $$\nE[f(X)] \\ge E[ f(\\mu) + f'(\\mu)(X - \\mu) ]\n$$  Choose $ \\mu = E[X] $:  $$\n\\begin{align}\nE[ f(\\mu) + f'(\\mu)(X-\\mu) ]   = E[ f(E[X]) + f'(E[X])(X - E[X]) ] \\\\\n   = E[ f( E[X] ) ]  + f'(E[X])(E[X] - E[E[X]]) \\\\\n   = f(E[X]) + 0 \\\\\n\\end{align}\n$$  $$\n\\to E[f(X)] \\ge f(E[X])\n$$", 
            "title": "Jensen's Inequality"
        }, 
        {
            "location": "/Probability-Notes/#markovs-inequality", 
            "text": "Claim :  $$\nX \\ge 0, a   0\n$$  $$\n\\Pr \\{ X \\ge a \\} \\le \\frac{E[X]}{a}\n$$  Proof :  Since $X \\ge 0$ and $a   0$:  $$\n\\begin{align}\nE[X]   = \\int_0^{\\infty} t\\ p_X(t) dt \\\\\n   = \\int_0^{a} t\\ p_X(t) dt + \\int_a^{\\infty} t\\ p_X(t) dt \\\\\n   \\ge \\int_{a}^{\\infty} t\\ p_X(t) dt \\\\\n   \\ge \\int_{a}^{\\infty} a\\ p_X(t) dt \\\\\n   = a \\int_{a}^{\\infty} p_X(t) dt \\\\\n   = a \\Pr\\{ X \\ge a \\} \\\\\n\\end{align}\n$$  $a   0$, so we can divide:  $$\n\\to \\Pr\\{X \\ge a \\} \\le \\frac{E[X]}{a}\n$$", 
            "title": "Markov's Inequality"
        }, 
        {
            "location": "/Probability-Notes/#chebyshevs-inequality", 
            "text": "Claim :  $$\na   0\n$$  $$\n\\Pr\\{|X - E[X]| \\ge a \\} \\le \\frac{ \\mathrm{Var}[X] }{a^2}\n$$  Proof :  $$\n\\begin{align}\n\\Pr\\{ |X - E[X]| \\ge a \\}   = \\Pr\\{ (X - E[X])^2 \\ge a^2 \\} \\\\\n   \\le \\frac{E[ (X-E[X])^2 ]}{a^2} \\\\\n   = \\frac{\\mathrm{Var}[X]}{a^2}\n\\end{align}\n$$  By Markov's and the definition of variance.", 
            "title": "Chebyshev's Inequality"
        }, 
        {
            "location": "/Probability-Notes/#chernoff-bound", 
            "text": "$$\nX \\ge 0, a   0\n$$  $$\n\\Pr\\{ X \\ge a \\} = \\Pr\\{ e^{tX} \\ge e^{ta} \\} \\le \\frac{E[e^{tX}]}{e^{ta}}\n$$  $$\n\\Pr\\{ X \\ge a \\} \\le \\min_{t 0} \\frac{E[e^{tX}]}{e^{ta}}\n$$  This can be seen by a straight forward application of Markov's inequality.\nThe parameter $t$ can be chosen to taste.   Generalized extreme value distribution (GEV) or Fisher Tippett Gnedenko theorem:  $$\nX_0, X_1, \\cdots, X_{n-1}   \\ \\ \\ \\text{  i.i.d. RVs}  \\\\\n\\lim_{n \\to \\infty} P( \\frac{max(X_0, X_1, \\cdots, X_{n-1}) - b_n}{a_n}  \\le x)   \\ \\ = G(x) \\\\\nG_{\\gamma,a,b}(x) = \\exp( -(1 + (\\frac{x-b}{a})\\gamma)^{-\\frac{1}{\\gamma}}), \\ \\ \\ \\    1 + (\\frac{x-b}{a}) \\gamma    0\n\\end{align}\n$$  Where $G_{\\gamma,a,b}(x)$ above is the general form of the special cases of Gumbel, Frechet and the Weibull family of distributions.  wiki", 
            "title": "Chernoff Bound"
        }, 
        {
            "location": "/Probability-Notes/#2018-08-04", 
            "text": "", 
            "title": "2018-08-04"
        }, 
        {
            "location": "/Amdahls-Law/", 
            "text": "Amdahl's Law\n\n\n\n\n$T_s$ - Time for a serial task\n\n\n$p$ - portion of a task that can be parallelized ($ p \\in [0,1]$)\n\n\n$n$ - number of processes that can be used to parallelize\n\n\n$T_{p,n}$ - Time for a parallel task with $p$ and $n$\n\n\n$F_{p,n} = \\frac{T_s}{T_{p,n}} $ - Speedup factor for $p$ and $n$\n\n\n\n\n$$\nT_{p,n} = T_s (1-p) + \\frac{T_s p}{n} \\\\\n\\to \\frac{T_{p,n}}{T_s} = 1 - p + \\frac{p}{n} \\\\\n\\to \\frac{T_s}{T_{p,n}} = \\frac{1}{ 1 - p + \\frac{p}{n} } \\\\\n\\to F_{p,n} = \\frac{1}{ 1 - p + \\frac{p}{n} }\n$$\n\n\nFor a completely serial task ($p=0$):\n\n\n$$\nF_{p,n} = \\frac{1}{ 1 - 0 + \\frac{0}{n} } = 1\n$$\n\n\nFor a completely parallel task ($p=1$):\n\n\n$$\nF_{p,n} = \\frac{1}{ 1 - 1 + \\frac{1}{n} }\n = \\frac{1}{ \\frac{1}{n} }\n = n\n$$\n\n\nWhen $n \n 1$:\n\n\n$$\nF_{p,n} = \\frac{1}{ 1 - p + \\frac{p}{n} } = \\frac{n}{ n - n p + p } \\\\\n \\approx \\frac{n}{n -n p} = \\frac{1}{1-p}\n$$\n\n\n2018-09-03", 
            "title": "Amdahls Law"
        }, 
        {
            "location": "/Amdahls-Law/#amdahls-law", 
            "text": "$T_s$ - Time for a serial task  $p$ - portion of a task that can be parallelized ($ p \\in [0,1]$)  $n$ - number of processes that can be used to parallelize  $T_{p,n}$ - Time for a parallel task with $p$ and $n$  $F_{p,n} = \\frac{T_s}{T_{p,n}} $ - Speedup factor for $p$ and $n$   $$\nT_{p,n} = T_s (1-p) + \\frac{T_s p}{n} \\\\\n\\to \\frac{T_{p,n}}{T_s} = 1 - p + \\frac{p}{n} \\\\\n\\to \\frac{T_s}{T_{p,n}} = \\frac{1}{ 1 - p + \\frac{p}{n} } \\\\\n\\to F_{p,n} = \\frac{1}{ 1 - p + \\frac{p}{n} }\n$$  For a completely serial task ($p=0$):  $$\nF_{p,n} = \\frac{1}{ 1 - 0 + \\frac{0}{n} } = 1\n$$  For a completely parallel task ($p=1$):  $$\nF_{p,n} = \\frac{1}{ 1 - 1 + \\frac{1}{n} }\n = \\frac{1}{ \\frac{1}{n} }\n = n\n$$  When $n   1$:  $$\nF_{p,n} = \\frac{1}{ 1 - p + \\frac{p}{n} } = \\frac{n}{ n - n p + p } \\\\\n \\approx \\frac{n}{n -n p} = \\frac{1}{1-p}\n$$", 
            "title": "Amdahl's Law"
        }, 
        {
            "location": "/Amdahls-Law/#2018-09-03", 
            "text": "", 
            "title": "2018-09-03"
        }, 
        {
            "location": "/Is-It-Really-Open/", 
            "text": "Is It Really Open\n\n\nFrom the Wikipedia entry on the \nOpen Source Model\n:\n\n\n\n\nOpen source promotes universal access via an open-source \nor free license to a product's design or blueprint, and \nuniversal redistribution of that design or blueprint.\n\n\n\n\n\n\n\n\n\n\nProject\n\n\nOpen Source?\n\n\nClaim\n\n\nIndividual/Organization\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nAir Quality Egg\n\n\nNo\n\n\n\" ... a ... device that uses sensors to record changes in the levels of specified air contaminants.\"\n\n\nGitHub\n\n\nThere are multiple references to it being \"open-source hardware\" on \nairquailityegg.com\n but the source and design files available on GitHub have no license.\n\n\n\n\n\n\nBCN3D\n\n\nyes\n\n\n\"A fully Open Source 3D printed robot arm\"\n\n\nsource\n (GPLv3), \nhardware\n (CERN OHL), \nelectronics\n (CERN OHL)\n\n\n\n\n\n\n\n\nDIY LilCNC\n\n\nyes\n\n\n\"... open-source set of plans for an inexpensive, fully functional 3-axis CNC ...\"\n\n\nDIYLilCNC\n\n\nDownloads\n\n\n\n\n\n\nDoti: Open Source Jacquard Loom\n\n\nNo\n\n\n\"open source\"\n\n\nDoti\n\n\nFrom the website: \"Doti is an open source desktop jacquard loom ...\"  yet no design files are available\n\n\n\n\n\n\nOpenEIT\n\n\nNo\n\n\n\"open\"\n\n\n\n\n\n\n\n\n\n\nFarmBot\n\n\nyes\n\n\n\"Open Source CNC Farming\"\n\n\nsource\n (MIT), \ndesign files\n (CC0)\n\n\n\n\n\n\n\n\nInMoov\n\n\nNo\n\n\n\"InMoov is the first Open Source 3D printed life-size robot.\"\n\n\nDesign files are under a non commercial license.\n\n\n\n\n\n\n\n\nLasersaur\n\n\nyes\n\n\n\"open source laser cutter\"\n\n\nLasersaur\n\n\nLicense\n\n\n\n\n\n\nODrive\n\n\nyes\n\n\n\"... accurately driving brushless motors, for cheap.\"\n\n\nsource\n \nhardware\n\n\n\n\n\n\n\n\nOpenCat\n\n\nmixed\n\n\n\"A programmable and highly maneuverable robotic cat ...\"\n\n\nOpenCat\n\n\nSource files are under MIT license but design files for the robot are not available.\n\n\n\n\n\n\nOpen Desk\n\n\nmixed\n\n\n\"open\"\n\n\nOpenDesk.cc\n\n\nThough they don't claim anywhere that they're \"open source\", the name is misleading.  Many of their furniture designs are free/libre (CC0, CC-BY) but many are under a non-commercial license\n\n\n\n\n\n\nOpenKnit\n\n\nNo\n\n\n\"open source digital knitting\"\n\n\nOpenKnit\n\n\nNo license on \nsource\n, \nInstructables build\n under a non commercial license (CC-BY-NC-SA)\n\n\n\n\n\n\nOpen Press Project\n\n\nNo\n\n\n\"Open Press\"\n\n\nMartin Schneider\n\n\nAll \ndesign files\n are under a non commercial license (CC-BY-NC)\n\n\n\n\n\n\nOpenROV\n\n\nmixed\n\n\n\"OpenROV is a DIY telerobotics community centered around underwater exploration \n adventure.\"\n\n\nSource code\n is under an MIT license but \ndesign files\n are under a non commercial license (CC-BY-NC-SA).\n\n\n\n\n\n\n\n\nOpenScanner\n\n\nNo\n\n\n\"Open Hardware\"\n\n\nOpenScan.eu\n\n\nThe project uses third party software to do the photogramatry, so the project consists of the \nPCB design files, Arduino code and 3D design\n files all which have no license information or are under a \nnon-commercial license\n.\n\n\n\n\n\n\nOpen Source Fashion\n\n\nunknown\n\n\n\"Open Source\" in name\n\n\nOpen Source Fashion\n\n\nI don't know what's \"open source\" about their site.  It looks to be just a blog.\n\n\n\n\n\n\nFree Sewing\n\n\nyes\n\n\n\"an open source platform for made-to-measure sewing patterns\"\n\n\nFree Sewing\n\n\nSource\n is free/libre and other content is under CC-BY\n\n\n\n\n\n\nOpenwear\n\n\nyes \n*\n (\nnow defunct\n)\n\n\n\"Openwear is an open-source brand concept ...\"\n\n\nOpenwear\n\n\nPattern files look to be under free/libre licenses (CC-BY-SA etc.)\n\n\n\n\n\n\nOSLoom\n\n\nNo\n\n\n\"open source jacquard loom\"\n\n\nOS Loom\n\n\nThough there are claims of the source being under GPL and the hardware being under OHL, I can't find any design files.  Other project design files, when available, are all under a non commercial license (CC-BY-NC-SA).\n\n\n\n\n\n\nPoppy Humanoid\n\n\nyes\n\n\n\"... an open-source and 3D printed humanoid robot.\"\n\n\nsource\n\n\n\n\n\n\n\n\nSeamly2D / Valentina\n\n\nyes\n\n\n\"Open source patternmaking software.\"\n\n\nSeamly2D\n\n\nPattern making software\n\n\n\n\n\n\nSTM32 Open Source Multimeter\n\n\nNo\n\n\n\"Open source multimeter\".\"\n\n\nEmbedBlog\n\n\nAll \nsource\n, \ncase design files\n and \ndocumentation\n are under a non-commercial license (CC-BY-NC-SA)\n\n\n\n\n\n\nThor\n\n\nyes\n\n\n\"DIY 3D Printable Robotic Arm\"\n\n\nsource\n (CC-BY-SA)\n\n\n\n\n\n\n\n\n\n\nComments\n\n\nFrom the Wikipedia entry on \nOpen Source Software\n:\n\n\n\n\nOpen-source software (OSS) is computer software with its source code made available with a\nlicense in which the copyright holder provides the rights to study, change, and distribute\nthe software to anyone and for any purpose.\n\n\n\n\nThis is an attempt to create a list of projects to reconcile\nclaims of openness with whether they actually are open.\n\n\nOften times companies claim that their projects are \"open source\",\neither computer source code, design files or other digital artifacts,\nbut either fail to provide the source or fail to provide proper\nlicensing.\n\n\nWhen talking about other digital assets, either art files, design files, documentation,\netc., what constitutes the analog of \"open source\" can get confusing, but I will generally\ntake it to mean that they provide the fundamental copyrightable material to help with or\nrecreate the project under a license that respects the freedoms of being able to run or create,\nto study, to change and to distribute, including distribution for commercial purposes.\n\n\n2019-01-10", 
            "title": "Is It Really Open"
        }, 
        {
            "location": "/Is-It-Really-Open/#is-it-really-open", 
            "text": "From the Wikipedia entry on the  Open Source Model :   Open source promotes universal access via an open-source \nor free license to a product's design or blueprint, and \nuniversal redistribution of that design or blueprint.      Project  Open Source?  Claim  Individual/Organization  Notes      Air Quality Egg  No  \" ... a ... device that uses sensors to record changes in the levels of specified air contaminants.\"  GitHub  There are multiple references to it being \"open-source hardware\" on  airquailityegg.com  but the source and design files available on GitHub have no license.    BCN3D  yes  \"A fully Open Source 3D printed robot arm\"  source  (GPLv3),  hardware  (CERN OHL),  electronics  (CERN OHL)     DIY LilCNC  yes  \"... open-source set of plans for an inexpensive, fully functional 3-axis CNC ...\"  DIYLilCNC  Downloads    Doti: Open Source Jacquard Loom  No  \"open source\"  Doti  From the website: \"Doti is an open source desktop jacquard loom ...\"  yet no design files are available    OpenEIT  No  \"open\"      FarmBot  yes  \"Open Source CNC Farming\"  source  (MIT),  design files  (CC0)     InMoov  No  \"InMoov is the first Open Source 3D printed life-size robot.\"  Design files are under a non commercial license.     Lasersaur  yes  \"open source laser cutter\"  Lasersaur  License    ODrive  yes  \"... accurately driving brushless motors, for cheap.\"  source   hardware     OpenCat  mixed  \"A programmable and highly maneuverable robotic cat ...\"  OpenCat  Source files are under MIT license but design files for the robot are not available.    Open Desk  mixed  \"open\"  OpenDesk.cc  Though they don't claim anywhere that they're \"open source\", the name is misleading.  Many of their furniture designs are free/libre (CC0, CC-BY) but many are under a non-commercial license    OpenKnit  No  \"open source digital knitting\"  OpenKnit  No license on  source ,  Instructables build  under a non commercial license (CC-BY-NC-SA)    Open Press Project  No  \"Open Press\"  Martin Schneider  All  design files  are under a non commercial license (CC-BY-NC)    OpenROV  mixed  \"OpenROV is a DIY telerobotics community centered around underwater exploration   adventure.\"  Source code  is under an MIT license but  design files  are under a non commercial license (CC-BY-NC-SA).     OpenScanner  No  \"Open Hardware\"  OpenScan.eu  The project uses third party software to do the photogramatry, so the project consists of the  PCB design files, Arduino code and 3D design  files all which have no license information or are under a  non-commercial license .    Open Source Fashion  unknown  \"Open Source\" in name  Open Source Fashion  I don't know what's \"open source\" about their site.  It looks to be just a blog.    Free Sewing  yes  \"an open source platform for made-to-measure sewing patterns\"  Free Sewing  Source  is free/libre and other content is under CC-BY    Openwear  yes  *  ( now defunct )  \"Openwear is an open-source brand concept ...\"  Openwear  Pattern files look to be under free/libre licenses (CC-BY-SA etc.)    OSLoom  No  \"open source jacquard loom\"  OS Loom  Though there are claims of the source being under GPL and the hardware being under OHL, I can't find any design files.  Other project design files, when available, are all under a non commercial license (CC-BY-NC-SA).    Poppy Humanoid  yes  \"... an open-source and 3D printed humanoid robot.\"  source     Seamly2D / Valentina  yes  \"Open source patternmaking software.\"  Seamly2D  Pattern making software    STM32 Open Source Multimeter  No  \"Open source multimeter\".\"  EmbedBlog  All  source ,  case design files  and  documentation  are under a non-commercial license (CC-BY-NC-SA)    Thor  yes  \"DIY 3D Printable Robotic Arm\"  source  (CC-BY-SA)", 
            "title": "Is It Really Open"
        }, 
        {
            "location": "/Is-It-Really-Open/#comments", 
            "text": "From the Wikipedia entry on  Open Source Software :   Open-source software (OSS) is computer software with its source code made available with a\nlicense in which the copyright holder provides the rights to study, change, and distribute\nthe software to anyone and for any purpose.   This is an attempt to create a list of projects to reconcile\nclaims of openness with whether they actually are open.  Often times companies claim that their projects are \"open source\",\neither computer source code, design files or other digital artifacts,\nbut either fail to provide the source or fail to provide proper\nlicensing.  When talking about other digital assets, either art files, design files, documentation,\netc., what constitutes the analog of \"open source\" can get confusing, but I will generally\ntake it to mean that they provide the fundamental copyrightable material to help with or\nrecreate the project under a license that respects the freedoms of being able to run or create,\nto study, to change and to distribute, including distribution for commercial purposes.", 
            "title": "Comments"
        }, 
        {
            "location": "/Is-It-Really-Open/#2019-01-10", 
            "text": "", 
            "title": "2019-01-10"
        }, 
        {
            "location": "/Number-Theory-Notes/", 
            "text": "Number Theory Notes\n\n\nWilson's Theorem\n\n\n$p$ prime\n\n\n$$\n\\prod_{i=1}^{p-1} (i) \\mod p \\equiv -1 \\mod p\n$$\n\n\nproof\n:\n\n\n$$\n\\begin{equation} \\label{eq1}\n\\begin{split}\n\\prod_{i=1}^{p-1} (i) \n = 1 \\cdot 2 \\cdot 3 \\cdots (p-1) \\\\\n  \n = (a_0 a_0') (a_1 a_1^{-1}) \\cdots (a_{\\frac{p-1}{2}} a_{\\frac{p-1}{2}}^{-1}) \\\\\n  \n = [1]\n\\end{split}\n\\end{equation}\n$$\n\n\nWhere $a_0=1$ and $a_0' = -1$.\n\n\nlemma\n:\n\n\nThe only number whose inverse is itself is $(-1)$\n\n\nlemma proof\n:\n\n\n$$\n\\begin{split}\nx^2 \n = 1 \\mod p \\\\\n \n = \\pm 1 \\mod p\n\\end{split}\n$$\n\n\nSince $p$ is prime, there are only two solutions.\n\n\nproof (cont'd)\n:\n\n\n$$\n\\begin{split}\n \\to [1] \n = (1 \\cdot -1) (a_1 a_1^{-1}) (a_2 a_2^{-1}) \\cdots (a_{\\frac{p-1}{2}} a_{\\frac{p-1}{2}}^{-1}) \\\\\n \n = (1 \\cdot -1) (1) (1) \\cdots (1) \\\\\n \n =  -1\n\\end{split}\n$$\n\n\n\n\nFermat's Theorem\n\n\n$p$ prime\n\n\n$$\n\\begin{split}\nx^{p-1} = 1 \\mod  p\n\\end{split}\n$$\n\n\nproof\n:\n\n\n$a \\ne 0$\n\n\n$$\n\\begin{align}\n \n \n -1 \n = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdots (p-1) \\mod p \\\\\n\\to \n \n -a^{p-1} \n = (a \\cdot 1) (a \\cdot 2) (a \\cdot 3) \\cdots (a \\cdot (p-1)) \\mod p \\\\\n\\to \n \n -a^{p-1} \n = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdots (p-1) \\mod p \\\\\n\\to \n \n -a^{p-1} \n = -1 \\mod p \\\\\n\\to \n \n a^{p-1} \n = 1 \\mod p\n\\end{align}\n$$\n\n\nSince $a \\cdot x$ is 1-1 and onto for prime $p$ (with $a,x \\ne 0$).\n\n\nLegendre Symbol\n\n\n$p$ prime\n\n\n$$\n\\left( \\dfrac{a}{p} \\right)  = \\begin{cases}\n 1, \n \\text{ if } \\sqrt{a} \\text{ exists } \\\\\n 0, \n \\text{ if } \\gcd(a,p) \\ne 1 \\\\\n -1, \n \\text{ if } \\sqrt{a} \\text{ does not exist }\n\\end{cases}\n$$\n\n\nnotes\n:\n\n\n$g$ a generator of $p$, consider $a = g^\\beta$\n\n\n$\\beta$ even:\n\n\n$$\n\\begin{align}\n \n \n g^\\beta \n = a \\\\\n\\to \n \n ( g^{\\frac{p-1}{2}} ) )^\\beta \n = ( a^{\\frac{p-1}{a}} ) \\\\\n\\to \n \n (-1)^\\beta \n = a^{\\frac{p-1}{2}} \\\\\n\\to \n \n a^{\\frac{p-1}{2}} \n = 1 \\\\\n\\end{align}\n$$\n\n\n$\\beta$ odd:\n\n\n$$\n\\begin{align}\n\\to \n \n (-1)^\\beta \n = a^{\\frac{p-1}{2}} \\\\\n\\to \n \n a^{\\frac{p-1}{2}} \n = -1 \\\\\n\\end{align}\n$$\n\n\nSo:\n\n\n$$\n\\left( \\dfrac{a}{p} \\right) = a^{\\frac{p-1}{2}}\n$$\n\n\n\n\nZeta Function\n\n\n$$\n\\begin{split}\n\\sum_{n=1}^{\\infty} \\frac{1}{n^s} \n = \\prod_{p \\text{ prime}}^{\\infty} ( \\frac{1}{1 - p^{-s}} )\n\\end{split}\n$$\n\n\nproof\n:\n\n\n$$\n\\begin{align}\n\n \n \\sum_{i=1}^{\\infty} a^i \n = S \\\\\n\n \n \\sum_{i=0}^{\\infty} a^{i+1} \n = \\sum_{i=1}^{\\infty} a^i  \\\\\n\n \n  \n = S a \\\\\n\n \n \n \\\\\n\n \n  S - S a \n = 1 \\\\\n\\to \n \n S \n = \\frac{1}{1-a}\n\\end{align}\n$$\n\n\nWrite out the product of infinit series of primes, $p_i$:\n\n\n$$\n\\begin{align}\n \n ( 1 + p_0^{-s} + p_0^{-2s} + p_0^{-3s} + \\cdots ) \\\\\n \n ( 1 + p_1^{-s} + p_1^{-2s} + p_1^{-3s} + \\cdots ) \\\\\n \n \\cdots \\\\\n \n = \\prod_{p \\text{ prime}}^{\\infty} [ \\sum_{i=0}^{\\infty} \\frac{1}{p^{i s}} ] \\\\\n \n = \\prod_{p \\text{ prime}}^{\\infty} ( \\frac{1}{1-p^{-s}} )\n\\end{align}\n$$\n\n\nAny choice of terms in the product of infinite sums of primes will yield a value in the\noriginal $\\sum \\frac{1}{n^s}$.\n\n\n\n\n2019-01-10", 
            "title": "Number Theory Notes"
        }, 
        {
            "location": "/Number-Theory-Notes/#number-theory-notes", 
            "text": "", 
            "title": "Number Theory Notes"
        }, 
        {
            "location": "/Number-Theory-Notes/#wilsons-theorem", 
            "text": "$p$ prime  $$\n\\prod_{i=1}^{p-1} (i) \\mod p \\equiv -1 \\mod p\n$$  proof :  $$\n\\begin{equation} \\label{eq1}\n\\begin{split}\n\\prod_{i=1}^{p-1} (i)   = 1 \\cdot 2 \\cdot 3 \\cdots (p-1) \\\\\n    = (a_0 a_0') (a_1 a_1^{-1}) \\cdots (a_{\\frac{p-1}{2}} a_{\\frac{p-1}{2}}^{-1}) \\\\\n    = [1]\n\\end{split}\n\\end{equation}\n$$  Where $a_0=1$ and $a_0' = -1$.  lemma :  The only number whose inverse is itself is $(-1)$  lemma proof :  $$\n\\begin{split}\nx^2   = 1 \\mod p \\\\\n   = \\pm 1 \\mod p\n\\end{split}\n$$  Since $p$ is prime, there are only two solutions.  proof (cont'd) :  $$\n\\begin{split}\n \\to [1]   = (1 \\cdot -1) (a_1 a_1^{-1}) (a_2 a_2^{-1}) \\cdots (a_{\\frac{p-1}{2}} a_{\\frac{p-1}{2}}^{-1}) \\\\\n   = (1 \\cdot -1) (1) (1) \\cdots (1) \\\\\n   =  -1\n\\end{split}\n$$", 
            "title": "Wilson's Theorem"
        }, 
        {
            "location": "/Number-Theory-Notes/#fermats-theorem", 
            "text": "$p$ prime  $$\n\\begin{split}\nx^{p-1} = 1 \\mod  p\n\\end{split}\n$$  proof :  $a \\ne 0$  $$\n\\begin{align}\n     -1   = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdots (p-1) \\mod p \\\\\n\\to     -a^{p-1}   = (a \\cdot 1) (a \\cdot 2) (a \\cdot 3) \\cdots (a \\cdot (p-1)) \\mod p \\\\\n\\to     -a^{p-1}   = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdots (p-1) \\mod p \\\\\n\\to     -a^{p-1}   = -1 \\mod p \\\\\n\\to     a^{p-1}   = 1 \\mod p\n\\end{align}\n$$  Since $a \\cdot x$ is 1-1 and onto for prime $p$ (with $a,x \\ne 0$).", 
            "title": "Fermat's Theorem"
        }, 
        {
            "location": "/Number-Theory-Notes/#legendre-symbol", 
            "text": "$p$ prime  $$\n\\left( \\dfrac{a}{p} \\right)  = \\begin{cases}\n 1,   \\text{ if } \\sqrt{a} \\text{ exists } \\\\\n 0,   \\text{ if } \\gcd(a,p) \\ne 1 \\\\\n -1,   \\text{ if } \\sqrt{a} \\text{ does not exist }\n\\end{cases}\n$$  notes :  $g$ a generator of $p$, consider $a = g^\\beta$  $\\beta$ even:  $$\n\\begin{align}\n     g^\\beta   = a \\\\\n\\to     ( g^{\\frac{p-1}{2}} ) )^\\beta   = ( a^{\\frac{p-1}{a}} ) \\\\\n\\to     (-1)^\\beta   = a^{\\frac{p-1}{2}} \\\\\n\\to     a^{\\frac{p-1}{2}}   = 1 \\\\\n\\end{align}\n$$  $\\beta$ odd:  $$\n\\begin{align}\n\\to     (-1)^\\beta   = a^{\\frac{p-1}{2}} \\\\\n\\to     a^{\\frac{p-1}{2}}   = -1 \\\\\n\\end{align}\n$$  So:  $$\n\\left( \\dfrac{a}{p} \\right) = a^{\\frac{p-1}{2}}\n$$", 
            "title": "Legendre Symbol"
        }, 
        {
            "location": "/Number-Theory-Notes/#zeta-function", 
            "text": "$$\n\\begin{split}\n\\sum_{n=1}^{\\infty} \\frac{1}{n^s}   = \\prod_{p \\text{ prime}}^{\\infty} ( \\frac{1}{1 - p^{-s}} )\n\\end{split}\n$$  proof :  $$\n\\begin{align}    \\sum_{i=1}^{\\infty} a^i   = S \\\\    \\sum_{i=0}^{\\infty} a^{i+1}   = \\sum_{i=1}^{\\infty} a^i  \\\\       = S a \\\\      \\\\     S - S a   = 1 \\\\\n\\to     S   = \\frac{1}{1-a}\n\\end{align}\n$$  Write out the product of infinit series of primes, $p_i$:  $$\n\\begin{align}\n   ( 1 + p_0^{-s} + p_0^{-2s} + p_0^{-3s} + \\cdots ) \\\\\n   ( 1 + p_1^{-s} + p_1^{-2s} + p_1^{-3s} + \\cdots ) \\\\\n   \\cdots \\\\\n   = \\prod_{p \\text{ prime}}^{\\infty} [ \\sum_{i=0}^{\\infty} \\frac{1}{p^{i s}} ] \\\\\n   = \\prod_{p \\text{ prime}}^{\\infty} ( \\frac{1}{1-p^{-s}} )\n\\end{align}\n$$  Any choice of terms in the product of infinite sums of primes will yield a value in the\noriginal $\\sum \\frac{1}{n^s}$.", 
            "title": "Zeta Function"
        }, 
        {
            "location": "/Number-Theory-Notes/#2019-01-10", 
            "text": "", 
            "title": "2019-01-10"
        }, 
        {
            "location": "/Arbitrary-Binary-Functions/", 
            "text": "Arbitrary Binary Functions\n\n\nShannon's counting argument.\n\n\n$$\nx \\in \\mathbb{B}^n \\\\\n \\\\\nf(X): \\{0,1\\}^n \\mapsto \\{0,1\\}\n$$\n\n\nThere are $2^{2^n}$ different binary functions.\nCan we approximate this with less than $\\frac{2^n}{c n}$ boolean gates for some constant $c$?\n\n\nThe strategy to show we can't is to overcount the number of boolean gates.\n\n\n$$\n\\begin{align}\n m \n \n \\text{ boolean gates } (\\frac{2^n}{c n}) \\\\\n n \n \n \\text{ inputs }\n\\end{align}\n$$\n\n\nLabel each of the $m$ gates as either one of the $n$ inputs or one of the set of ${ \\wedge, \\vee, \\neg }$.\nAssume a maximum of 2 inputs but that outputs can be traced to as many other gates as needed.\n\n\nWe have a total of $(n+3)$ labels for each gate and a maximum of $m^2$ input choices.\n\n\nEach of the $m$ gates has a choice of label and choice of inputs, giving:\n\n\n$$\n ((n + 3) m^2)^m \n$$\n\n\n$$\n\\lg = \\log_2\n$$\n\n\nFor $n$ large enough:\n\n\n$$\n\\begin{align}\n \\lg( ((n + 3) m^2)^m ) \n = \\frac{2^n}{c n} [ \\lg(n+3) + 2 n - 2 \\lg(c n) ] \\\\\n = \\frac{2^n}{c} [ \\frac{\\lg(n+3)}{n} + 2 - \\frac{2 \\lg(c n)}{n} ] \n \n \\frac{2^n}{c} [ \\frac{2 \\lg(n)}{n} + 2 - \\frac{2 \\lg(c n)}{n} ] \\\\\n = \\frac{2^n}{c} [ 2 + \\frac{2}{n} ( \\lg(n) - \\lg(n) - \\lg(c) ) ]  \n = \\frac{2^n}{c} [ 2 - \\frac{2}{n} \\lg(c) ] \\\\\n \n 2 \\frac{ 2^n }{ c } \n = \\frac{2^n}{ \\frac{c}{2} }\n\\end{align}\n$$\n\n\nFor $c\n2$:\n\n\n$$\n ((n + 3) m^2)^m \n 2^{2^n}\n$$\n\n\nEven when we overcount, we still can't the count large enough to represent all binary functions.\n\n\nsrc", 
            "title": "Arbitrary Binary Functions"
        }, 
        {
            "location": "/Arbitrary-Binary-Functions/#arbitrary-binary-functions", 
            "text": "Shannon's counting argument.  $$\nx \\in \\mathbb{B}^n \\\\\n \\\\\nf(X): \\{0,1\\}^n \\mapsto \\{0,1\\}\n$$  There are $2^{2^n}$ different binary functions.\nCan we approximate this with less than $\\frac{2^n}{c n}$ boolean gates for some constant $c$?  The strategy to show we can't is to overcount the number of boolean gates.  $$\n\\begin{align}\n m     \\text{ boolean gates } (\\frac{2^n}{c n}) \\\\\n n     \\text{ inputs }\n\\end{align}\n$$  Label each of the $m$ gates as either one of the $n$ inputs or one of the set of ${ \\wedge, \\vee, \\neg }$.\nAssume a maximum of 2 inputs but that outputs can be traced to as many other gates as needed.  We have a total of $(n+3)$ labels for each gate and a maximum of $m^2$ input choices.  Each of the $m$ gates has a choice of label and choice of inputs, giving:  $$\n ((n + 3) m^2)^m \n$$  $$\n\\lg = \\log_2\n$$  For $n$ large enough:  $$\n\\begin{align}\n \\lg( ((n + 3) m^2)^m )   = \\frac{2^n}{c n} [ \\lg(n+3) + 2 n - 2 \\lg(c n) ] \\\\\n = \\frac{2^n}{c} [ \\frac{\\lg(n+3)}{n} + 2 - \\frac{2 \\lg(c n)}{n} ]     \\frac{2^n}{c} [ \\frac{2 \\lg(n)}{n} + 2 - \\frac{2 \\lg(c n)}{n} ] \\\\\n = \\frac{2^n}{c} [ 2 + \\frac{2}{n} ( \\lg(n) - \\lg(n) - \\lg(c) ) ]    = \\frac{2^n}{c} [ 2 - \\frac{2}{n} \\lg(c) ] \\\\\n   2 \\frac{ 2^n }{ c }   = \\frac{2^n}{ \\frac{c}{2} }\n\\end{align}\n$$  For $c 2$:  $$\n ((n + 3) m^2)^m   2^{2^n}\n$$  Even when we overcount, we still can't the count large enough to represent all binary functions.  src", 
            "title": "Arbitrary Binary Functions"
        }, 
        {
            "location": "/Empirical-Laws/", 
            "text": "Empirical Laws\n\n\nGall's Law\n\n\n\n\nA complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.\n\n\n\n\nWikipedia\n\n\nHanlon's Razor\n\n\n\n\nNever attribute to malice that which is adequately explained by stupidity.\n\n\n\n\nWikipedia\n\n\nGervais Principle\n\n\n\n\nSociopaths, in their own best interests, knowingly promote over-performing losers into middle-management, groom under-performing losers into sociopaths, and leave the average bare-minimum-effort losers to fend for themselves.\n\n\n\n\nNote: \"The Losers are not social losers (as in the opposite of \u201ccool\u201d), but people who have struck bad bargains economically \u2013 giving up capitalist striving for steady paychecks.\"\n\n\nSource\n\n\nGilder's Law\n\n\n\n\nBandwidth grows at least three times faster than computer power\n\n\n\n\nSource\n\n\nKoomey's Law\n\n\n\n\nThe number of computations per joule of energy dissipated doubled about every 1.57 years.\n\n\n\n\nNote: The scaling looks to have slowed to about 2.6 years as of 2000.\n\n\nWikipedia\n\n\nMetcalfe's Law\n\n\n\n\nThe effect of a telecommunications network is proportional to the square of the number of connected users of the system.\n\n\n\n\nWikipedia\n\n\nMoore's Law\n\n\n\n\nThe number of transistors in a dense integrated circuit doubles about every two years.\n\n\n\n\nWikipedia\n\n\nOccam's Razor\n\n\n\n\nSimpler solutions are more likely to be correct than complex ones.\n\n\n\n\nWikipedia\n\n\nPareto's Principle\n\n\n\n\nFor many events, roughly 80% of the effects come from 20% of the causes.\n\n\n\n\nWikipedia\n\n\nPeter Principle\n\n\n\n\nPeople in a hierarchy tend to rise to their \"level of incompetence\".\n\n\n\n\nWikipedia\n\n\nPlanck's Principle\n\n\n\n\nScientific change does not occur because individual scientists change their mind, but rather that successive generations of scientists have different views.\n\n\n\n\nWikipedia\n\n\nReed's Law\n\n\n\n\nThe utility of a group forming network of $n$ members scales as $O(2^n)$.\n\n\n\n\nThere are $2^n$ subgroups of a set of $n$ members.\n\n\nWhereas Sarnoff's law is one to many, thus linear.\nMetcalf's law is many to many, but only on an individual connection basis, like a telephone network.\nReed's law considers subgroup formation as an added factor to the utility\nand points out that Metcalf's law might undervalue network effects significantly.\n\n\nWikipedia\n\n\nSarnoff's Law\n\n\n\n\nThe value of a broadcast network is proportional to the number of viewers.\n\n\n\n\nThat is, the value of a network, in this above case a broadcast network, scales as $O(n)$.\n\n\nWikipedia\n\n\nSpolsky's Observation\n\n\n\n\nSmart companies try to commoditize their products' complements.\n\n\n\n\nNote: In this context, there are 'substitutes' and 'compliments', where\na substitute is a product you buy that replaces the core product and a compliment\nis a product you buy with the core product.\n\n\nSource\n\n\nUcaetano's Addendum to Spolsky's Observation\n\n\n\n\nCreate a desert of profitability around you.\n\n\n\n\nSource\n\n\nSwanson's Law\n\n\n\n\nThe price of solar photovoltaic modules tends to drop 20 percent for every doubling of cumulative shipped volume.\n\n\n\n\nNote: at present, costs halve at every 10 years.\n\n\nWikipedia\n\n\nWagner's Law\n\n\n\n\nThe advent of modern industrial society will result in increasing political pressure for social progress and increased allowance for social consideration by industry.\n\n\n\n\nWikipedia\n\n\nWright's Law\n\n\n\n\nProduction doubling leads to a constant percent decrease in cost.\n\n\n\n\naka Experience curve effects.\n\n\nThe above is paraphrased.\nWright noticed that every time total aircraft production doubled, the required labor cost fell 20%.\n\n\nFor unit number $n$, cost $P_n$ is approximately:\n\n\n$$\nP_n = P_1 n^{ \\lg(\\beta) } = P_1 n^{-\\alpha}\n$$\n\n\nWhere $(1-\\beta)$ is the reduction proportion and $\\alpha$ is the \"elasticity of cost\" ($\\alpha = -\\lg(\\beta)$).\nNote that $ \\frac{ P_{2n} }{P_n} = 2^{-\\alpha} $\n\n\nIt appears that $(1-\\beta)$ estimates can typically range from $0.1$ to $0.25$.\n\n\nAlso note that economies of scale might be intertwined with with the experience curve effects and that it might be hard to separate the two.\n\n\nWikipedia\n\n\nWu's Razor\n\n\n\n\nFor sufficiently powerful actors, Hanlon's Razor is invoked to give malice plausible deniability.\n\n\n\n\nThe above is paraphrased from the original:\n\n\n\n\nI've come to the conclusion Hanlon's Razor isn't particularly useful.\nIt's catchy, popular- but as a cognitive tool it's almost never applicable\nand it's usually invoked not to aid the determination of truth, but as\nrhetorical squid ink to give malice plausible deniability.\n\n\n\n\n(\ntweet\n, \narchive\n)\n\n\n2019-03-18", 
            "title": "Empirical Laws"
        }, 
        {
            "location": "/Empirical-Laws/#empirical-laws", 
            "text": "", 
            "title": "Empirical Laws"
        }, 
        {
            "location": "/Empirical-Laws/#galls-law", 
            "text": "A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.   Wikipedia", 
            "title": "Gall's Law"
        }, 
        {
            "location": "/Empirical-Laws/#hanlons-razor", 
            "text": "Never attribute to malice that which is adequately explained by stupidity.   Wikipedia", 
            "title": "Hanlon's Razor"
        }, 
        {
            "location": "/Empirical-Laws/#gervais-principle", 
            "text": "Sociopaths, in their own best interests, knowingly promote over-performing losers into middle-management, groom under-performing losers into sociopaths, and leave the average bare-minimum-effort losers to fend for themselves.   Note: \"The Losers are not social losers (as in the opposite of \u201ccool\u201d), but people who have struck bad bargains economically \u2013 giving up capitalist striving for steady paychecks.\"  Source", 
            "title": "Gervais Principle"
        }, 
        {
            "location": "/Empirical-Laws/#gilders-law", 
            "text": "Bandwidth grows at least three times faster than computer power   Source", 
            "title": "Gilder's Law"
        }, 
        {
            "location": "/Empirical-Laws/#koomeys-law", 
            "text": "The number of computations per joule of energy dissipated doubled about every 1.57 years.   Note: The scaling looks to have slowed to about 2.6 years as of 2000.  Wikipedia", 
            "title": "Koomey's Law"
        }, 
        {
            "location": "/Empirical-Laws/#metcalfes-law", 
            "text": "The effect of a telecommunications network is proportional to the square of the number of connected users of the system.   Wikipedia", 
            "title": "Metcalfe's Law"
        }, 
        {
            "location": "/Empirical-Laws/#moores-law", 
            "text": "The number of transistors in a dense integrated circuit doubles about every two years.   Wikipedia", 
            "title": "Moore's Law"
        }, 
        {
            "location": "/Empirical-Laws/#occams-razor", 
            "text": "Simpler solutions are more likely to be correct than complex ones.   Wikipedia", 
            "title": "Occam's Razor"
        }, 
        {
            "location": "/Empirical-Laws/#paretos-principle", 
            "text": "For many events, roughly 80% of the effects come from 20% of the causes.   Wikipedia", 
            "title": "Pareto's Principle"
        }, 
        {
            "location": "/Empirical-Laws/#peter-principle", 
            "text": "People in a hierarchy tend to rise to their \"level of incompetence\".   Wikipedia", 
            "title": "Peter Principle"
        }, 
        {
            "location": "/Empirical-Laws/#plancks-principle", 
            "text": "Scientific change does not occur because individual scientists change their mind, but rather that successive generations of scientists have different views.   Wikipedia", 
            "title": "Planck's Principle"
        }, 
        {
            "location": "/Empirical-Laws/#reeds-law", 
            "text": "The utility of a group forming network of $n$ members scales as $O(2^n)$.   There are $2^n$ subgroups of a set of $n$ members.  Whereas Sarnoff's law is one to many, thus linear.\nMetcalf's law is many to many, but only on an individual connection basis, like a telephone network.\nReed's law considers subgroup formation as an added factor to the utility\nand points out that Metcalf's law might undervalue network effects significantly.  Wikipedia", 
            "title": "Reed's Law"
        }, 
        {
            "location": "/Empirical-Laws/#sarnoffs-law", 
            "text": "The value of a broadcast network is proportional to the number of viewers.   That is, the value of a network, in this above case a broadcast network, scales as $O(n)$.  Wikipedia", 
            "title": "Sarnoff's Law"
        }, 
        {
            "location": "/Empirical-Laws/#spolskys-observation", 
            "text": "Smart companies try to commoditize their products' complements.   Note: In this context, there are 'substitutes' and 'compliments', where\na substitute is a product you buy that replaces the core product and a compliment\nis a product you buy with the core product.  Source", 
            "title": "Spolsky's Observation"
        }, 
        {
            "location": "/Empirical-Laws/#ucaetanos-addendum-to-spolskys-observation", 
            "text": "Create a desert of profitability around you.   Source", 
            "title": "Ucaetano's Addendum to Spolsky's Observation"
        }, 
        {
            "location": "/Empirical-Laws/#swansons-law", 
            "text": "The price of solar photovoltaic modules tends to drop 20 percent for every doubling of cumulative shipped volume.   Note: at present, costs halve at every 10 years.  Wikipedia", 
            "title": "Swanson's Law"
        }, 
        {
            "location": "/Empirical-Laws/#wagners-law", 
            "text": "The advent of modern industrial society will result in increasing political pressure for social progress and increased allowance for social consideration by industry.   Wikipedia", 
            "title": "Wagner's Law"
        }, 
        {
            "location": "/Empirical-Laws/#wrights-law", 
            "text": "Production doubling leads to a constant percent decrease in cost.   aka Experience curve effects.  The above is paraphrased.\nWright noticed that every time total aircraft production doubled, the required labor cost fell 20%.  For unit number $n$, cost $P_n$ is approximately:  $$\nP_n = P_1 n^{ \\lg(\\beta) } = P_1 n^{-\\alpha}\n$$  Where $(1-\\beta)$ is the reduction proportion and $\\alpha$ is the \"elasticity of cost\" ($\\alpha = -\\lg(\\beta)$).\nNote that $ \\frac{ P_{2n} }{P_n} = 2^{-\\alpha} $  It appears that $(1-\\beta)$ estimates can typically range from $0.1$ to $0.25$.  Also note that economies of scale might be intertwined with with the experience curve effects and that it might be hard to separate the two.  Wikipedia", 
            "title": "Wright's Law"
        }, 
        {
            "location": "/Empirical-Laws/#wus-razor", 
            "text": "For sufficiently powerful actors, Hanlon's Razor is invoked to give malice plausible deniability.   The above is paraphrased from the original:   I've come to the conclusion Hanlon's Razor isn't particularly useful.\nIt's catchy, popular- but as a cognitive tool it's almost never applicable\nand it's usually invoked not to aid the determination of truth, but as\nrhetorical squid ink to give malice plausible deniability.   ( tweet ,  archive )", 
            "title": "Wu's Razor"
        }, 
        {
            "location": "/Empirical-Laws/#2019-03-18", 
            "text": "", 
            "title": "2019-03-18"
        }, 
        {
            "location": "/Food-CO2-Water/", 
            "text": "CO2 and Water Usage of Food Consumed\n\n\n\n\n\n\n\n\nDiet\n\n\nPer Capita Yearly CO2 Emission $(\\frac{kg}{(cap)(yr)})$\n\n\nPer Capita Yearly Water Consumption $(\\frac{kg}{(cap)(yr)})$\n\n\n\n\n\n\n\n\n\n\nAmerican Omnivore\n\n\n1422.96\n\n\n756.97\n\n\n\n\n\n\nAmerican Vegetarian\n\n\n515.53\n\n\n275.21\n\n\n\n\n\n\nAmerican Vegan (2 cup almond milk replacement)\n\n\n449.97\n\n\n491.80\n\n\n\n\n\n\nAmerican Vegan (2% almond milk replacement)\n\n\n449.97\n\n\n231.60\n\n\n\n\n\n\n\n\n\n\nAmerican Omnivore\n -  Meat and milk consumption taken from the National Chicken Council and the USDA\n\n\nAmerican Vegetarian\n -  Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Cow milk still used (67.59kg)\n\n\nAmerican Vegan (2 cup almond milk replacement0)\n - Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Almond milk used with 225g of almonds per litre of almond milk (assuming 67.59 L of almond milk consumed per capita per year)\n\n\nAmerican Vegan (2% almond milk replacement)\n -  Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Almond milk used with 20g of almonds per litre of almond milk (assuming 67.59 L of almond milk consumed per capita per year)\n\n\n\n\nWorked calculations\n\n\n\n\n\n\n\n\nType\n\n\nPer Capita Yearly Consumption $(kg)$\n\n\nPer Capita Yearly CO2 Emission $(\\frac{kg}{(cap)(yr)})$\n\n\nPer Capita Yearly Water Consumption $(\\frac{kg}{(cap)(yr)})$\n\n\n\n\n\n\n\n\n\n\nMeat (beef)\n\n\n25.85\n\n\n742.67\n\n\n324.68\n\n\n\n\n\n\nMeat (pork)\n\n\n23.04\n\n\n134.78\n\n\n102.76\n\n\n\n\n\n\nMeat (poultry)\n\n\n109.6\n\n\n451.55\n\n\n261.94\n\n\n\n\n\n\nMilk (cow)\n\n\n67.59\n\n\n93.95\n\n\n67.59\n\n\n\n\n\n\n\n\nw = 25.85 + 23.04 + 109.6 = 158.49\nmilk = 67.59\n\nomni_co2 = (25.85*28.73) + (23.04*5.85) + (109.6*4.12) + (milk*1.39)\nomni_h2o = (25.85*12.56) + (23.04*4.46) + (109.6*2.39) + (milk*1)\n\nveg_co2 = w*2.66 + milk*1.39\nveg_h2o = w*1.31 + milk*1\n\nvegan_co2_0 = w*2.66 + milk*0.42\nvegan_h2o_0 = w*1.31 + milk*(17.74*.237)\n\nvegan_co2_1 = w*2.66 + milk*0.42\nvegan_h2o_1 = w*1.31 + milk*(17.74*.02)\n\n\n\n\n\nThe following additional notes should be considered:\n\n\n\n\nI've found conflicting reports for the number of almonds in almond milk. If it's assumed that there are 225g of almonds per gallon of almond milk, this is \nestimate 0\n above (.237kg almonds per litre). If it's assumed the almond milk is 2% (by weight), then this is \nestimate 1\n above (.02kg almonds per litre).\n\n\nThe \nAmerican Omnivore\n diet estimates does not include rice, wheat, maize, vegetables or other non-animal products so can be considered a 'lower bound' on per capita CO2 and water consumption.\n\n\nThe non \nAmerican Omnivore\n entries use soybeans as a proxy for the meat (by weight) for CO2 emission and rice as a proxy for meat (by weight) for water consumption to give a conservative estimate of the CO2 emissions and water usage.\n\n\n\n\nReferences\n\n\n\"Per Capita Consumption of Poultry and Livestock, 1965 to Estimated 2019, in Pounds\"\n\n\n\n\n\n\n\n\nYear\n\n\nBeef (lbs)\n\n\nPork (lbs)\n\n\nTotal Poultry (lbs)\n\n\n\n\n\n\n\n\n\n\n208\n\n\n57.0\n\n\n50.8\n\n\n109.6\n\n\n\n\n\n\n\n\nThis implies \n25.85kg\n of beef, \n23.04kg\n of pork and \n49.71kg\n of poultry for the average American.\n\n\n\"Dairy Data\"\n\n\nThe \nper capita consumption of dairy for Americans\n:\n\n\n\n\n\n\n\n\nYear\n\n\nMilk Consumption (lbs)\n\n\n\n\n\n\n\n\n\n\n2017\n\n\n149\n\n\n\n\n\n\n\n\n149 pounds per person per year is about \n67.59kg\nper person per year.\n\n\n\"Food consumption patterns and their effect on water requirement in China\" by  J. Liu and H. H. G. Savenije\n\n\n\n\n\n\n\n\nFood\n\n\nWater footprint $(\\frac{m^3}{kg})$\n\n\nPer capita annual food consumption (2003) $(\\frac{kg}{(cap)(yr)})$\n\n\n\n\n\n\n\n\n\n\nRice\n\n\n1.31\n\n\n79\n\n\n\n\n\n\nWheat\n\n\n0.98\n\n\n61\n\n\n\n\n\n\nMaize\n\n\n0.84\n\n\n15\n\n\n\n\n\n\nSoybeans\n\n\n3.20\n\n\n7\n\n\n\n\n\n\nVegetables\n\n\n0.19\n\n\n270\n\n\n\n\n\n\nFruits\n\n\n0.50\n\n\n50\n\n\n\n\n\n\nBeef\n\n\n12.56\n\n\n5\n\n\n\n\n\n\nPork\n\n\n4.46\n\n\n35\n\n\n\n\n\n\nPoultry\n\n\n2.39\n\n\n11\n\n\n\n\n\n\nMilk\n\n\n1.00\n\n\n17\n\n\n\n\n\n\n\n\n\"Systematic review of greenhouse gas emissions for different fresh food categories\" by Stephen Clune, Enda Crossin, Karli Verghese\n\n\n\n\n\n\n\n\nFood\n\n\nMean $\\frac{(kg) (CO2\\ eq)}{kg}$ (2015?)\n\n\n\n\n\n\n\n\n\n\nRice\n\n\n2.66\n\n\n\n\n\n\nWheat\n\n\n0.51\n\n\n\n\n\n\nMaize\n\n\n0.63\n\n\n\n\n\n\nSoybeans\n\n\n0.58\n\n\n\n\n\n\nVegetables\n\n\n0.47\n\n\n\n\n\n\nFruits\n\n\n0.50\n\n\n\n\n\n\nBeef\n\n\n28.73\n\n\n\n\n\n\nPork\n\n\n5.85\n\n\n\n\n\n\nChicken\n\n\n4.12\n\n\n\n\n\n\nMilk\n\n\n1.39\n\n\n\n\n\n\nAlmond/coconut milk\n\n\n0.42\n\n\n\n\n\n\n\n\n\"The green, blue and grey water footprint of crops and derived crop products\" by M. M. Mekonnen and A. Y. Hoekstra\n\n\n\n\n\n\n\n\nFood\n\n\nGlobal average water footprint $(\\frac{m^3}{ton})$ (1996-2005)\n\n\nGlobal average water footprint ($\\frac{m^3}{kg}$ (1996-2005))\n\n\n\n\n\n\n\n\n\n\nAlmonds\n\n\n16095\n\n\n17.74\n\n\n\n\n\n\n\n\nHow many ounces of almonds go into making each half-gallon of almond milk (example: Silk or Almond Breeze brand)?\n\n\nAs a conservative estimate of the almonds used in almond milk:\n\n\n\n\nAround 2 cups of almonds for a half gallon.\n\n\nAround \n225 g per cup of ground almonds\n.\n\n\n2 cups almonds = 450 g almonds.\n\n\n1 gallon = 3.79 kg (water).\n\n\n1/2 gallon = 1.90 kg\n\n\n450 g almonds per 1.90 kg of almond milk\n\n\n.237 kg of almonds per 1 kg of almond milk\n\n\n\n\nAs a potentially more realistic estimate of the number of almonds used in almond milk:\n\n\n\n\nIf almond milk has 2% of almonds, by weight, then for every litre of almond milk, there are approximately 20g of almonds\n\n\n.02 kg of almonds per 1kg of almond milk\n\n\n\n\nGreenhouse Gas Emissions from a Typical Passenger Vehicle\n\n\n$4600 \\frac{kg}{yr}$ of CO2 emissions for the typical US passenger vehicle.\n\n\n\"Almond milk: quite good for you \u2013 very bad for the planet\" by Emine Saner\n\n\n\"Your Almond Habit Is Sucking California Dry\" by Tom Philpott\n\n\n\"Lay Off the Almond Milk, You Ignorant Hipsters\" by Tom Philpott\n\n\n\"Almond Milk is Taking a Toll on the Environment\"\n\n\n2019-04-02", 
            "title": "Food CO2 Water"
        }, 
        {
            "location": "/Food-CO2-Water/#co2-and-water-usage-of-food-consumed", 
            "text": "Diet  Per Capita Yearly CO2 Emission $(\\frac{kg}{(cap)(yr)})$  Per Capita Yearly Water Consumption $(\\frac{kg}{(cap)(yr)})$      American Omnivore  1422.96  756.97    American Vegetarian  515.53  275.21    American Vegan (2 cup almond milk replacement)  449.97  491.80    American Vegan (2% almond milk replacement)  449.97  231.60      American Omnivore  -  Meat and milk consumption taken from the National Chicken Council and the USDA  American Vegetarian  -  Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Cow milk still used (67.59kg)  American Vegan (2 cup almond milk replacement0)  - Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Almond milk used with 225g of almonds per litre of almond milk (assuming 67.59 L of almond milk consumed per capita per year)  American Vegan (2% almond milk replacement)  -  Meat, pork and poultry replaced with soybean (by weight, assumed 158.49kg of soybean) for CO2 emission. Meat, pork and poultry replaced with rice (by weight, assumed 158.49kg of rice) for water consumption. Almond milk used with 20g of almonds per litre of almond milk (assuming 67.59 L of almond milk consumed per capita per year)", 
            "title": "CO2 and Water Usage of Food Consumed"
        }, 
        {
            "location": "/Food-CO2-Water/#worked-calculations", 
            "text": "Type  Per Capita Yearly Consumption $(kg)$  Per Capita Yearly CO2 Emission $(\\frac{kg}{(cap)(yr)})$  Per Capita Yearly Water Consumption $(\\frac{kg}{(cap)(yr)})$      Meat (beef)  25.85  742.67  324.68    Meat (pork)  23.04  134.78  102.76    Meat (poultry)  109.6  451.55  261.94    Milk (cow)  67.59  93.95  67.59     w = 25.85 + 23.04 + 109.6 = 158.49\nmilk = 67.59\n\nomni_co2 = (25.85*28.73) + (23.04*5.85) + (109.6*4.12) + (milk*1.39)\nomni_h2o = (25.85*12.56) + (23.04*4.46) + (109.6*2.39) + (milk*1)\n\nveg_co2 = w*2.66 + milk*1.39\nveg_h2o = w*1.31 + milk*1\n\nvegan_co2_0 = w*2.66 + milk*0.42\nvegan_h2o_0 = w*1.31 + milk*(17.74*.237)\n\nvegan_co2_1 = w*2.66 + milk*0.42\nvegan_h2o_1 = w*1.31 + milk*(17.74*.02)  The following additional notes should be considered:   I've found conflicting reports for the number of almonds in almond milk. If it's assumed that there are 225g of almonds per gallon of almond milk, this is  estimate 0  above (.237kg almonds per litre). If it's assumed the almond milk is 2% (by weight), then this is  estimate 1  above (.02kg almonds per litre).  The  American Omnivore  diet estimates does not include rice, wheat, maize, vegetables or other non-animal products so can be considered a 'lower bound' on per capita CO2 and water consumption.  The non  American Omnivore  entries use soybeans as a proxy for the meat (by weight) for CO2 emission and rice as a proxy for meat (by weight) for water consumption to give a conservative estimate of the CO2 emissions and water usage.", 
            "title": "Worked calculations"
        }, 
        {
            "location": "/Food-CO2-Water/#references", 
            "text": "", 
            "title": "References"
        }, 
        {
            "location": "/Food-CO2-Water/#per-capita-consumption-of-poultry-and-livestock-1965-to-estimated-2019-in-pounds", 
            "text": "Year  Beef (lbs)  Pork (lbs)  Total Poultry (lbs)      208  57.0  50.8  109.6     This implies  25.85kg  of beef,  23.04kg  of pork and  49.71kg  of poultry for the average American.", 
            "title": "\"Per Capita Consumption of Poultry and Livestock, 1965 to Estimated 2019, in Pounds\""
        }, 
        {
            "location": "/Food-CO2-Water/#dairy-data", 
            "text": "The  per capita consumption of dairy for Americans :     Year  Milk Consumption (lbs)      2017  149     149 pounds per person per year is about  67.59kg per person per year.", 
            "title": "\"Dairy Data\""
        }, 
        {
            "location": "/Food-CO2-Water/#food-consumption-patterns-and-their-effect-on-water-requirement-in-china-by-j-liu-and-h-h-g-savenije", 
            "text": "Food  Water footprint $(\\frac{m^3}{kg})$  Per capita annual food consumption (2003) $(\\frac{kg}{(cap)(yr)})$      Rice  1.31  79    Wheat  0.98  61    Maize  0.84  15    Soybeans  3.20  7    Vegetables  0.19  270    Fruits  0.50  50    Beef  12.56  5    Pork  4.46  35    Poultry  2.39  11    Milk  1.00  17", 
            "title": "\"Food consumption patterns and their effect on water requirement in China\" by  J. Liu and H. H. G. Savenije"
        }, 
        {
            "location": "/Food-CO2-Water/#systematic-review-of-greenhouse-gas-emissions-for-different-fresh-food-categories-by-stephen-clune-enda-crossin-karli-verghese", 
            "text": "Food  Mean $\\frac{(kg) (CO2\\ eq)}{kg}$ (2015?)      Rice  2.66    Wheat  0.51    Maize  0.63    Soybeans  0.58    Vegetables  0.47    Fruits  0.50    Beef  28.73    Pork  5.85    Chicken  4.12    Milk  1.39    Almond/coconut milk  0.42", 
            "title": "\"Systematic review of greenhouse gas emissions for different fresh food categories\" by Stephen Clune, Enda Crossin, Karli Verghese"
        }, 
        {
            "location": "/Food-CO2-Water/#the-green-blue-and-grey-water-footprint-of-crops-and-derived-crop-products-by-m-m-mekonnen-and-a-y-hoekstra", 
            "text": "Food  Global average water footprint $(\\frac{m^3}{ton})$ (1996-2005)  Global average water footprint ($\\frac{m^3}{kg}$ (1996-2005))      Almonds  16095  17.74", 
            "title": "\"The green, blue and grey water footprint of crops and derived crop products\" by M. M. Mekonnen and A. Y. Hoekstra"
        }, 
        {
            "location": "/Food-CO2-Water/#how-many-ounces-of-almonds-go-into-making-each-half-gallon-of-almond-milk-example-silk-or-almond-breeze-brand", 
            "text": "As a conservative estimate of the almonds used in almond milk:   Around 2 cups of almonds for a half gallon.  Around  225 g per cup of ground almonds .  2 cups almonds = 450 g almonds.  1 gallon = 3.79 kg (water).  1/2 gallon = 1.90 kg  450 g almonds per 1.90 kg of almond milk  .237 kg of almonds per 1 kg of almond milk   As a potentially more realistic estimate of the number of almonds used in almond milk:   If almond milk has 2% of almonds, by weight, then for every litre of almond milk, there are approximately 20g of almonds  .02 kg of almonds per 1kg of almond milk", 
            "title": "How many ounces of almonds go into making each half-gallon of almond milk (example: Silk or Almond Breeze brand)?"
        }, 
        {
            "location": "/Food-CO2-Water/#greenhouse-gas-emissions-from-a-typical-passenger-vehicle", 
            "text": "$4600 \\frac{kg}{yr}$ of CO2 emissions for the typical US passenger vehicle.", 
            "title": "Greenhouse Gas Emissions from a Typical Passenger Vehicle"
        }, 
        {
            "location": "/Food-CO2-Water/#almond-milk-quite-good-for-you-very-bad-for-the-planet-by-emine-saner", 
            "text": "", 
            "title": "\"Almond milk: quite good for you \u2013 very bad for the planet\" by Emine Saner"
        }, 
        {
            "location": "/Food-CO2-Water/#your-almond-habit-is-sucking-california-dry-by-tom-philpott", 
            "text": "", 
            "title": "\"Your Almond Habit Is Sucking California Dry\" by Tom Philpott"
        }, 
        {
            "location": "/Food-CO2-Water/#lay-off-the-almond-milk-you-ignorant-hipsters-by-tom-philpott", 
            "text": "", 
            "title": "\"Lay Off the Almond Milk, You Ignorant Hipsters\" by Tom Philpott"
        }, 
        {
            "location": "/Food-CO2-Water/#almond-milk-is-taking-a-toll-on-the-environment", 
            "text": "", 
            "title": "\"Almond Milk is Taking a Toll on the Environment\""
        }, 
        {
            "location": "/Food-CO2-Water/#2019-04-02", 
            "text": "", 
            "title": "2019-04-02"
        }, 
        {
            "location": "/SSH-Recipes/", 
            "text": "SSH Recipes\n\n\n\n\n\n\n\n\nCommand\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nssh -L local:local.host:remote remote.host\n\n\nTunnel port \nlocal\n on \nlocal.host\n to \nremote\n port on \nremote.host\n\n\n\n\n\n\nssh -R remote:local.host:local remote.host\n\n\nTunnel port \nremote\n on \nremote.host\n to \nlocal\n port on \nlocal.host\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nssh -L 8080:localhost:80 user@remote.host\n\n\nSend port \n8080\n connections on \nlocalhost\n to port \n80\n on \nremote.host\n\n\n\n\n\n\nssh -R 2222:localhost:22 user@remote.host\n\n\nSend port \n2222\n connections on \nremote.host\n to port \n22\n locally (ssh redirection from remote to local)\n\n\n\n\n\n\n\n\n2019-09-24", 
            "title": "SSH Recipes"
        }, 
        {
            "location": "/SSH-Recipes/#ssh-recipes", 
            "text": "Command  Description      ssh -L local:local.host:remote remote.host  Tunnel port  local  on  local.host  to  remote  port on  remote.host    ssh -R remote:local.host:local remote.host  Tunnel port  remote  on  remote.host  to  local  port on  local.host        Example  Description      ssh -L 8080:localhost:80 user@remote.host  Send port  8080  connections on  localhost  to port  80  on  remote.host    ssh -R 2222:localhost:22 user@remote.host  Send port  2222  connections on  remote.host  to port  22  locally (ssh redirection from remote to local)", 
            "title": "SSH Recipes"
        }, 
        {
            "location": "/SSH-Recipes/#2019-09-24", 
            "text": "", 
            "title": "2019-09-24"
        }, 
        {
            "location": "/Future-Predictions/", 
            "text": "Future Predictions\n\n\nThese are a set of predictions about what's going to happen in the future.\n\n\nEach prediction will have conditions that need to be met in order for them to\nbe considered true as well as conditions that indicate if the prediction was wrong.\n\n\nEach prediction is meant to be falsifiable to avoid making broad claims that could\nbe considered having come to pass because of ambiguous assertions.\n\n\nArtificial Intelligence\n\n\n\n\nHuman level artificial intelligence will be a reality by the year 2030\n\n\n\n\n\n\n\n\n\n\nConditions for acceptance\n\n\n\n\n\n\n\n\n\n\nText conversation that is indistinguishable from human text conversation (passing the Turing test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConditions for failure\n\n\n\n\n\n\n\n\n\n\nOnly independent aspects that have been solved without putting them together (image recognition, natural language process, etc. without a complete system that integrates all of them together)\n\n\n\n\n\n\nEasily fooled chatbots\n\n\n\n\n\n\n\n\nThe fundamental assumptions for this prediction are:\n\n\n\n\nHuman cognition is the result of simple algorithms working in parallel on massive data sets\n\n\nThe human brain capacity is roughly 2.3 Pb of information\n\n\nHard disk space is a good proxy for the feasibility of producing human level intelligence\n\n\nAI will be achieved when commodity hardware is available, in the form of roughly a $1000 option, that has the compute and storage of the human brain (3.2Pb)\n\n\n\n\nUsing \njcmit.net/diskprice\n as a source, depending on how you count, hard drive prices fall at a rate of 1/2 every 2-3 years.\nAs of this writing, the prices is about $\\$$150/8Tb (.00000000001705302565 $\\$$US/byte).\n\n\n$$\n\\begin{equation}\n\\begin{split}\n\\frac{\\$ 1000}{2.3 \\text{Pb} \\cdot 2^{10} }   \n = 2^{-y \\alpha}\\frac{\\$150}{8 \\text{Tb}}  \\\\\n\\to y  \n= \\frac{ - \\lg{\\left( \\frac{8000}{2.3 \\cdot 150 \\cdot 2^{10} }\\right)} }{\\alpha} \\\\\n\\end{split}\n\\end{equation}\n$$\n\n\n$y$ is the number of years and \n$\\alpha$ is the doubling factor.\nIf $\\alpha \\in (\\frac{1}{2}, \\frac{1}{3})$, this gives a timeline of roughly 10 to 16 years before we'll see a hard drive that has the storage capacity of the human brain for\nabout $\\$$1000 USD.\n\n\nThe 2030 prediction is a bit aggressive and considering Moore's law might be slowing down, the timeline might be closer to 2040.\nRegardless, I am staying with my 2030 prediction.\n\n\nCrypto Currency\n\n\n\n\nA crypto currency, most likely Bitcoin, will be a major global currency, storing at least %20 of the global wealth by 2030\n\n\n\n\n\n\n\n\n\n\nConditions for acceptance\n\n\n\n\n\n\n\n\n\n\nUsed in day-to-day life for purchases and money transfers\n\n\n\n\n\n\nBy some reasonable estimate, 20% of the worlds wealth is stored in a crypto currency\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConditions for failure\n\n\n\n\n\n\n\n\n\n\nNot used for day-to-day purchases\n\n\n\n\n\n\nOnly a select few have crypto currency wallets\n\n\n\n\n\n\nCrypto currency is treated a stock or bond rather than a currency\n\n\n\n\n\n\n\n\nI believe Bitcoin to be the most likely leader as there's so much work and buy in currently, but this could change.\nA good rule of thumb of crypto currency not taking over is that if the USD price per coin is not high \nor\n the\nprice per coin is very high but is not in widespread usage, signaling that it's being used by the wealthy as a kind\nof modern stock market.\n\n\nThe prediction of 2030 is done by using historic USD-BTC price (\nsrc\n) and roughly\nfitting an exponential curve (by \"eye\").\nBitcoin is still in it's infancy so it's highly volatile, so this prediction might be significantly off.\n\n\nPart of this prediction is the fact that crypto currency solves a lot of problems and opens up new avenues for global trade:\n\n\n\n\nOnline purchases have the potential to be much easier\n\n\nMoney transfers have the potential to be much more seamless and cheap\n\n\nCurrency exchanges (for purchases, etc.) are normalized to a de-factor standard (e.g. Bitcoin)\n\n\nNon provincial ownership allowing for de-centralized operation and direction\n\n\n\n\nAs a side note, total global wealth as of 2019 is estimated to be $\\$$360T\n($ \\$360 \\cdot 10^{12} $) (\nsrc\n).\nIf Bitcoin is capped at 21M coins and establishes itself by storing %20 of the $\\$$360T, this gives $ \\frac{ \\$360T \\cdot 0.2 }{ 21M BTC } \\approx \\$3.4M/BTC $.\n\n\n\n\nUPDATE\n: If we estimate Bitcoin's growth at about 27% per year, this gives us about a 5-7 year time frame for when 1BTC will reach $1M.\n\n\nAs of this writing, this gives us an estimate that BTC will start to become ubiquitous around 2026 to 2028.\n\n\nEnergy Production\n\n\n\n\nSolar, wind and battery technology will account for the majority of the worlds energy production by 2040\n\n\n\n\n\n\n\n\n\n\nConditions for acceptance\n\n\n\n\n\n\n\n\n\n\nOver 50% of the world's energy usage will come from solar, wind and stored energy in the form of battery technology\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConditions for failure\n\n\n\n\n\n\n\n\n\n\nFossil fuels (coal), nuclear or other energy sources still being the primary energy provider\n\n\n\n\n\n\n\n\nSwanson's law (\nw\n) has photo voltaic cell prices falling at about 10% per year.\nThis is roughly a price halving every 6-7 years.\nCurrent prices are about $\\$$0.75 / W for low volume consumer panels and $\\$$0.20 / W for higher volumes.\n\n\nI guess there's debate on whether batteries follow a Moore's law like price curve (\nsrc\n \nsrc\n) but prices are falling at about %20 per year (\nsrc\n) perhaps due to Wright's law (\nw\n).\nRegardless, as of this writing, lead acid batteries are at $\\$$0.15/Wh and lithium batteries look to be somewhere in the range of $\\$$0.15/Wh to $\\$$0.05/Wh.\n\n\nThe average US household consumes 30 kWh per day.\nAssuming a 12 hour sunlight window, that's $30 kWh / 12h = 2500 W$ needed.\nThe average American pays $\\$$0.1854/kWh leading to about $\\$$1400/year in electricity costs (\nsrc\n).\n\n\nIf we assume we want at least a 2.5KW solar panel array and storage for 30kWh, that's $\\$$2000 to $\\$$6500, which is 2-5 years before the installation pays for itself.\nIn five years time that changes to about $\\$$800 to $\\$$2500, which is about 0.5 to 2 years before the installation pays for itself.\n\n\nSolar and battery technology might have a lot of hidden costs and other factors that might prohibit them from falling in price so drastically over the coming years\nbut when an installation gets within the cost of a single months electricity payment, it's hard to see how this couldn't become widely adopted.\n\n\n2040 is a conservative estimate and is made in consideration that I'm no doubt missing a large number of other factors that come into play from creating, deploying and installing energy stations,\non the consumer or business side.\n\n\n\n\nUPDATE\n: There is a current growth rate of 29% capacity, mostly supplied by China now (\nw\n, \niea\n).\nThere is %2.1 energy usage being satisfied by solar currently, leading to about a 15 year adoption schedule.\n\n\nAssuming the growth rate holds relatively steady, this amounts to adoption by 2036 to 2040.\n\n\n2021-04-27", 
            "title": "Future Predictions"
        }, 
        {
            "location": "/Future-Predictions/#future-predictions", 
            "text": "These are a set of predictions about what's going to happen in the future.  Each prediction will have conditions that need to be met in order for them to\nbe considered true as well as conditions that indicate if the prediction was wrong.  Each prediction is meant to be falsifiable to avoid making broad claims that could\nbe considered having come to pass because of ambiguous assertions.", 
            "title": "Future Predictions"
        }, 
        {
            "location": "/Future-Predictions/#artificial-intelligence", 
            "text": "Human level artificial intelligence will be a reality by the year 2030      Conditions for acceptance      Text conversation that is indistinguishable from human text conversation (passing the Turing test)        Conditions for failure      Only independent aspects that have been solved without putting them together (image recognition, natural language process, etc. without a complete system that integrates all of them together)    Easily fooled chatbots     The fundamental assumptions for this prediction are:   Human cognition is the result of simple algorithms working in parallel on massive data sets  The human brain capacity is roughly 2.3 Pb of information  Hard disk space is a good proxy for the feasibility of producing human level intelligence  AI will be achieved when commodity hardware is available, in the form of roughly a $1000 option, that has the compute and storage of the human brain (3.2Pb)   Using  jcmit.net/diskprice  as a source, depending on how you count, hard drive prices fall at a rate of 1/2 every 2-3 years.\nAs of this writing, the prices is about $\\$$150/8Tb (.00000000001705302565 $\\$$US/byte).  $$\n\\begin{equation}\n\\begin{split}\n\\frac{\\$ 1000}{2.3 \\text{Pb} \\cdot 2^{10} }     = 2^{-y \\alpha}\\frac{\\$150}{8 \\text{Tb}}  \\\\\n\\to y   = \\frac{ - \\lg{\\left( \\frac{8000}{2.3 \\cdot 150 \\cdot 2^{10} }\\right)} }{\\alpha} \\\\\n\\end{split}\n\\end{equation}\n$$  $y$ is the number of years and \n$\\alpha$ is the doubling factor.\nIf $\\alpha \\in (\\frac{1}{2}, \\frac{1}{3})$, this gives a timeline of roughly 10 to 16 years before we'll see a hard drive that has the storage capacity of the human brain for\nabout $\\$$1000 USD.  The 2030 prediction is a bit aggressive and considering Moore's law might be slowing down, the timeline might be closer to 2040.\nRegardless, I am staying with my 2030 prediction.", 
            "title": "Artificial Intelligence"
        }, 
        {
            "location": "/Future-Predictions/#crypto-currency", 
            "text": "A crypto currency, most likely Bitcoin, will be a major global currency, storing at least %20 of the global wealth by 2030      Conditions for acceptance      Used in day-to-day life for purchases and money transfers    By some reasonable estimate, 20% of the worlds wealth is stored in a crypto currency        Conditions for failure      Not used for day-to-day purchases    Only a select few have crypto currency wallets    Crypto currency is treated a stock or bond rather than a currency     I believe Bitcoin to be the most likely leader as there's so much work and buy in currently, but this could change.\nA good rule of thumb of crypto currency not taking over is that if the USD price per coin is not high  or  the\nprice per coin is very high but is not in widespread usage, signaling that it's being used by the wealthy as a kind\nof modern stock market.  The prediction of 2030 is done by using historic USD-BTC price ( src ) and roughly\nfitting an exponential curve (by \"eye\").\nBitcoin is still in it's infancy so it's highly volatile, so this prediction might be significantly off.  Part of this prediction is the fact that crypto currency solves a lot of problems and opens up new avenues for global trade:   Online purchases have the potential to be much easier  Money transfers have the potential to be much more seamless and cheap  Currency exchanges (for purchases, etc.) are normalized to a de-factor standard (e.g. Bitcoin)  Non provincial ownership allowing for de-centralized operation and direction   As a side note, total global wealth as of 2019 is estimated to be $\\$$360T\n($ \\$360 \\cdot 10^{12} $) ( src ).\nIf Bitcoin is capped at 21M coins and establishes itself by storing %20 of the $\\$$360T, this gives $ \\frac{ \\$360T \\cdot 0.2 }{ 21M BTC } \\approx \\$3.4M/BTC $.   UPDATE : If we estimate Bitcoin's growth at about 27% per year, this gives us about a 5-7 year time frame for when 1BTC will reach $1M.  As of this writing, this gives us an estimate that BTC will start to become ubiquitous around 2026 to 2028.", 
            "title": "Crypto Currency"
        }, 
        {
            "location": "/Future-Predictions/#energy-production", 
            "text": "Solar, wind and battery technology will account for the majority of the worlds energy production by 2040      Conditions for acceptance      Over 50% of the world's energy usage will come from solar, wind and stored energy in the form of battery technology        Conditions for failure      Fossil fuels (coal), nuclear or other energy sources still being the primary energy provider     Swanson's law ( w ) has photo voltaic cell prices falling at about 10% per year.\nThis is roughly a price halving every 6-7 years.\nCurrent prices are about $\\$$0.75 / W for low volume consumer panels and $\\$$0.20 / W for higher volumes.  I guess there's debate on whether batteries follow a Moore's law like price curve ( src   src ) but prices are falling at about %20 per year ( src ) perhaps due to Wright's law ( w ).\nRegardless, as of this writing, lead acid batteries are at $\\$$0.15/Wh and lithium batteries look to be somewhere in the range of $\\$$0.15/Wh to $\\$$0.05/Wh.  The average US household consumes 30 kWh per day.\nAssuming a 12 hour sunlight window, that's $30 kWh / 12h = 2500 W$ needed.\nThe average American pays $\\$$0.1854/kWh leading to about $\\$$1400/year in electricity costs ( src ).  If we assume we want at least a 2.5KW solar panel array and storage for 30kWh, that's $\\$$2000 to $\\$$6500, which is 2-5 years before the installation pays for itself.\nIn five years time that changes to about $\\$$800 to $\\$$2500, which is about 0.5 to 2 years before the installation pays for itself.  Solar and battery technology might have a lot of hidden costs and other factors that might prohibit them from falling in price so drastically over the coming years\nbut when an installation gets within the cost of a single months electricity payment, it's hard to see how this couldn't become widely adopted.  2040 is a conservative estimate and is made in consideration that I'm no doubt missing a large number of other factors that come into play from creating, deploying and installing energy stations,\non the consumer or business side.   UPDATE : There is a current growth rate of 29% capacity, mostly supplied by China now ( w ,  iea ).\nThere is %2.1 energy usage being satisfied by solar currently, leading to about a 15 year adoption schedule.  Assuming the growth rate holds relatively steady, this amounts to adoption by 2036 to 2040.", 
            "title": "Energy Production"
        }, 
        {
            "location": "/Future-Predictions/#2021-04-27", 
            "text": "", 
            "title": "2021-04-27"
        }, 
        {
            "location": "/Diophantine-Approximation/", 
            "text": "Diophantine Approximation\n\n\nDirichlet's Approximation Theorem\n\n\n$$\n\\begin{array}{c}\n\\forall \\alpha \\in \\mathbb{R}, \\forall n \\in \\mathbb{Z}_{+} \\\\\n\\exists p, q \\in \\mathbb{Z}_{+}, \\ \\ 1 \\le q \\le n \\\\\n\\to 0 \n | q \\alpha - p | \n \\frac{1}{n} \\\\\n\\end{array}\n$$\n\n\nConsider\n\n\n$$\n\\begin{array}{c}\nr_q = q \\alpha - \\lfloor q \\alpha \\rfloor \\\\\nr_q \\in [0,1) \\\\\n\\end{array}\n$$\n\n\nAllow for $r_0 = 0$ and there\nare $(n+1)$ points for $(0 \\le q \\le n)$, $r_q$, in the unit interval.\nBy pigeonhole, there must be two that fall in some interval $[\\frac{s}{n}, \\frac{s+1}{n})$ for $0 \\le s \n n$.\n\n\nCall the two points $r_m$ and $r_l$, $\\ m \n l$.\n\n\n$$\n\\begin{array}{cl}\n\n |r_m - r_l| \n \\frac{1}{n} \\\\\n\\to \n | \\{ m \\alpha \\} - \\{ l \\alpha \\} | \n \\frac{1}{n} \\\\\n\\to \n | (m \\alpha - \\lfloor m \\alpha \\rfloor) - (l \\alpha - \\lfloor l \\alpha \\rfloor) | \n \\frac{1}{n} \\\\\n\\to \n | (m - l) \\alpha - (\\lfloor m \\alpha \\rfloor - \\lfloor l \\alpha \\rfloor ) | \n \\frac{1}{n} \\\\\n\\end{array}\n$$\n\n\n$$\n\\begin{array}{cl}\n \n q' = m - l \\in \\mathbb{Z} \\\\\n \n p' = (\\lfloor m \\alpha \\rfloor - \\lfloor l \\alpha \\rfloor )  \\in \\mathbb{Z} \\\\\n\\to \n | q' \\alpha - p' | \n \\frac{1}{n}\n\\end{array}\n$$\n\n\n\n\nSo long as $\\alpha$ is irrational:\n\n\n$$\n\\begin{array}{cl}\n \n | \\alpha - \\frac{p}{q} | \n \\frac{1}{q n} \n \\frac{1}{n} \\\\\n\\to \n | \\alpha - \\frac{p}{q} | \n \\frac{1}{C}\n\\end{array}\n$$\n\n\nFor some constant, $C$.\n\n\nWe can now pick an $n'$ s.t.:\n\n\n$$\n\\begin{array}{cl}\n \n \\frac{1}{n'} \n \\frac{1}{C} \\\\\n\\to \n | \\alpha - \\frac{p'}{q'} | \n \\frac{1}{C}\n\\to \n q' \\ne q\n\\end{array}\n$$\n\n\nSo there are infinitely many pairs, ${p,q}$ s.t. $ | q \\alpha - p | \n \\frac{1}{n} $.\n\n\n\n\nRearranging,\n\n\n$$\n\\begin{array}{cl}\n\n | \\alpha - \\frac{p}{q} | \n \\frac{1}{q n} \n \\frac{1}{q^2} \\\\\n\\to \n | \\alpha - \\frac{p}{q} | \n \\frac{1}{q^2}\n\\end{array}\n$$\n\n\nNote that this only says \"there exists\" a $q$ and is not a relation for all $q$.\n\n\n$$\n\\begin{array}{cl}\n\n \\forall \\alpha \\in \\mathbb{R}, \\forall n_0 \\in \\mathbb{Z}_{+} \\\\\n\n \\exists p,q \\in \\mathbb{Z}_{+}, \\ \\ q \n n_0 \\\\\n\\to \n | \\alpha - \\frac{p}{q} | \n \\frac{1}{q^2}\n\\end{array}\n$$\n\n\n\n\nHere is an example for $2^{\\frac{1}{4}}$:\n\n\n#!/usr/bin/python3\nimport gmpy2\nwith gmpy2.local_context(gmpy2.coneext(), precision=1000) as ctx:\n  x = gmpy2.sqrt(gmpy2.sqrt(2))\n  N = 1000000\n  for q in range(1,N):\n    pf = gmpy2.floor(q*x)\n    pc = gmpy2.ceil(q*x)\n    r = q*x - pf\n    rp = pc - q*x\n    if (r\nrp):\n      y = x - (pf/gmpy2.mpfr(q))\n      print(q,y)\n    else:\n      y = (pc/gmpy2.mpfr(q)) - x\n      print(q,y)\n\n\n\n\n\n\nLiouville Bounds\n\n\nFor $\\alpha$ the root of a polynomial of degree $n$:\n\n\n$$\n\\begin{array}{cc}\n\\forall p(x) = \\sum_{k=0}^{n} c_k x^k, \n c_k \\in \\mathbb{Z}, \\ \\ p(\\alpha) = 0 \\\\\n\\exists A \n 0, \n \\forall p,q \\in \\mathbb{Z}_{+} \\\\\n| \\alpha - \\frac{p}{a}|  \n \\frac{A}{q^n}\n\\end{array}\n$$\n\n\n$\\alpha_k$ the roots of $p(x)$ above, with $\\alpha$ distinct from the rest, and $M$ is the maximum value of $|p'(x)|$ on the interval $[\\alpha-1,\\alpha+1]$:\n\n\n$$\nA \n \\text{min} \\left( 1, \\frac{1}{M}, | \\alpha - \\alpha_1|, | \\alpha - \\alpha_2|, \\cdots, |\\alpha - \\alpha_{n-1}| \\right)\n$$\n\n\nAssume, for contradiction, some $p,q$, with $p(\\frac{p}{q}) \\ne 0 $ s.t.:\n\n\n$$\n| \\alpha - \\frac{p}{a} | \\le \\frac{A}{q^n} \\le A \n \\text{min} \\left( 1, \\frac{1}{M}, | \\alpha - \\alpha_1|, | \\alpha - \\alpha_2|, \\cdots, |\\alpha - \\alpha_{n-1}| \\right)\n$$\n\n\nMy the mean value theorem:\n\n\n$$\n\\begin{array}{cc}\n\n p(\\alpha) - p(\\frac{p}{q}) = (\\alpha - \\frac{p}{q}) \\cdot p'(x_0) \\\\\n\\to \n | \\alpha - \\frac{p}{q}| = \\frac{ |p(\\alpha) - p(\\frac{p}{q}) }{ | p'(x_0) | }  \\\\\n\\to \n | \\alpha - \\frac{p}{q}| = | \\frac{p(\\frac{p}{q})}{ p'(x_0) } | \\\\\n\\to \n | \\alpha - \\frac{p}{q}| = | \\frac{ \\sum_{k=0}^{n} c_k p^k q^{-k} }{ p'(x_0) } |  \\\\\n\\to \n | \\alpha - \\frac{p}{q}| = \\frac{1}{q^n} | \\frac{ \\sum_{k=0}^{n} c_k p^k q^{n-k} }{ p'(x_0) } |  \\ge \\frac{ \\frac{1}{q^n} }{ p'(x_0) } \\\\\n\\to \n | \\alpha - \\frac{p}{q}| \\ge \\frac{ \\frac{1}{q^n} }{ p'(x_0) } \\ge \\frac{ \\frac{1}{q^n} }{ M } \n \\frac{A}{q^n} \\ge | \\alpha - \\frac{p}{q} | \\\\\n\\to \n | \\alpha - \\frac{p}{q}|  \n | \\alpha - \\frac{p}{q} | \\\\\n\\end{array}\n$$\n\n\nA contradiction, so the inequality holds.\n\n\n2020-05-22", 
            "title": "Diophantine Approximation"
        }, 
        {
            "location": "/Diophantine-Approximation/#diophantine-approximation", 
            "text": "", 
            "title": "Diophantine Approximation"
        }, 
        {
            "location": "/Diophantine-Approximation/#dirichlets-approximation-theorem", 
            "text": "$$\n\\begin{array}{c}\n\\forall \\alpha \\in \\mathbb{R}, \\forall n \\in \\mathbb{Z}_{+} \\\\\n\\exists p, q \\in \\mathbb{Z}_{+}, \\ \\ 1 \\le q \\le n \\\\\n\\to 0   | q \\alpha - p |   \\frac{1}{n} \\\\\n\\end{array}\n$$  Consider  $$\n\\begin{array}{c}\nr_q = q \\alpha - \\lfloor q \\alpha \\rfloor \\\\\nr_q \\in [0,1) \\\\\n\\end{array}\n$$  Allow for $r_0 = 0$ and there\nare $(n+1)$ points for $(0 \\le q \\le n)$, $r_q$, in the unit interval.\nBy pigeonhole, there must be two that fall in some interval $[\\frac{s}{n}, \\frac{s+1}{n})$ for $0 \\le s   n$.  Call the two points $r_m$ and $r_l$, $\\ m   l$.  $$\n\\begin{array}{cl}  |r_m - r_l|   \\frac{1}{n} \\\\\n\\to   | \\{ m \\alpha \\} - \\{ l \\alpha \\} |   \\frac{1}{n} \\\\\n\\to   | (m \\alpha - \\lfloor m \\alpha \\rfloor) - (l \\alpha - \\lfloor l \\alpha \\rfloor) |   \\frac{1}{n} \\\\\n\\to   | (m - l) \\alpha - (\\lfloor m \\alpha \\rfloor - \\lfloor l \\alpha \\rfloor ) |   \\frac{1}{n} \\\\\n\\end{array}\n$$  $$\n\\begin{array}{cl}\n   q' = m - l \\in \\mathbb{Z} \\\\\n   p' = (\\lfloor m \\alpha \\rfloor - \\lfloor l \\alpha \\rfloor )  \\in \\mathbb{Z} \\\\\n\\to   | q' \\alpha - p' |   \\frac{1}{n}\n\\end{array}\n$$   So long as $\\alpha$ is irrational:  $$\n\\begin{array}{cl}\n   | \\alpha - \\frac{p}{q} |   \\frac{1}{q n}   \\frac{1}{n} \\\\\n\\to   | \\alpha - \\frac{p}{q} |   \\frac{1}{C}\n\\end{array}\n$$  For some constant, $C$.  We can now pick an $n'$ s.t.:  $$\n\\begin{array}{cl}\n   \\frac{1}{n'}   \\frac{1}{C} \\\\\n\\to   | \\alpha - \\frac{p'}{q'} |   \\frac{1}{C}\n\\to   q' \\ne q\n\\end{array}\n$$  So there are infinitely many pairs, ${p,q}$ s.t. $ | q \\alpha - p |   \\frac{1}{n} $.   Rearranging,  $$\n\\begin{array}{cl}  | \\alpha - \\frac{p}{q} |   \\frac{1}{q n}   \\frac{1}{q^2} \\\\\n\\to   | \\alpha - \\frac{p}{q} |   \\frac{1}{q^2}\n\\end{array}\n$$  Note that this only says \"there exists\" a $q$ and is not a relation for all $q$.  $$\n\\begin{array}{cl}  \\forall \\alpha \\in \\mathbb{R}, \\forall n_0 \\in \\mathbb{Z}_{+} \\\\  \\exists p,q \\in \\mathbb{Z}_{+}, \\ \\ q   n_0 \\\\\n\\to   | \\alpha - \\frac{p}{q} |   \\frac{1}{q^2}\n\\end{array}\n$$   Here is an example for $2^{\\frac{1}{4}}$:  #!/usr/bin/python3\nimport gmpy2\nwith gmpy2.local_context(gmpy2.coneext(), precision=1000) as ctx:\n  x = gmpy2.sqrt(gmpy2.sqrt(2))\n  N = 1000000\n  for q in range(1,N):\n    pf = gmpy2.floor(q*x)\n    pc = gmpy2.ceil(q*x)\n    r = q*x - pf\n    rp = pc - q*x\n    if (r rp):\n      y = x - (pf/gmpy2.mpfr(q))\n      print(q,y)\n    else:\n      y = (pc/gmpy2.mpfr(q)) - x\n      print(q,y)", 
            "title": "Dirichlet's Approximation Theorem"
        }, 
        {
            "location": "/Diophantine-Approximation/#liouville-bounds", 
            "text": "For $\\alpha$ the root of a polynomial of degree $n$:  $$\n\\begin{array}{cc}\n\\forall p(x) = \\sum_{k=0}^{n} c_k x^k,   c_k \\in \\mathbb{Z}, \\ \\ p(\\alpha) = 0 \\\\\n\\exists A   0,   \\forall p,q \\in \\mathbb{Z}_{+} \\\\\n| \\alpha - \\frac{p}{a}|    \\frac{A}{q^n}\n\\end{array}\n$$  $\\alpha_k$ the roots of $p(x)$ above, with $\\alpha$ distinct from the rest, and $M$ is the maximum value of $|p'(x)|$ on the interval $[\\alpha-1,\\alpha+1]$:  $$\nA   \\text{min} \\left( 1, \\frac{1}{M}, | \\alpha - \\alpha_1|, | \\alpha - \\alpha_2|, \\cdots, |\\alpha - \\alpha_{n-1}| \\right)\n$$  Assume, for contradiction, some $p,q$, with $p(\\frac{p}{q}) \\ne 0 $ s.t.:  $$\n| \\alpha - \\frac{p}{a} | \\le \\frac{A}{q^n} \\le A   \\text{min} \\left( 1, \\frac{1}{M}, | \\alpha - \\alpha_1|, | \\alpha - \\alpha_2|, \\cdots, |\\alpha - \\alpha_{n-1}| \\right)\n$$  My the mean value theorem:  $$\n\\begin{array}{cc}  p(\\alpha) - p(\\frac{p}{q}) = (\\alpha - \\frac{p}{q}) \\cdot p'(x_0) \\\\\n\\to   | \\alpha - \\frac{p}{q}| = \\frac{ |p(\\alpha) - p(\\frac{p}{q}) }{ | p'(x_0) | }  \\\\\n\\to   | \\alpha - \\frac{p}{q}| = | \\frac{p(\\frac{p}{q})}{ p'(x_0) } | \\\\\n\\to   | \\alpha - \\frac{p}{q}| = | \\frac{ \\sum_{k=0}^{n} c_k p^k q^{-k} }{ p'(x_0) } |  \\\\\n\\to   | \\alpha - \\frac{p}{q}| = \\frac{1}{q^n} | \\frac{ \\sum_{k=0}^{n} c_k p^k q^{n-k} }{ p'(x_0) } |  \\ge \\frac{ \\frac{1}{q^n} }{ p'(x_0) } \\\\\n\\to   | \\alpha - \\frac{p}{q}| \\ge \\frac{ \\frac{1}{q^n} }{ p'(x_0) } \\ge \\frac{ \\frac{1}{q^n} }{ M }   \\frac{A}{q^n} \\ge | \\alpha - \\frac{p}{q} | \\\\\n\\to   | \\alpha - \\frac{p}{q}|    | \\alpha - \\frac{p}{q} | \\\\\n\\end{array}\n$$  A contradiction, so the inequality holds.", 
            "title": "Liouville Bounds"
        }, 
        {
            "location": "/Diophantine-Approximation/#2020-05-22", 
            "text": "", 
            "title": "2020-05-22"
        }, 
        {
            "location": "/GCode-Common/", 
            "text": "Common GCode Commands\n\n\n\n\n\n\n\n\nGCode\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nG0\n\n\nRapid motion\n\n\n\n\n\n\nG1\n\n\nSlow motion\n\n\n\n\n\n\nG20\n\n\nUnits in inches\n\n\n\n\n\n\nG21\n\n\nUnits in mm\n\n\n\n\n\n\nG38.2\n\n\nProbe towards workspace (-), stop on contact, alarm if probe not tripped\n\n\n\n\n\n\nG38.3\n\n\nProbe towards workspace (-), stop on contact\n\n\n\n\n\n\nG38.4\n\n\nProbe away from workspace (+), stop on loss of contact, alarm if probe not tripped\n\n\n\n\n\n\nG38.5\n\n\nProbe away from workspace (+), stop on loss of contact\n\n\n\n\n\n\nM3[S\nS\n]\n\n\nStart spindle\n\n\n\n\n\n\nM5\n\n\nStop spindle\n\n\n\n\n\n\n\n\n2020-09-09", 
            "title": "GCode Common"
        }, 
        {
            "location": "/GCode-Common/#common-gcode-commands", 
            "text": "GCode  Description      G0  Rapid motion    G1  Slow motion    G20  Units in inches    G21  Units in mm    G38.2  Probe towards workspace (-), stop on contact, alarm if probe not tripped    G38.3  Probe towards workspace (-), stop on contact    G38.4  Probe away from workspace (+), stop on loss of contact, alarm if probe not tripped    G38.5  Probe away from workspace (+), stop on loss of contact    M3[S S ]  Start spindle    M5  Stop spindle", 
            "title": "Common GCode Commands"
        }, 
        {
            "location": "/GCode-Common/#2020-09-09", 
            "text": "", 
            "title": "2020-09-09"
        }, 
        {
            "location": "/Misc-Math/", 
            "text": "Misc. Math\n\n\nLandau Notation\n\n\n$$\nf(x) = O(g(x)) \\iff \\limsup_{x \\to \\infty} \\frac{f(x)}{g(x)} \n \\infty\n$$\n\n\n$$\nf(x) = o(g(x)) \\iff \\lim_{x \\to \\infty} \\frac{f(x)}{g(x)} = 0\n$$\n\n\n$$\nf(x) = \\Omega(g(x)) \\iff \\liminf_{x \\to \\infty} \\frac{f(x)}{g(x)} \n 0\n$$\n\n\n$$\nf(x) = \\omega(g(x)) \\iff \\liminf_{x \\to \\infty} \\frac{f(x)}{g(x)} = \\infty\n$$\n\n\n$$\nf(x) = \\Theta(g(x)) \\iff f(x) = O(g(x)) \\ \\\n \\ f(x) = \\Omega(g(x))\n$$\n\n\n\n\n$e$ is Irrational\n\n\nProof by contradiction.\n\n\nAssume $e$ is rational.\nThis means $e = \\frac{p}{v}$.\n\n\nWe use the identity:\n\n\n$$\ne = \\sum_{k=0}^{\\infty} \\frac{1}{k!}\n$$\n\n\nWith the usual convention that $0!=1$.\n\n\n$$\n\\begin{array}{lcl}\n \n e \n = \\frac{p}{v} \\\\\n \n \n = \\sum_{k=0}^{v} \\frac{1}{k!} + \\sum_{k=v+1}^{\\infty} \\frac{1}{k!} \\\\\n\\to \n (v!) e  \n = (v-1)! p \\\\\n \n \n = \\sum_{k=0}^{v} \\frac{v!}{k!} + ( \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots )\n\\end{array}\n$$\n\n\nBy assumption, $(v!) e = (v-1)! p \\in \\mathbb{Z}$.\nWe also have the first sum $\\sum_{k=0}^{v} \\frac{v!}{k!} \\in \\mathbb{Z}$.\n\n\nThe second sum is greater than 0 and we can get bounds:\n\n\n$$\n\\begin{array}{lrcl}\n \n  0 \n \n \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots \n \\le \\frac{1}{v+1} \\sum_{k=0}^{\\infty} \\frac{1}{(v+1)^k} \\\\\n\\to \n 0 \n \n \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots \n \\le \\frac{1}{v}\n\\end{array}\n$$\n\n\nChoose $v \n 1$ and we have the second sum as non-integral, contradicting the assumption of rationality.\n\n\n\n\n2020-10-31", 
            "title": "Misc Math"
        }, 
        {
            "location": "/Misc-Math/#misc-math", 
            "text": "", 
            "title": "Misc. Math"
        }, 
        {
            "location": "/Misc-Math/#landau-notation", 
            "text": "$$\nf(x) = O(g(x)) \\iff \\limsup_{x \\to \\infty} \\frac{f(x)}{g(x)}   \\infty\n$$  $$\nf(x) = o(g(x)) \\iff \\lim_{x \\to \\infty} \\frac{f(x)}{g(x)} = 0\n$$  $$\nf(x) = \\Omega(g(x)) \\iff \\liminf_{x \\to \\infty} \\frac{f(x)}{g(x)}   0\n$$  $$\nf(x) = \\omega(g(x)) \\iff \\liminf_{x \\to \\infty} \\frac{f(x)}{g(x)} = \\infty\n$$  $$\nf(x) = \\Theta(g(x)) \\iff f(x) = O(g(x)) \\ \\  \\ f(x) = \\Omega(g(x))\n$$", 
            "title": "Landau Notation"
        }, 
        {
            "location": "/Misc-Math/#e-is-irrational", 
            "text": "Proof by contradiction.  Assume $e$ is rational.\nThis means $e = \\frac{p}{v}$.  We use the identity:  $$\ne = \\sum_{k=0}^{\\infty} \\frac{1}{k!}\n$$  With the usual convention that $0!=1$.  $$\n\\begin{array}{lcl}\n   e   = \\frac{p}{v} \\\\\n     = \\sum_{k=0}^{v} \\frac{1}{k!} + \\sum_{k=v+1}^{\\infty} \\frac{1}{k!} \\\\\n\\to   (v!) e    = (v-1)! p \\\\\n     = \\sum_{k=0}^{v} \\frac{v!}{k!} + ( \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots )\n\\end{array}\n$$  By assumption, $(v!) e = (v-1)! p \\in \\mathbb{Z}$.\nWe also have the first sum $\\sum_{k=0}^{v} \\frac{v!}{k!} \\in \\mathbb{Z}$.  The second sum is greater than 0 and we can get bounds:  $$\n\\begin{array}{lrcl}\n    0     \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots   \\le \\frac{1}{v+1} \\sum_{k=0}^{\\infty} \\frac{1}{(v+1)^k} \\\\\n\\to   0     \\frac{1}{v+1} + \\frac{1}{(v+1)(v+2)} + \\cdots   \\le \\frac{1}{v}\n\\end{array}\n$$  Choose $v   1$ and we have the second sum as non-integral, contradicting the assumption of rationality.", 
            "title": "$e$ is Irrational"
        }, 
        {
            "location": "/Misc-Math/#2020-10-31", 
            "text": "", 
            "title": "2020-10-31"
        }, 
        {
            "location": "/Socio-Economic-Definitions/", 
            "text": "Socio-Economic Definitions\n\n\n\n\n\n\nAutocracy\n\n\n\n\n\n\nA form of government in which unlimited power is held by a single individual\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nCapitalism\n\n\n\n\n\n\n(politics)\n A socio-economic system based on private ownership of resources or capital.\n\n\n(economics)\n An economic system based on private ownership of the means of production and their operation for profit.\n\n\n(politics, economic liberalism)\n A socio-economic system based on private property rights, including the private ownership of resources or capital, with economic decisions made largely through the operation of a market unregulated by the state.\n\n\n(economics, economic liberalism)\n An economic system based on the abstraction of resources into the form of privately owned capital, with economic decisions made largely through the operation of a market unregulated by the state.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nCommunism\n\n\n\n\n\n\n(socio-economics)\n A socio-economic system based on common ownership of the means of production and the absence of social classes, money and a state.\n\n\n\n\n(\nsrc\n, \nWiktionary\n)\n\n\n\n\n\n\nDirect Democracy\n\n\n\n\n\n\nA form of democracy in which people decide on policy initiatives directly.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nFascism\n\n\n\n\n\n\nA form of ideology characterized by centralized, totalitarian governance, strong regimentation of the economy\n  and of society, and repression of criticism or opposition, by violence or otherwise. \n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nFiefdom\n\n\n\n\n\n\nAny organization in the control of a dominant individual.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nFeudalism\n\n\n\n\n\n\nA hierarchical social system, reinforced by religion, based on personal ownership of resources and fealty between a lord and subject.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nMarxism\n\n\n\n\n\n\nA method of socioeconomic analysis that uses a materialist interpretation of historical development, better known\n  as historical materialism, to understand class relations and social conflict as well as a dialectical perspective\n  to view social transformation.\n\n\nThe socialist and communist theory that advocates a capture of state power by the working or lower class\n  with an ultimate goal of the institution of communism.\n\n\n\n\n(\nsrc\n \nwiktionary\n)\n\n\n\n\n\n\nNeoliberalism\n\n\n\n\n\n\nAn ideology that espouses ideas associated with economic liberalism, free market capitalism with a focus on\n  privatization, deregulation, globalization, free trade, austerity and reduction in government spending to increase\n  the role of the private sector in the economy and society.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nOligarchy\n\n\n\n\n\n\nA government run by only a few, often wealthy, individuals.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nRepresentative Democracy\n\n\n\n\n\n\nA type of democracy founded on the principle of elected officials representing groups of people.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nSocial Democracy\n\n\n\n\n\n\nA policy that advocates economic and social interventions to promote social justice through liberal-democratic polity\n  and a capitalist-oriented mixed economy. \n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nSocialism\n\n\n\n\n\n\n(socio-economics)\n Any economic or political theory advocating for collective or governmental ownership and\n  administration of the means of production and distribution of goods\n\n\n\n\n(\nsrc\n)\n\n\n\n\nRelated Definitions\n\n\n\n\nDebate\n\n\n\n\n\n\nA discussion of opposing views\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nDialectic\n\n\n\n\n\n\nA discourse between two or more people holding different points of view about a subject but\n  both parties wishing to establish the truth through reasoned methods of argumentation.\n\n\nA formal system of reasoning that arrives at a truth by the exchange of logical arguments\n\n\n\n\nNote that in the context of Marxism, dialectic discussion (dialectical method, dialectics) serves as a discourse between two parties\nto mutually come to truth, as opposed to a didactic discussion, where one party is teaching the other\nor a general debate, where both parties could be discussing to voice their views without any\nintention of changing them.\n\n\n(\nsrc\n \nwiktionary\n)\n\n\n\n\n\n\nDictatorship of the Proletariat\n\n\n\n\n\n\nA state of affairs in which the proletariat holds political power.\n\n\nThe temporary period following the fall of capitalism characterized by a struggle\n  to achieve a classless, stateless and moneyless communist society\n\n\n\n\n(\nsrc\n \nwiktionary\n)\n\n\n\n\n\n\nDidactic\n\n\n\n\n\n\nA method of instruction with the intent to teach or demonstrate.\n\n\n\n\n(\nsrc\n) \n\n\n\n\n\n\nHistorical Materialism\n\n\n\n\n\n\nA Marxist methodological approach to the study of society, economics, and history, looking for the causes of developments and changes in human society in the means by which humans collectively produce the necessities of life.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nMaterialism\n\n\n\n\n\n\nA form of philosophical monism that holds that matter is the fundamental substance in nature, and that all things,\n  including mental states and consciousness, are results of material interactions.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nMonism\n\n\nA concept that there exists only a single reality of which the physical world is an aspect of. Specifically, monism denies the existence of a mind\n  body duality or other aspects of duality.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n\n\nProletariat\n\n\n\n\n\n\nThe working class or lower class.\n\n\n\n\n(\nsrc\n)\n\n\n\n\n2020-11-02", 
            "title": "Socio Economic Definitions"
        }, 
        {
            "location": "/Socio-Economic-Definitions/#socio-economic-definitions", 
            "text": "Autocracy    A form of government in which unlimited power is held by a single individual   ( src )    Capitalism    (politics)  A socio-economic system based on private ownership of resources or capital.  (economics)  An economic system based on private ownership of the means of production and their operation for profit.  (politics, economic liberalism)  A socio-economic system based on private property rights, including the private ownership of resources or capital, with economic decisions made largely through the operation of a market unregulated by the state.  (economics, economic liberalism)  An economic system based on the abstraction of resources into the form of privately owned capital, with economic decisions made largely through the operation of a market unregulated by the state.   ( src )    Communism    (socio-economics)  A socio-economic system based on common ownership of the means of production and the absence of social classes, money and a state.   ( src ,  Wiktionary )    Direct Democracy    A form of democracy in which people decide on policy initiatives directly.   ( src )    Fascism    A form of ideology characterized by centralized, totalitarian governance, strong regimentation of the economy\n  and of society, and repression of criticism or opposition, by violence or otherwise.    ( src )    Fiefdom    Any organization in the control of a dominant individual.   ( src )    Feudalism    A hierarchical social system, reinforced by religion, based on personal ownership of resources and fealty between a lord and subject.   ( src )    Marxism    A method of socioeconomic analysis that uses a materialist interpretation of historical development, better known\n  as historical materialism, to understand class relations and social conflict as well as a dialectical perspective\n  to view social transformation.  The socialist and communist theory that advocates a capture of state power by the working or lower class\n  with an ultimate goal of the institution of communism.   ( src   wiktionary )    Neoliberalism    An ideology that espouses ideas associated with economic liberalism, free market capitalism with a focus on\n  privatization, deregulation, globalization, free trade, austerity and reduction in government spending to increase\n  the role of the private sector in the economy and society.   ( src )    Oligarchy    A government run by only a few, often wealthy, individuals.   ( src )    Representative Democracy    A type of democracy founded on the principle of elected officials representing groups of people.   ( src )    Social Democracy    A policy that advocates economic and social interventions to promote social justice through liberal-democratic polity\n  and a capitalist-oriented mixed economy.    ( src )    Socialism    (socio-economics)  Any economic or political theory advocating for collective or governmental ownership and\n  administration of the means of production and distribution of goods   ( src )", 
            "title": "Socio-Economic Definitions"
        }, 
        {
            "location": "/Socio-Economic-Definitions/#related-definitions", 
            "text": "Debate    A discussion of opposing views   ( src )    Dialectic    A discourse between two or more people holding different points of view about a subject but\n  both parties wishing to establish the truth through reasoned methods of argumentation.  A formal system of reasoning that arrives at a truth by the exchange of logical arguments   Note that in the context of Marxism, dialectic discussion (dialectical method, dialectics) serves as a discourse between two parties\nto mutually come to truth, as opposed to a didactic discussion, where one party is teaching the other\nor a general debate, where both parties could be discussing to voice their views without any\nintention of changing them.  ( src   wiktionary )    Dictatorship of the Proletariat    A state of affairs in which the proletariat holds political power.  The temporary period following the fall of capitalism characterized by a struggle\n  to achieve a classless, stateless and moneyless communist society   ( src   wiktionary )    Didactic    A method of instruction with the intent to teach or demonstrate.   ( src )     Historical Materialism    A Marxist methodological approach to the study of society, economics, and history, looking for the causes of developments and changes in human society in the means by which humans collectively produce the necessities of life.   ( src )    Materialism    A form of philosophical monism that holds that matter is the fundamental substance in nature, and that all things,\n  including mental states and consciousness, are results of material interactions.   ( src )    Monism  A concept that there exists only a single reality of which the physical world is an aspect of. Specifically, monism denies the existence of a mind\n  body duality or other aspects of duality.   ( src )    Proletariat    The working class or lower class.   ( src )", 
            "title": "Related Definitions"
        }, 
        {
            "location": "/Socio-Economic-Definitions/#2020-11-02", 
            "text": "", 
            "title": "2020-11-02"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/", 
            "text": "Bitcoin Moon Math\n\n\nBitcoin Price Bounds\n\n\n~$280T        Global wealth\n  21M         Total Bitcoins\n\n\n\n\nAssuming Bitcoin stores 10% of the total value of domestic companies,\nthis gives \n\n\n     (0.1) * ($280 * 10^12) / (21 * 10^6 BTC)\n =  ~$1.3 * 10^6 / BTC\n\n\n\n\nor about \n$1.3M\n per Bitcoin.\n\n\nThis gives a rough range of what the Bitcoin value should be.\nIncreasing the stored wealth increases the number as would\nan increased global company market capitalization.\nThe 10% was chosen as an arbitrary number.\nOne can easily imagine 20%+ or more as also being reasonable.\n\n\nAs a guide, if Bitcoin should ever significantly exceed\nthe global wealth or still be volatile\nafter being valued at a significant percentage of the global wealth,\nthen this would indicate, to me, a bubble.\n\n\nComments\n\n\nAs has been said elsewhere, should Bitcoin store a significant amount\nof wealth to warrant a $1M+/BTC, this would probably come with\nsome significant changes, such as:\n\n\n\n\nMajor resellers accepting Bitcoin\n\n\nBanks going out of business or otherwise changing significantly\n\n\nSome countries or governments adopting Bitcoin as a major or primary currency\n\n\n\n\nThe point being that Bitcoin adoption doesn't happen in a vacuum.\nIf the price were to rise significantly, this would bring changes\nto our everyday lives including the way we do banking.\n\n\n\n\nReferences\n\n\n\n\n~$64.4T Market Cap of domestic companies \nthe World Bank\n (2016)\n\n\n~$280T global wealth \nGlobal Wealth Report by Credit Suisse\n (2017)\n\n\n\n\n2017-12-06", 
            "title": "Bitcoin Moon Math"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/#bitcoin-moon-math", 
            "text": "", 
            "title": "Bitcoin Moon Math"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/#bitcoin-price-bounds", 
            "text": "~$280T        Global wealth\n  21M         Total Bitcoins  Assuming Bitcoin stores 10% of the total value of domestic companies,\nthis gives        (0.1) * ($280 * 10^12) / (21 * 10^6 BTC)\n =  ~$1.3 * 10^6 / BTC  or about  $1.3M  per Bitcoin.  This gives a rough range of what the Bitcoin value should be.\nIncreasing the stored wealth increases the number as would\nan increased global company market capitalization.\nThe 10% was chosen as an arbitrary number.\nOne can easily imagine 20%+ or more as also being reasonable.  As a guide, if Bitcoin should ever significantly exceed\nthe global wealth or still be volatile\nafter being valued at a significant percentage of the global wealth,\nthen this would indicate, to me, a bubble.", 
            "title": "Bitcoin Price Bounds"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/#comments", 
            "text": "As has been said elsewhere, should Bitcoin store a significant amount\nof wealth to warrant a $1M+/BTC, this would probably come with\nsome significant changes, such as:   Major resellers accepting Bitcoin  Banks going out of business or otherwise changing significantly  Some countries or governments adopting Bitcoin as a major or primary currency   The point being that Bitcoin adoption doesn't happen in a vacuum.\nIf the price were to rise significantly, this would bring changes\nto our everyday lives including the way we do banking.", 
            "title": "Comments"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/#references", 
            "text": "~$64.4T Market Cap of domestic companies  the World Bank  (2016)  ~$280T global wealth  Global Wealth Report by Credit Suisse  (2017)", 
            "title": "References"
        }, 
        {
            "location": "/Bitcoin-Moon-Math/#2017-12-06", 
            "text": "", 
            "title": "2017-12-06"
        }, 
        {
            "location": "/Energy-Discussion/", 
            "text": "Solar Energy Discussion\n\n\nEnergy Limits of Earth\n\n\nAll estimates are going to be conservative.\n\n\n$$\n\\begin{array}{ll}\n\\textbf{Earth Radius} \n \\approx 6.371 \\cdot 10^6 (m) \\\\\n\\textbf{Solar Energy} \n \\approx 240 \\frac{W}{m^2} \\\\\n\\textbf{Earth Population} \n \\approx 7.7 \\cdot 10^9 \\\\\n\\textbf{Average Energy Per Person} \n \\approx 30 kWh \\text{ daily usage}\n\\end{array}\n$$\n\n\nApproximate the solar energy available on land by underestimating the area\nby taking the disk as described by the radius of the Earth:\n\n\n$$\n\\begin{array}{l}\n\\pi \\cdot (6.371 \\cdot 10^6)^2 (m^2) \\cdot (240 \\frac{W}{m^2}) \\cdot (24 \\frac{h}{day}) \\\\\n\\to ~ 700 \\cdot 10^{15} \\frac{W h}{day}\n\\end{array}\n$$\n\n\nEstimating global population usage:\n\n\n$$\n\\begin{array}{l}\n(7.7 \\cdot 10^9) \\cdot (30 \\cdot 10^3 \\frac{W h}{day}) \\\\\n\\to ~ 0.231 \\cdot 10^{15} \\frac{W h}{day}\n\\end{array}\n$$\n\n\nSo, as a rough upper bound, the energy requirement of\nhumans that could be \"theoretically\" satisfied by the sun's energy\nis about an increase of\n$ \\frac{700}{.231} (\\approx 3030) $ more people,\nor about a population of 23 trillion people.\n\n\nWorld Adoption of Solar\n\n\nAt a current growth rate of $29\\%$ with $2.1\\%$ of the population being\nsupplied by solar, an estimate for the full adoption would be:\n\n\n$$\n\\begin{array}{l}\n2.1 \\cdot (1.29)^y = 100 \\\\\n\\to y = \\frac{ \\ln(\\frac{100}{2.1}) }{ \\ln(1.29) } \\\\\n\\to y \\approx  15.17\n\\end{array}\n$$\n\n\nOr about 15 years till we see a large scale rollout and adoption.\n\n\nSome caveats are that this assumes exponential growth for the entirety of\nthe adoption where the more likely event is some \"s-curve\" or other logistic\ncurve as it nears full adoption.\n\n\nIt further assumes constant $29\\%$ growth.\nAlso note that the vast majority of this growth is from China production.\n\n\nWorld Energy Consumption\n\n\nOne estimate for the energy consumption used by the world is about a $3\\%$ annual increase, globally.\n\n\nHere a plot of energy usage globally, taken from the \nEIA\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is the energy usage for the USA:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome caveats:\n\n\n\n\nThe units are different in the two different graphs because of differing sources for the data\n\n\nChina makes up for most of the energy usage, as do other developing nations, whereas the USA and Europe have slowed to less than $2\\%$ energy usage\n\n\nThe USA had some sort of change in the late 1970s and went from $3\\%+$ energy usage to around $1\\%$ energy usage\n\n\n\n\nIf a conservative $3\\%$ annual increase is taken, the numbers above for the suns available energy on the earth and the\ncurrent energy consumption of the worlds population, we can get an estimate for when the energy consumption will exceed\nthe earths available energy from the sun:\n\n\n$$\n\\begin{array}{l}\n\\frac{700 \\cdot 10^15 \\cdot \\frac{W h}{day} }{ .231 \\cdot 10^{15} \\frac{W h}{day} } \\\\\n\\approx 3030\n\\end{array}\n$$\n\n\n$$\n\\begin{array}{l}\n\\exp( y \\cdot \\ln(1.03) ) = 3030 \\\\\n\\to y = \\frac{ \\ln(3030) }{ \\ln(1.03) } \\\\\n\\to y \\approx 271 \\text{ years }\n\\end{array}\n$$\n\n\nWhich gives us a rough estimate of 270 years for us to reach a \"Type I\" civilization on the Kardeshev scale.\n\n\nReferences\n\n\n\n\nEarth Radius\n\n\nSolar Energy Potential\n\n\nGlobal Population\n\n\nGrowth of Photovoltaics\n (\nsource\n)\n\n\nWorld Energy Usage\n\n\nCountry Energy Usage\n\n\nKardashev scale\n\n\n\n\n2021-04-24", 
            "title": "Energy Discussion"
        }, 
        {
            "location": "/Energy-Discussion/#solar-energy-discussion", 
            "text": "", 
            "title": "Solar Energy Discussion"
        }, 
        {
            "location": "/Energy-Discussion/#energy-limits-of-earth", 
            "text": "All estimates are going to be conservative.  $$\n\\begin{array}{ll}\n\\textbf{Earth Radius}   \\approx 6.371 \\cdot 10^6 (m) \\\\\n\\textbf{Solar Energy}   \\approx 240 \\frac{W}{m^2} \\\\\n\\textbf{Earth Population}   \\approx 7.7 \\cdot 10^9 \\\\\n\\textbf{Average Energy Per Person}   \\approx 30 kWh \\text{ daily usage}\n\\end{array}\n$$  Approximate the solar energy available on land by underestimating the area\nby taking the disk as described by the radius of the Earth:  $$\n\\begin{array}{l}\n\\pi \\cdot (6.371 \\cdot 10^6)^2 (m^2) \\cdot (240 \\frac{W}{m^2}) \\cdot (24 \\frac{h}{day}) \\\\\n\\to ~ 700 \\cdot 10^{15} \\frac{W h}{day}\n\\end{array}\n$$  Estimating global population usage:  $$\n\\begin{array}{l}\n(7.7 \\cdot 10^9) \\cdot (30 \\cdot 10^3 \\frac{W h}{day}) \\\\\n\\to ~ 0.231 \\cdot 10^{15} \\frac{W h}{day}\n\\end{array}\n$$  So, as a rough upper bound, the energy requirement of\nhumans that could be \"theoretically\" satisfied by the sun's energy\nis about an increase of\n$ \\frac{700}{.231} (\\approx 3030) $ more people,\nor about a population of 23 trillion people.", 
            "title": "Energy Limits of Earth"
        }, 
        {
            "location": "/Energy-Discussion/#world-adoption-of-solar", 
            "text": "At a current growth rate of $29\\%$ with $2.1\\%$ of the population being\nsupplied by solar, an estimate for the full adoption would be:  $$\n\\begin{array}{l}\n2.1 \\cdot (1.29)^y = 100 \\\\\n\\to y = \\frac{ \\ln(\\frac{100}{2.1}) }{ \\ln(1.29) } \\\\\n\\to y \\approx  15.17\n\\end{array}\n$$  Or about 15 years till we see a large scale rollout and adoption.  Some caveats are that this assumes exponential growth for the entirety of\nthe adoption where the more likely event is some \"s-curve\" or other logistic\ncurve as it nears full adoption.  It further assumes constant $29\\%$ growth.\nAlso note that the vast majority of this growth is from China production.", 
            "title": "World Adoption of Solar"
        }, 
        {
            "location": "/Energy-Discussion/#world-energy-consumption", 
            "text": "One estimate for the energy consumption used by the world is about a $3\\%$ annual increase, globally.  Here a plot of energy usage globally, taken from the  EIA .              Here is the energy usage for the USA:              Some caveats:   The units are different in the two different graphs because of differing sources for the data  China makes up for most of the energy usage, as do other developing nations, whereas the USA and Europe have slowed to less than $2\\%$ energy usage  The USA had some sort of change in the late 1970s and went from $3\\%+$ energy usage to around $1\\%$ energy usage   If a conservative $3\\%$ annual increase is taken, the numbers above for the suns available energy on the earth and the\ncurrent energy consumption of the worlds population, we can get an estimate for when the energy consumption will exceed\nthe earths available energy from the sun:  $$\n\\begin{array}{l}\n\\frac{700 \\cdot 10^15 \\cdot \\frac{W h}{day} }{ .231 \\cdot 10^{15} \\frac{W h}{day} } \\\\\n\\approx 3030\n\\end{array}\n$$  $$\n\\begin{array}{l}\n\\exp( y \\cdot \\ln(1.03) ) = 3030 \\\\\n\\to y = \\frac{ \\ln(3030) }{ \\ln(1.03) } \\\\\n\\to y \\approx 271 \\text{ years }\n\\end{array}\n$$  Which gives us a rough estimate of 270 years for us to reach a \"Type I\" civilization on the Kardeshev scale.", 
            "title": "World Energy Consumption"
        }, 
        {
            "location": "/Energy-Discussion/#references", 
            "text": "Earth Radius  Solar Energy Potential  Global Population  Growth of Photovoltaics  ( source )  World Energy Usage  Country Energy Usage  Kardashev scale", 
            "title": "References"
        }, 
        {
            "location": "/Energy-Discussion/#2021-04-24", 
            "text": "", 
            "title": "2021-04-24"
        }
    ]
}